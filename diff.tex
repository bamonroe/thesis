\documentclass[11pt,a4paper]{report}
%DIF LATEXDIFF DIFFERENCE FILE
%DIF DEL ref.tex    Fri Mar 17 17:30:32 2017
%DIF ADD main.tex   Fri Mar 17 16:45:22 2017

\usepackage{subfiles}  % For compiling things into one big document from sub-documents

\usepackage[justification=centering]{caption}
\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{setspace}	% For line spacing
\usepackage{csquotes}	% For quoting
\usepackage[hidelinks]{hyperref} %To make references into links
\usepackage{amsmath}	% For equation stuff
\usepackage{amssymb}	% For math symbols
\usepackage{amsthm}		% For theorem environments
\usepackage{relsize}	% To resize math symbols
\usepackage{bm}			% For Bold math Symbols
\usepackage{nicefrac}	% For nice looking fractions
\usepackage{graphicx}	% For Graphics
\usepackage[justification=centering]{subcaption} % For subcaptions to tables/figures

\graphicspath{{ch1/figures/}{ch2/figures/}{ch3/figures/}{ch4/figures/}{figures/}}

% for changes
\usepackage[final]{changes}

% Stuff or code
\usepackage{listings}
\usepackage{color}
\lstset{frame=none,
  language=R,
  aboveskip=1mm,
  belowskip=1mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}
\newsavebox{\LstBoxR}
\newsavebox{\LstBoxStata}


% Stuff for Tables
\usepackage{tabularx}
\newcolumntype{Y}{>{\centering\arraybackslash}X} % A centered column type that sucks up excess space
\usepackage{caption}
\usepackage{adjustbox}
\usepackage{booktabs}		% For \toprule, \midrule, and \bottomrule
\usepackage{pgfplotstable}	% Generates a table from a CSV
\pgfplotsset{compat=1.12}
\setlength{\extrarowheight}{.5em}
\usepackage{multirow}

\usepackage[stretch=15]{microtype}	% Read about this, tested it, and was sold.
\usepackage[backend=biber, uniquename=false, refsegment=chapter, doi=false, isbn=false, url=false, style=authoryear-comp, maxnames=99]{biblatex}	%For bibliography stuff
\renewbibmacro{in:}{}
\addbibresource{/home/bam/thesis/thesis/library.bib}	% The path to the bibliography file

% Convenience Commands
\newcommand\CE{\ensuremath{\mathit{CE}}}    % Certainty Equivalent
\newcommand\Prob{\ensuremath{\mathit{Pr}}}  % Probability
\newcommand{\E}{\operatorname{E}}           % Variance Operator
\newcommand{\Var}{\operatorname{Var}}       % Variance Operator
\newcommand\OB{\ensuremath{\succ^{\!*}}}    % Certainty Equivalent
\newcommand{\money}[1]{$\$\!\:#1$}          % Money command
\newcommand{\overbar}[1]{\mkern 1.5mu\overline{\mkern-1.5mu#1\mkern-1.5mu}\mkern 1.5mu} % Command to make a shorter overline/longer bar


% Make a break a column title into 2 lines
\newcommand{\cnline}[2][c]{%
	\setlength{\extrarowheight}{0em}
	\begin{tabular}[#1]{@{}c@{}}#2\end{tabular}
	\setlength{\extrarowheight}{5em}
}

% Table of contents only when locally compiled
\newcommand{\lltoc}[1]{
	\pagenumbering{gobble}
	\makeatletter
	\@starttoc{toc}%
	\makeatother
	\break
	\pagenumbering{arabic}
}
\newcommand{\llltoc}[1]{
	\makeatletter
	\@starttoc{toc}%
	\makeatother
}

% A fix for Chapter numbering with above
\let\oldchapter\chapter
\renewcommand{\chapter}[1]{
	\refstepcounter{chapter}% 
	\oldchapter*{{\huge Chapter \thechapter}\\[1em]#1}
}

% Commands that display text either in or out of subfile
\newcommand{\onlyinsubfile}[1]{#1}
\newcommand{\notinsubfile}[1]{}


\title{Stochastic Models in Experimental Economics}
\author{Brian Albert Monroe}
%DIF PREAMBLE EXTENSION ADDED BY LATEXDIFF
%DIF UNDERLINE PREAMBLE %DIF PREAMBLE
\RequirePackage[normalem]{ulem} %DIF PREAMBLE
\RequirePackage{color}\definecolor{RED}{rgb}{1,0,0}\definecolor{BLUE}{rgb}{0,0,1} %DIF PREAMBLE
\providecommand{\DIFaddtex}[1]{{\protect\color{blue}\uwave{#1}}} %DIF PREAMBLE
\providecommand{\DIFdeltex}[1]{{\protect\color{red}\sout{#1}}}                      %DIF PREAMBLE
%DIF SAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddbegin}{} %DIF PREAMBLE
\providecommand{\DIFaddend}{} %DIF PREAMBLE
\providecommand{\DIFdelbegin}{} %DIF PREAMBLE
\providecommand{\DIFdelend}{} %DIF PREAMBLE
%DIF FLOATSAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddFL}[1]{\DIFadd{#1}} %DIF PREAMBLE
\providecommand{\DIFdelFL}[1]{\DIFdel{#1}} %DIF PREAMBLE
\providecommand{\DIFaddbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFaddendFL}{} %DIF PREAMBLE
\providecommand{\DIFdelbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFdelendFL}{} %DIF PREAMBLE
%DIF HYPERREF PREAMBLE %DIF PREAMBLE
\providecommand{\DIFadd}[1]{\texorpdfstring{\DIFaddtex{#1}}{#1}} %DIF PREAMBLE
\providecommand{\DIFdel}[1]{\texorpdfstring{\DIFdeltex{#1}}{}} %DIF PREAMBLE
\newcommand{\DIFscaledelfig}{0.5}
%DIF HIGHLIGHTGRAPHICS PREAMBLE %DIF PREAMBLE
\RequirePackage{settobox} %DIF PREAMBLE
\RequirePackage{letltxmacro} %DIF PREAMBLE
\newsavebox{\DIFdelgraphicsbox} %DIF PREAMBLE
\newlength{\DIFdelgraphicswidth} %DIF PREAMBLE
\newlength{\DIFdelgraphicsheight} %DIF PREAMBLE
% store original definition of \includegraphics %DIF PREAMBLE
\LetLtxMacro{\DIFOincludegraphics}{\includegraphics} %DIF PREAMBLE
\newcommand{\DIFaddincludegraphics}[2][]{{\color{blue}\fbox{\DIFOincludegraphics[#1]{#2}}}} %DIF PREAMBLE
\newcommand{\DIFdelincludegraphics}[2][]{% %DIF PREAMBLE
\sbox{\DIFdelgraphicsbox}{\DIFOincludegraphics[#1]{#2}}% %DIF PREAMBLE
\settoboxwidth{\DIFdelgraphicswidth}{\DIFdelgraphicsbox} %DIF PREAMBLE
\settoboxtotalheight{\DIFdelgraphicsheight}{\DIFdelgraphicsbox} %DIF PREAMBLE
\scalebox{\DIFscaledelfig}{% %DIF PREAMBLE
\parbox[b]{\DIFdelgraphicswidth}{\usebox{\DIFdelgraphicsbox}\\[-\baselineskip] \rule{\DIFdelgraphicswidth}{0em}}\llap{\resizebox{\DIFdelgraphicswidth}{\DIFdelgraphicsheight}{% %DIF PREAMBLE
\setlength{\unitlength}{\DIFdelgraphicswidth}% %DIF PREAMBLE
\begin{picture}(1,1)% %DIF PREAMBLE
\thicklines\linethickness{2pt} %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,0){\framebox(1,1){}}}% %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,0){\line( 1,1){1}}}% %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,1){\line(1,-1){1}}}% %DIF PREAMBLE
\end{picture}% %DIF PREAMBLE
}\hspace*{3pt}}} %DIF PREAMBLE
} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddbegin}{\DIFaddbegin} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddend}{\DIFaddend} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelbegin}{\DIFdelbegin} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelend}{\DIFdelend} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddbegin}{\DIFOaddbegin \let\includegraphics\DIFaddincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddend}{\DIFOaddend \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelbegin}{\DIFOdelbegin \let\includegraphics\DIFdelincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelend}{\DIFOaddend \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddbeginFL}{\DIFaddbeginFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddendFL}{\DIFaddendFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelbeginFL}{\DIFdelbeginFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelendFL}{\DIFdelendFL} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddbeginFL}{\DIFOaddbeginFL \let\includegraphics\DIFaddincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddendFL}{\DIFOaddendFL \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelbeginFL}{\DIFOdelbeginFL \let\includegraphics\DIFdelincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelendFL}{\DIFOaddendFL \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
%DIF END PREAMBLE EXTENSION ADDED BY LATEXDIFF

\begin{document}
% Set up the commands for when full document is compiled together
\renewcommand{\onlyinsubfile}[1]{}
\renewcommand{\notinsubfile}[1]{#1}
\renewcommand{\lltoc}[1]{}
\let\chapter\oldchapter

\pagenumbering{arabic}
\maketitle
\onehalfspacing
\tableofcontents


\onehalfspacing
\setcounter{chapter}{0}
\chapter{Weird Data in Experiments, and Economists' Reactions to Them}

\lltoc

\section{\enquote{Preference Reversals} and the \texorpdfstring{\textcite{Grether1979}}{Grether \& Plott (1979)}  Experiments}

\textcite{Grether1979} describes and tests for explanations of \enquote{preference reversal} phenomenon that had been observed in previous studies by psychologists, in particular \textcite{Lichtenstein1971, Lichtenstein1973} and \textcite{Lindman1971}.
In these experiments subjects were asked to directly state a preference for one of two bets, termed a $P$ bet and a \$ bet,  and then to state a price at which they would be willing to sell each bet.
These stated preferences generate an implied preference for the two bets.
The observed phenomenon was of subjects stating a preference for either the $P$ or the \$ bet in the direct comparison, and then stating a higher selling price for opposite bet.
This type of behavior was deemed a \enquote{preference reversal} because the stated preferences and the implied preferences were inconsistent.
This preference reversal was said to be incompatible with Expected Utility Theory (EUT), which, assuming a deterministic choice process and ignoring indifference for now, requires that a subject state a higher price for the bet which she selected in the direct comparison.
\textcite[623]{Grether1979} set about to condut \enquote{a series of experiments designed to discredit the psychologists' works as applied to economics} and ended up \enquote{as perplexed as the reader who has just been introduced to the problem.} \parencite*[624]{Grether1979} after failing to substantially reduce the observed inconsistencies in their own controlled experiment.

\textcite{Grether1979} identified 13 possible theoretical criticisms and/or explanations of this phenomenon, of which 3 related to economic theory, 6 were psychological in nature, and 4 were artifacts of experimental method.
Of greatest concern to experimental economists should be the explanations involving experimental method and economic theory.
The possible explanations concerning economic theory included misspecified incentives, income effects, and indifference.
The possible explanations involving experimental method included confusion and misunderstanding, low frequency of errors/small sample sizes, unsophisticated subjects, and, my favorite, that the experimenters were psychologists.
Grether and Plott then detail the ways in which each of these possibilities could potentially lead to the observed seemingly theory-inconsistent data, discuss how the previous literature by psychologists inadequately control for these various possibilities, and how their experiment attempts to impose adequate controls.

In identifying these possibilities, \textcite{Grether1979} touch on aspects of conducting economic laboratory experiments which are later codified as necessary precepts for valid controlled experiments by \textcite{Smith1982}.{\footnotemark} 
These precepts will be elaborated on later.

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	Notably missing from \textcite{Harrison2001} is a restriction on psychologists from conducting experiments.
}

To better understand the nature of the preference reversal phenomenon as described by \textcite{Grether1979}, the subsequent critiques of their method, and potential accommodations of this seemingly inconsistent data, a description of the relevant details of the experiment is needed.
Subjects were students recruited from economics and political science classes, promised a minimum of \money{5} for participation and that the experiment would take no longer than one hour.

The experiment entailed the subjects making 2 types of choices.
The first asked them to state either a strict preference for a $P$ bet or a \$ bet, where the terms are defined below, or stating that they \enquote{Don't care} across 6 pairs of $P$ and \$ bets.
The second asked subjects to state \enquote{the smallest price for which you would sell a ticket to the following bet} \parencite*[630]{Grether1979} for each $P$ bet and \$ bet across the same 6 pairs.
Though each pair of $P$ bets and \$ bets were for different amounts, the relationship between the $P$ bets and \$ bets remained similar across all 6 pairs.
The $P$ bet, named for being a \enquote{probability} bet, is a lottery between winning a small but positive amount of money, $P_1$ with a high probability (never less than 29/36), and incurring a small loss, $P_0$ on the subject's initial endowment with a low probability (never more than 7/36).
The \$ bet, named for being a \enquote{money} bet, is a lottery between winning a large amount of money, $\$_1$, with a low probability (never more than 18/36), and incurring a small loss, $\$_0$, on the subject's initial endowment with a relatively high probability (never less than 18/36).

\textcite{Grether1979} conducted two different experiments eliciting the above choices which  varied slightly in order to test one of the psychological theories for the preference reversal phenomenon.
In the first experiment the subjects were split into two groups in which one group was asked to make a series of hypothetical decisions, for which they would be paid a guaranteed \money{7}, while the other group was initially endowed \money{7}, but told that their final earnings would depend on one of their choices chosen at random and being played out.
Both groups were asked their preferences for pairs 1, 2, and 3, then asked their minimum selling price for all 12 gambles, then asked their preferences for pairs 4, 5, and 6.
The second experiment was also split into two groups but both groups were paid based on their decisions and they were also asked for \enquote{the exact dollar amount such that you are indifferent between the bet and the amount of money} in addition to being asked for a selling price directly.
The first group was asked for a \enquote{selling price} first while the second group was asked for the \enquote{dollar equivalent} amount first.
This additional set of questions were implemented to control for potential strategic behavior that might be associated with the term \enquote{selling}.

All of the groups that were incentivized with real monetary rewards were told that they would only be paid for one of their choices.
This was meant to combat the income effect of accumulating earnings across many questions.
If a selling price question was selected for payment, the experimenters would use the method detailed in G. M. Becker, DeGroot \& Marschak (1964) (BDM).
In this method, a subject is asked to report the lowest price she is willing to accept to give up her right to play a certain lottery.
The experimenter then selects a \enquote{buying} price from a uniform distribution between two feasible price intervals and if the \enquote{selling} price reported by the subject is less than the selected buying price the subject receives the buying price, otherwise the subject plays out the lottery; in this experiment the random distribution was between \money{0.00} and \money{9.99}.
BDM explain how this type of auction mechanism leads to the subject's true selling price being the strongly dominant response, at least in theory.

Despite having conducted this experiment in expectation of refuting the results of psychologists, \textcite{Grether1979} end up confirming these results with their own experiment.
The lack of a substantial reduction in the proportion of subjects displaying the preference reversal phenomenon, particularly in the groups which had monetary incentives attached to their choices, led \textcite{Grether1979} to suggest that certain assumptions economist had held concerning the structure of preferences may not be valid.
\textcite[623]{Grether1979} remarked concerning the preference reversal phenomenon \enquote{The inconsistency is deeper than the mere lack of transitivity or even stochastic transitivity.
It suggests that no optimization principles of any sort lie behind even the simplest of human choices and that the uniformities in human choice behavior which lie behind market behavior may result from principles which are of a completely different sort from those generally accepted.} 

The totals of the different choices for the groups of incentivized subjects are presented in Table \ref{tb:GP1979-res} below.
Experiment 1 in Table \ref{tb:GP1979-res} only includes the group which was paid with real money, while Experiment 2-1 and Experiment 2-2 in Table \ref{tb:GP1979-res} represent experiment 2 groups 1 and 2, respectively,  where the differences between the groups are detailed above.
The mean difference in reported prices for inconsistent choices from experiment 1 is reported in Table \ref{tb:GP1979-mv}, \textcite{Grether1979} did not report these statistics for experiment 2.
In Table \ref{tb:GP1979-mv} the \enquote{Predicted} preference reversal is that of selecting the $P$ bet in the direct comparison and stating a higher selling price for the \$ bet, and the \enquote{Unpredicted} preference reversal is selecting the \$ bet in the direct comparison and stating a higher selling price for the $P$ bet.


\begin{table}
	\caption{\textcite{Grether1979} - Results for Incentivized Experiments}
	\label{tb:GP1979-res}
	\centering
	\begin{tabularx}{\textwidth}{Ycccccc}
		\multicolumn{3}{c}{Experiment 1} \\\hline
			             &         & \multicolumn{3}{c}{Reservation Prices} &              &                \\[0em]\cmidrule{3-5} 
		Bet              & Choices & Consistent & Inconsistent & Equal      & \%Consistent & \%Inconsistent \\[0em]\hline
		P                &      99 &         26 &           69 &    4       &      26.26\% &        69.70\% \\[-.1em]
		\$               &     174 &        145 &           22 &    7       &      83.33\% &        12.64\% \\[-.1em]
		Indifferent      &       3 &            &              &            &              &                \\[-.1em]\hline
		                                                                                   &                \\[-.5em]
		\multicolumn{3}{c}{Experiment 2}                                                                    \\[0em]\hline
		\multicolumn{2}{l}{\underline{Selling Price}}                                                       \\[0em]
		P                & 44     & 8         & 30          & 6    & 18.18\%   & 68.18\%                    \\[-.1em]
		\$               & 72     & 54        & 15          & 3    & 75.00\%   & 20.83\%                    \\[-.1em]
		Indifferent      & 4      &           &             &      &           &                            \\[-.1em]
		\multicolumn{3}{l}{\underline{Equivalent Price}}                                                    \\[0em]
		P                & 44     & 4         & 34          & 6    & 9.09\%    & 68.18\%                    \\[-.1em]
		\$               & 72     & 59        & 11          & 2    & 81.94\%   & 15.28\%                    \\[-.1em]
		Indifferent      &        &           &             &      &           &                            \\[-.1em]\hline
		                                                                       &                            \\[-.5em]
		\multicolumn{3}{c}{Experiment 2-1}                                                                  \\[0em]\hline
		\multicolumn{2}{l}{\underline{Selling Price}}                                                       \\[0em]
		P                & 44     & 16        & 27          & 1    & 36.36\%   & 61.36\%                    \\[-.1em]
		\$               & 64     & 54        & 9           & 1    & 84.38\%   & 14.06\%                    \\[-.1em]
		Indifferent      & 0      &           &             &      &           &                            \\[-.1em]
		\multicolumn{2}{c}{\underline{Equivalent Price}}                                                    \\[0em]
		P                & 44     & 19        & 22          & 3    & 43.18\%   & 50.00\%                    \\[-.1em]
		\$               & 72     & 51        & 10          & 3    & 79.69\%   & 15.63\%                    \\[-.1em]
		Indifferent      & 0      &           &             &      &           &                            \\[-.1em]\bottomrule


	\end{tabularx}
\end{table}

\break

\begin{table}
	\caption{ \textcite{Grether1979} - Experiment 1:\\Mean Values of Reversals (in Dollars)}
	\label{tb:GP1979-mv}
	\centering
	\begin{tabularx}{4.5in}{cccccc}
		    & \multicolumn{2}{c}{Predicted} & & \multicolumn{2}{c}{Unpredicted} \\\cmidrule{2-3}\cmidrule{5-6}
		Bet & Incentives & No Incentives    & & Incentives & No Incentives      \\\hline
		1   &       1.71 & 2.49             & &       0.40 & 0.79               \\ 
		2   &       1.45 & 2.65             & &       0.51 & 0.90               \\ 
		3   &       1.48 & 1.29             & &       1.00 & 0.25               \\ 
		4   &       3.31 & 5.59             & &       3.00 & 0.02               \\ 
		5   &       1.52 & 1.79             & &       0.38 & 0.01               \\ 
		6   &       0.92 & 1.18             & &       0.33 & 0.31               \\\bottomrule

	\end{tabularx}
\end{table}


In Table \ref{tb:GP1979-res} two things are apparent.
The first is the degree of inconsistent choices from subjects who chose the $P$ bet in a binary choice option and then reported a higher price for the \$ bet from exactly the same pair in the BDM task.
Of all the groups with incentivized choices, no fewer than 50\% of those who chose the $P$ bet reported a selling price for the $P$ bet that was at least 1 cent below the selling price reported for the \$ best.
Table \ref{tb:GP1979-mv} shows that the average difference between the elicited selling price and the expected value of the lottery in question ranged from 1 cent to \money{5.59}.
The magnitude of these differences will form an important part of the critique of these experiments by \textcite{Harrison1989, Harrison1992} which will be discussed later.

The second implication from Table \ref{tb:GP1979-res} is the asymmetry of the frequency of choice inconsistencies.
While the maximum proportion of inconsistency for subjects selecting a $P$ bet choice in the binary comparison was about 77%, the maximum proportion of inconsistency for selecting a \$ bet was only about 21%.
Also, the  mean value of the reversal is larger for the \enquote{Predicted} reversal for every bet.
Subsequent critiques of these experiments ignore this asymmetry, suggest that it is meaningless due to a failure to satisfy either the saliency or dominance precepts initially proposed by \textcite{Smith1982}, to be discussed later, or suggest that this asymmetry is predicted by alternative theories to EUT, such as the \enquote{Regret Theory} of  Loomes \& Sugden (1982).

\section{Theoretical Critiques of the \texorpdfstring{\textcite{Grether1979}}{Grether \& Plott (1979)} Experiments}

\textcite{Holt1986} offers an explanation of the preference reversal phenomenon which does not require the forfeiture of transitivity.
Instead, \textcite{Holt1986} proposes that should the independence axiom not hold, subjects are not making choices which are separable, but instead are making choices between compound lotteries.
Choices over compounded lotteries may display the preference reversal phenomenon without being a violation of transitivity.

Take for example a three question scenario which represents the \textcite{Grether1979} instrument, where a subject must make a choice between a $P$ bet and a \$ bet, and the subject is asked to reveal her selling price for both the $P$ bet and the \$ bet using the BDM mechanism.
Suppose also that only one of these three choices will be played out for real earnings.
The expected utility of such a scenario would be the following:

\begin{equation}
	\label{eq:GP-EU}
	\frac{1}{3}\E\lbrace u (w+\tilde{x})\rbrace  + \frac{1}{3}\E\lbrace u (w+\tilde{b}(r_\DOLLAR ;X_\DOLLAR ))\rbrace + \frac{1}{3}\E\lbrace u (w+\tilde{b}(r_P;X_P))\rbrace
\end{equation}

\noindent where $w$ is the initial wealth of the subject, $\tilde{x}$ is the random payment determined by the chosen lottery, $X_\DOLLAR $ or $X_P$, and $\tilde{b}$ is the random payment of BDM mechanism given the elicited selling price $r$ for each respective lottery, $X_\DOLLAR $ or $X_P$.

Given equation (\ref{eq:GP-EU}) and the validity of the independence axiom, the subject should choose the lottery in the binary comparison which she prefers most, and reveal the minimum price she is willing to sell each lottery in order to maximize her utility.
The ranking of the minimum reservation prices should also correspond to the selected of lottery in the binary choice.
However, suppose that the binary choice came after the selling price elicitations, the subject can be said to be making a choice between two compound lotteries:

\begin{equation}
	\label{eq:GP-binary}
	\left[ \frac{1}{3},X_P;\frac{1}{3},B(\hat{r}_\DOLLAR  ; X_\DOLLAR ) ; \frac{1}{3}, B(\hat{r}_P ; X_P)\right]   \textit{and}   \left[ \frac{1}{3},X_\DOLLAR ;\frac{1}{3},B(\hat{r}_\DOLLAR  ; X_\DOLLAR ) ; \frac{1}{3}, B(\hat{r}_P ; X_P) \right]
\end{equation}

\noindent where $B(\hat{r};X)$ is the lottery resulting from the BDM mechanism between the reservation price $\hat{r}$ and either the $X_\DOLLAR $ or $X_P$ lotteries.
As such, we can rewrite the last part of both these compound lotteries as follows:

\begin{equation}
	Z \equiv \left[ \frac{1}{2}, B(\hat(R)_\DOLLAR ;X_\DOLLAR )  ; \frac{1}{2},B(\hat{r}_P ; X_P)  \right]
\end{equation}

\noindent and (\ref{eq:GP-binary}) can be rewritten as

\begin{equation}
	\label{eq:GP-bin-reduced}
	\left( \frac{1}{3}, X_\DOLLAR  ; \frac{2}{3},Z \right) \textit{and} \left( \frac{1}{3},X_P ; \frac{2}{3},Z  \right)
\end{equation}

If independence holds, the subject would only choose the left option if, and only if, she preferred $X_\DOLLAR $ to $X_P$, and vise versa.
Should the independence axiom fail, then this relationship also fails and the subject may choose the left option even if she doesn't prefer $X_\DOLLAR $ to $X_P$.
If such  a choice is made, then the price revealed for the chosen lottery using the BDM mechanism may be lower than the price solicited for the alternative lottery because the impact of such a choice has been diluted by the compound lottery. 

\textcite{Holt1986} offers an explanation for the preference reversal phenomenon, but makes no comment about the asymmetry of the phenomenon, nor does he suggest an alternative theory to EUT other than to state that \enquote{...any theory of rational choice in such contexts must be derived from a set of axioms that does not include or imply the independence axiom...} (1986 p.514) \textcite{Holt1986} does state that since the choices are diluted by compounding the opportunity cost of an apparent preference reversal is very low, thus the asymmetry may not be so interesting.
This point is elaborated on by \textcite{Harrison1989, Harrison1992} and will be discussed later. 

\textcite{Karni1987} also state that the preference reversal phenomenon can be explained by an alternative to EUT which doesn't include the independence axiom.
Differing from \textcite{Holt1986} however, they propose a model which would explain the preference reversal phenomenon which they deem \enquote{Expected Utility with Rank Dependent Utilities} (EURDU).
EURDU requires that  the independence axiom not hold, that the possible outcomes of a given lottery be ranked, the probabilities of each of the outcomes be transformed, and weights of the outcomes generated by these transformed probabilities be dependent on the rank of the outcome.
The first axiomatization of a EURDU model was by \textcite{Quiggin1982}, though it was calle \enquote{Anticipated Utility} at the time, and now is more commonly called \enquote{Rank Dependent Utility} (RDU).
\textcite{Yaari1987} independently proposed a utility theory which required a violation of the independence axiom, a ranking of outcomes and a linear utility function called \enquote{Dual Theory}.

Assuming some discrete lottery, $(x_1,p_1;\ldots;x_n,p_n)$ , that the probabilities associated with the outcomes of the lotteries sum to 1, and that $x_1 \leq x_2 \leq \ldots \leq x_n$, then the following function represents the  EURDU of such a lottery, \textcite{Karni1987}:

\begin{equation}
	\label{eq:KS1987-EURDU}
	V(x_1,p_1; \ldots ; x_n, p_n) = \sum_{i=1}^{n}u(x_i) \left[ f\left( \sum_{j=i}^n p_j\right)  \right]
\end{equation}

The above utility structure combined with the compound lottery structure, necessitated by the lack of the independence axiom and the BDM mechanism, is sufficient to generate utility maximizing choices which appear to be preference reversals. To demonstrate this, \textcite{Karni1987} proposed a simplified version of the BDM mechanism in which a subject must select a selling price, $s$, from the set $\lbrace 1,2,3,4,5\rbrace$, and the experimenter randomly selects an buying price from the set $\lbrace 1,2,3,4,5 \rbrace$ to determine the outcome.
Recall that if the buying price is greater than the selling price, the subject receives the buying price, otherwise she plays out the lottery.
In addition, they proposed the following candidate probability weighting function and utility function :


\begin{align}
	f(p) &= 
	\begin{cases} 
		1.1564 p,     & 0 \leq p \leq 0.1833 \\
		0.9p + 0.047, & 0.1833 \leq p \leq 0.7 \\
		0.5p + 0.327, & 0.7 \leq p \leq 0.98 \\
		p^10,         & 0.98
	\end{cases}\label{eq:KS1987-pw}\\
	u(x) &= 
	\begin{cases} 
		30x + 30,     & x \leq -1 \\
		10x + 10,     & -1 \leq x \leq 12 \\
		6.75x + 49,   & 12 \leq x
	\end{cases}\label{eq:KS1987-ux}
\end{align}

Using two lotteries from the \textcite{Grether1979} experiments ($A$ and $B$ below), they set up the value function:

\begin{equation}
	\label{eq:KS1987-Alot}
	A = ( -1, \frac{1}{36} \,;\, 4, \frac{35}{36}) \quad \textit{and} \quad B=(-1.5, \frac{25}{36} \,;\, 16, \frac{11}{36})
\end{equation}

\begin{align}
	\label{eq:KS1987-VA}
	\begin{split}
		V(A|\Pi(A)) &\equiv V \left( A,\frac{s}{5} \,;\, s+1, \frac{1}{5} \,;\, \ldots \,;\, 5 \frac{1}{5} \right)\\
		            &=      V \left(-1,\frac{s}{5} \times \frac{1}{36} \,;\, 4, \frac{s}{5}\times \frac{35}{36} \,;\, s+1, \frac{1}{5} \,;\, \ldots \,;\, 5,\frac{1}{5}  \right)
	\end{split}
\end{align}

\noindent where lottery $A$ is a $P$ bet, lottery $B$ is a \$ bet, and $\Pi(A)$ returns the selling price of lottery $A$ elicited from the BDM mechanism.
Solving equations (\ref{eq:KS1987-Alot}) and (\ref{eq:KS1987-VA}) for the possible values of $s$ produces the following table from \textcite[679]{Karni1987}:

\begin{table}[ht]
	\centering
	\caption{ \textcite{Karni1987} - Values for Different Choices of $\Pi(k),k = A,B$}
	\label{tb:KS1987:Pi}
	\begin{tabular}{cccc}
		   & $V(A|\Pi(A))$  & $V(B|\Pi(B))$  & Value of $\Pi(k)$      \\\hline
		1  & $40.65 = V(A)$ & $40.38 = V(B)$ & $5 < \Pi(k)$           \\
		2  & 43.06          & 44.42          & $4 \leq \Pi(k) \leq 5$ \\
		3  & 44.53          & $46.66^*$      & $3 \leq \Pi(k) \leq 4$ \\
		4  & $45.25^*$      & 45.06          & $2 \leq \Pi(k) \leq 3$ \\
		5  & 43.70          & 39.61          & $1 \leq \Pi(k) \leq 2$ \\
		6  & 39.48          & 39.48          & $\Pi(k) \leq 1$        \\\hline
		7  & $3.065 = C(A)$ & $3.065 = C(A)$ & $3.038 = C(B)$
	\end{tabular}
\end{table}

In row 1 of Table (\ref{tb:KS1987:Pi}) the conditional values of $A$ and $B$ are equivalent to the unconditional values of $A$ and $B$ because if a subject could have chosen a price greater than $5$ in this example the subject would have played out either $A$ or $B$ with 100\% probability.
The asterisks indicate at which values of $s$ the conditional value of $A$ or $B$ is maximized.
Row 7 indicates the certainty equivalents $A$ and $B$ which are a direct result of the monotonicity of $u(\cdot)$ and by definition $u(C(H)) = V(C(H),1)$ for every $H$ which is an element of the set of lotteries offered. 

From row 1 we can see that the subject prefers lottery $A$ to $B$ and should choose $A$ in the direct lottery choice.
From row 7 we can see that the true certainty equivalent of lottery $A$ is greater than lottery $B$.
From rows 3 and 4 we see that when the subject is asked for a selling price for each lottery she would choose a price between 2 and 3 for lottery $A$, and a price between 3 and 4 for lottery $B$.
The true certainty equivalent of lottery $A$ is out of the range of selling prices which would maximize this subject's utility for this compound lottery, and the utility maximizing selling price for $B$ is greater than that of $A$.
This subject would therefore display a \enquote{preference reversal} by selecting $A$ in the direct comparison and selecting a higher price for $B$ with the BDM mechanism.

Using the penny grid employed in the \textcite{Grether1979} experiments, \textcite[680]{Karni1987} calculated the selling price that would have been elicited from the same subject for lottery $A$ as \money{3.43}, and for lottery $B$ as \money{4.33}.
Because the unconditional values of lottery $A$ and lottery $B$ along with their respective certainty equivalents are the same as in the first row and seventh row of Table (\ref{tb:KS1987:Pi}), these elicited selling prices also display a \enquote{preference reversal}.
The elicited selling prices using this penny grid are also significantly different from the certainty equivalents as calculated in row 7.

In contrast to the critiques of \textcite{Holt1986} and \textcite{Karni1987}, \textcite{Loomes1989} suggest that the apparent preference reversals are in fact violations of transitivity as \textcite[623]{Grether1979} had stated and offer \enquote{Regret Theory} as a potential explanation, which predicts the apparent preference reversal and lacks the transitivity axiom.
Regret Theory was originally and independently developed by \textcite{Loomes1982} and \textcite{Bell1982}, then axiomized by \textcite{Fishburn1987} and modified by \textcite{Loomes1987} to include a \enquote{convexity} axiom to be described below.

Regret Theory assumes that a subject has a \enquote{choiceless} utility function, which is unique up to a linear transformation and assigns a real-valued utility number to every conceivable outcome of an action.
This utility function represents the utility the subject would derive from the outcome of an action if she experienced it without having chosen it \textcite[807]{Loomes1987}.
The\enquote{choiceless} utility of an outcome that would occur in a particular state of the world given an action is compared with the \enquote{choiceless} utility of an outcome that would occur in the same state of the world given another feasible action using a \enquote{modified} utility function:

\begin{equation}
	\label{eq:LS1987:mu}
	m^k_{ij} = M( c_{ij} , c_{kj} )
\end{equation}

\noindent where $M$ is the modified utility function, $c_{ij}$ and $c_{kj}$ are the \enquote{choiceless} utilities of the outcome of actions $i$ and $k$, respectively, in the event that state of the world $j$ occurs, and $m^k_{ij}$ is the resulting modified utility of having chosen action $i$ instead of action $k$.

\textcite[809]{Loomes1987} assume that the degree of regret only depends on the difference in  he \enquote{choiceless} utilities which would occur in the same state of the world but given different actions.
Thus (\ref{eq:LS1987:mu}) can be re-written as follows:

\begin{equation}
	\label{eq:LS1987:mu2}
	m^k_{ij} = c_{ij} + R(c_{ij} - c_{kj})
\end{equation}

\noindent where $R(\cdot)$ is a \enquote{regret-rejoice} function. 
A subject would select an action which has the greatest expected modified utility; the sum of the probability weighted modified utilities across all potential states of the world.
Keeping with the notation of \textcite{Loomes1989}, $m^k_{ij}$ will be rewritten as $\psi(x_{ij}, x_{kj})$, where $x_{ij}$ and $x_{kj}$ are the outcomes of actions $i$ and $k$, respectively, should state of the world $j$ occur.
Thus $\psi(\cdot)$ incorporates the transformation of the outcomes into \enquote{choiceless} utilities, and those \enquote{choiceless} utilities into the modified utilities.

\begin{equation}
	\label{eq:LSS1989:mu3}
	A_i \succcurlyeq  A_k \Leftrightarrow \sum_{j} p_j \, \psi ( x_{ij} , x_{kj} ) \geq  0
\end{equation}

\noindent where $A_i$ and $A_k$ are actions $i$ and $k$, respectively.
Two important assumptions are made about $\psi(\cdot)$: first, $\psi(\cdot)$ is skew-symmetric, i.e. $\psi(x_{ij},x_{kj}) = -\psi(x_{ij},x_{kj})$, and second it is convex, i.e. if $x_3 > x_2 > x_1$, then $\phi(x_3,x_1) > \psi(x_3,x_2) + \psi(x_2,x_1)$.
This convexity allows subjects to be \enquote{regret} averse and is the basis for the prediction of the preference reversal phenomenon.

Using this notation, \textcite{Loomes1989} denote the $P$ bets and \$ bets as actions, and modify the choice of a selling price for the BDM mechanism as a binary choice between an action which returns a constant amount of money for certain, $C$, and either the $P$ bet or the \$ bet.

Table 4 -  \textcite{Loomes1989}
\begin{table}[ht]
	\centering
	\caption{ \textcite{Loomes1989} \\ Actions, States, and Outcomes }
	\label{tb:LSS1989:ASO}
	\begin{tabular}{ccccc}
		\multirow{2}{*}{Action} & $S_1$ & $S_2$ & $S_3$ & $S_4$ \\[-.75em]
		                        & $p_1$ & $p_2$ & $p_3$ & $p_4$ \\\hline
		                    \$  &   a   &   a   &   d   &   d   \\
		                    P   &   b   &   e   &   b   &   e   \\
		                    C   &   c   &   c   &   c   &   c   
	\end{tabular}
\end{table}

\noindent where the columns represent 4 states of the world, $S_1 , \ldots , S_4$, with associated probabilities $p_1, \ldots, p_2$, and the rows represent the different actions, \$ bet, $P$ bet, and a certainty $C$, with potential outcomes $a,b,c,d$ and $e$ such that $a > b > c > d,e$.
If $p_1 + p_3 > 0.5 > p_1 + p_2$ then the first 2 rows correspond to the \$ bet and $P$ bet from \textcite{Grether1979}.
These actions can be made into 3 pairwise choices, $\lbrace P , \$ \rbrace , \lbrace P,C \rbrace , \lbrace \$, C \rbrace$, called a \enquote{triple}.
Applying the formula from (\ref{eq:LSS1989:mu3}) to the outcomes and probabilities of Table (\ref{tb:LSS1989:ASO}) generates the following preference relations:

\begin{align}
	P  \succcurlyeq \$ &\Leftrightarrow p_1 \psi(b,a) + p_2 \psi(e,a) + p_3 \psi(b,d) + p_4 \psi(e,d) \geq 0 \label{eq:LSS1989:PD}\\
	\$ \succcurlyeq C  &\Leftrightarrow p_1 \psi(a,c) + p_2 \psi(a,c) + p_3 \psi(d,c) + p_4 \psi(d,c) \geq 0 \label{eq:LSS1989:DC}\\
	C  \succcurlyeq P  &\Leftrightarrow p_1 \psi(c,b) + p_2 \psi(c,e) + p_3 \psi(c,b) + p_4 \psi(c,e) \geq 0 \label{eq:LSS1989:CP}
\end{align}

In the above pairwise choices, the most common preference reversal phenomenon of the \textcite{Grether1979} experiments is observed if the $P$ bet is chosen over the \$ bet, the \$ bet chosen over the $C$ money certainty, and the $C$ money certainty chosen over the $P$ bet.
The less common preference reversal is observed if the \$ bet is chosen over the $P$ bet, the $P$ bet is chosen over the $C$ money certainty, and the $C$ money certainty is chosen over the \$ bet.
The first of these two preference reversals is predicted by Regret Theory when $p_2 =0$ and $d \geq e$ in equations (\ref{eq:LSS1989:PD}), (\ref{eq:LSS1989:DC}), and (\ref{eq:LSS1989:CP}), while the second one is not.
\textcite[143]{Loomes1989} call the first of these preference reversals the \enquote{predicted} preference reversal, and the second the \enquote{unpredicted} preference reversal.

\textcite{Loomes1989} design three experiments to test whether subjects who display the preference reversal phenomenon may follow Regret Theory instead of EUT by utilizing the special case of $p_2 = 2$ and $d \geq e$.
The first two experiments confront subjects with different sets of triples, called the \enquote{choice-only} design, while the third experiment had some subjects face the BDM mechanism to elicit selling prices for each lottery as in \textcite{Grether1979}, called the \enquote{standard} design, and some subjects use the \enquote{choice-only} design.
\textcite[142]{Loomes1989} state that their null hypothesis is that subjects make choices in accordance with EUT but make mistakes randomly such that there should be an equal proportion of subjects who display the \enquote{predicted} preference reversal and subjects who display the \enquote{unpredicted} preference reversal for any given triple.
They state that they will reject this EUT null hypothesis in favor of the alternative of Regret Theory if the frequency of subjects displaying the \enquote{predicted} preference reversal is significantly higher than subjects displaying the \enquote{unpredicted} preference reversal to an extent that can't be attributed to chance.

Experiment 1 had 283 subjects, 120 of which also participated in Experiment 2 which was held a few days later and had some chance of loosing money.
Experiment 3 had 186 subjects.
All subjects we randomly assigned to different subsamples, with each subsample assigned to a unique set of triples.
An equal number of subjects were assigned to the \enquote{choice-only} and \enquote{standard} designs in Experiment 3, and the responses from the group that participated in the \enquote{standard} design were imputed into choices as if they had conducted the \enquote{choice-only} design.
The bets used in the pairwise comparisons are presented in Table (\ref{tb:LSS1989:Bets}) below:

\break
\begin{table}[ht]
	\centering
	\caption{ \textcite{Loomes1989} \\ Bets Used in Three Experiments }
	\label{tb:LSS1989:Bets}
	\begin{tabular}{cc}
		        \$ bets                    &         P bets\\\hline
		$\$_1$ = (12.00, 0.4 \,;\, 0, 0.6) & $P_1$  = (8.00, 0.6 \,;\, 0, 0.4) \\
 		$\$_1$ = (12.00, 0.4 \,;\, 0, 0.6) & $P_1$  = (8.00, 0.6 \,;\, 0, 0.4) \\
 		$\$_1$ = (12.00, 0.4 \,;\, 0, 0.6) & $P_1$  = (8.00, 0.6 \,;\, 0, 0.4) \\
 		$\$_1$ = (12.00, 0.4 \,;\, 0, 0.6) & $P_1$  = (8.00, 0.6 \,;\, 0, 0.4) \\
 		$\$_1$ = (12.00, 0.4 \,;\, 0, 0.6) & $P_1$  = (8.00, 0.6 \,;\, 0, 0.4) 
	\end{tabular}
\end{table}

The subjects in Experiment 1 were split into 4 subsamples, $A$, $B$, $C$, and $D$, each of which made pairwise choices across one triple, $(\$_1,P_1,C)$, where $C$ varied for each subsample as shown in Table (\ref{tb:LSS1989:Exp12}) below.
The subjects in Experiment 2 were split into 2 subsamples, $E$ and $F$, each of which faced 4 triples, with each triple containing the $\$_2$ bet and either the $P_2$ bet or $P_3$ bet and unique values of $C$ for each triple.
The subsamples for Experiment 2 differed only by the values of $C$ in their triples.
This is also shown in Table (\ref{tb:LSS1989:Exp12}) below along with the number of subjects who responded with particular patterns of choice for each triple:

\break
\begin{table}[h]
	\centering
	\caption{ \textcite{Loomes1989} \\ Results of Experiments 1 \& 2 }
	\label{tb:LSS1989:Exp12}
	\begin{tabularx}{\textwidth}{cccYYYYYYYY}
                        &           &     & \multicolumn{8}{c}{Pattern of choice}               \\\cmidrule{4-11}
			            &           &     & \$ & \$ & \$ & $\$\dagger$ &  $P^*$ &  P &  P  & P  \\[-.5em]
			            &           &     & \$ & \$ &  C & $ C\dagger$ & $\$^*$ & \$ &  C  & C  \\[-.5em]
		Triple          & Subsample &   n &  C &  P &  C & $ P\dagger$ &  $C^*$ &  P &  C  & P  \\\hline
                        &           &     & \multicolumn{8}{c}{Experiment 1}                    \\
		$\$_t,P_t,2.50$ &         A &  71 &  2 &  9 &  1 &           1 &      3 & 27 &  19 & 9  \\
		$\$_t,P_t,2.50$ &         B &  70 &  1 &  4 &  1 &           2 &     12 & 15 &  32 & 3  \\
		$\$_t,P_t,2.50$ &         C &  72 &  1 &  4 &  4 &           0 &      7 &  6 &  44 & 6  \\
		$\$_t,P_t,2.50$ &         D &  70 &  5 &  4 &  4 &           0 &      4 &  4 &  50 & 2  \\
		Total           &           & 283 &  9 & 21 & 10 &           3 &     26 & 40 & 145 & 20 \\
                        &           &     & \multicolumn{8}{c}{Experiment 2}                    \\
		$\$_2,P_2,2.50$ &         E &  60 & 14 & 17 &  3 &           1 &      7 &  8 &   8 & 2  \\
		$\$_2,P_2,2.50$ &         E &  60 & 17 &  8 & 10 &           0 &      8 &  4 &  13 & 0  \\
		$\$_2,P_3,2.50$ &         E &  60 &  7 & 22 &  0 &           1 &      2 & 15 &   9 & 4  \\
		$\$_2,P_3,2.50$ &         E &  60 &  7 & 18 &  3 &           2 &      7 &  5 &  14 & 4  \\
		$\$_2,P_2,2.50$ &         F &  60 & 19 & 11 &  3 &           2 &     11 &  1 &   9 & 4  \\
		$\$_2,P_2,2.50$ &         F &  60 & 20 &  3 & 11 &           1 &      6 &  0 &  18 & 1  \\
		$\$_2,P_3,2.50$ &         F &  60 &  9 & 21 &  2 &           1 &      2 & 10 &   7 & 8  \\
		$\$_2,P_3,2.50$ &         F &  60 & 17 &  5 &  7 &           4 &      6 &  1 &  14 & 6  \\\bottomrule
                   \multicolumn{11}{r}{* indicates the \enquote{predicted} preference reversal} \\[-.5em]
         \multicolumn{11}{r}{$\dagger$ indicates the \enquote{unpredicted} preference reversal} \\

	\end{tabularx}
\end{table}

The subjects in Experiment 3 were split into 6 subsamples, $G_1,H_1,I_1$ for the \enquote{standard} design and $G_2,H_2,I_2$ for the \enquote{choice-only} design.
Each subsample of the same letter designation faced the same \$ bet and $P$ bet, and after imputing the elicited selling prices from the \enquote{standard} design subsamples into a choice of $C$, all subsamples of Experiment 3 faced the same value of $C$.
The purpose of imputing these choices was to provide a direct comparison of the \enquote{standard} design and the  \enquote{choice-only} design.
The number of subjects who displayed each possible choice pattern for Experiment 3 is shown in Table 7 below.
Some subjects in the \enquote{standard} design reported a selling price for a bet which was greater than the largest possible outcome of the bet, or smaller than the smallest possible outcome of the bet.
The number of subjects who did not display this \enquote{perverse} behavior in the \enquote{standard} design is reported in parenthesis next to the total number of subjects displaying a particular choice pattern in Table 7 below.

\begin{table}[!h]
	\caption{ \textcite{Loomes1989}\\Results of Experiment 3}
	\begin{tabularx}{\textwidth}{YYYYYYYYY}
			            &           &     & $\$ \succ_c P$ & $\$ \succ_c P$ & $\$ \succ_c P$ &  $\$ \succ_c P$ & $\$ \succ_c P$ & $\$ \succ_c P$ \\[-.5em]
		        Actions & Subsample &   n & $\$ \succ_c P$ & $\$ \succ_c P$ & $\$ \succ_c P$ &  $\$ \succ_c P$ & $\$ \succ_c P$ & $\$ \succ_c P$ \\\hline
                                                                    \multicolumn{9}{r}{Group 1 \enquote{Standard} Design: Choice and Valuations} \\
            $\$_3, P_4$ &     $G_1$ &  31 &           4(3) &           0(0) &           5(2) &          11(11) &           3(3) &           8(6) \\
            $\$_4, P_5$ &     $H_1$ &  31 &         14(11) &           1(1) &           5(1) &            6(6) &           2(1) &           3(2) \\
            $\$_5, P_6$ &     $I_1$ &  31 &          10(9) &           2(1) &           5(4) &          11(10) &           0(0) &           3(3) \\
                        &     Total &  93 &         28(23) &           3(2) &          15(7) &          28(25) &           5(4) &         14(11) \\\hline
	\end{tabularx}
	\begin{tabularx}{\textwidth}{cccYYYYYYYY}
                        &           &     & \multicolumn{8}{c}{Pattern of choice}                         \\\cmidrule{4-11}
			            &           &     & \$ & \$  & \$   & $\$\dagger$ &  $P^*$ &  P    &  P    & P    \\[-.5em]
			            &           &     & \$ & \$  &  C   & $ C\dagger$ & $\$^*$ & \$    &  C    & C    \\[-.5em]
		Triple          & Subsample &   n &  C &  P  &  C   & $ P\dagger$ &  $C^*$ &  P    &  C    & P    \\\hline
		\multicolumn{11}{r}{Group 1 \enquote{Standard} Design: Imputed Choice and Valuations}             \\
		$\$_3,P_4,4.5$  &     $G_1$ &  31 &  1 &   1 &    5 &           1 &   2.75 &  6.75 & 10.25 & 2.25 \\
		$\$_4,P_5,4.5$  &     $H_1$ &  31 &  4 & 4.5 & 10.5 &           1 &      3 &     2 &     5 & 1    \\
		$\$_5,P_6,4.5$  &     $I_1$ &  31 &  4 & 3.5 &  6.5 &           3 &      6 &   2.5 &     5 & 0.5  \\
		Total           &           &  93 &  9 &   9 &   22 &           6 &  11.75 & 11.25 & 20.25 & 3.75 \\
		\multicolumn{11}{r}{Group 2 \enquote{Choice-Only} Design: Imputed Choice and Valuations}          \\
		$\$_3,P_4,4.5$  &     $G_2$ &  31 &  2 &   0 &    4 &           0 &      4 &     2 &    12 & 7    \\
		$\$_4,P_5,4.5$  &     $H_2$ &  31 & 10 &   2 &    3 &           3 &      6 &     1 &     6 & 0    \\
		$\$_5,P_6,4.5$  &     $I_2$ &  31 &  3 &   5 &    8 &           1 &      4 &     1 &     8 & 1    \\
		Total           &           &  93 & 15 &   7 &   15 &           4 &     14 &     4 &    26 & 8    \\\bottomrule
							 \multicolumn{11}{r}{* indicates the \enquote{predicted} preference reversal} \\[-.5em]
                   \multicolumn{11}{r}{$\dagger$ indicates the \enquote{unpredicted} preference reversal} \\
	\end{tabularx}
\end{table}

\noindent where $r_\DOLLAR $ and $r_P$ are the elicited selling prices for the \$ bet and $P$ bet, respectively, and $\succ_c$ stands for \enquote{chosen over}.

In every experiment and across every subsample there were statistically significantly more subjects displaying the \enquote{predicted} preference reversal than displaying the \enquote{unpredicted} preference reversal, leading \textcite{Loomes1989} to reject the null hypothesis of EUT in favor of the alternative of Regret Theory for every experiment.

Regret Theory is unique in it's explanation of the preference reversal phenomenon in that, unlike the alternative proposed by \textcite{Karni1987}, Regret Theory predicts both the preference reversal phenomenon's existence as well as the asymmetrical distribution between the two possible patterns of preference reversal. 


\section{Necessary Precepts for Valid Inferences from Economic Experiments, and the Violation of these Precepts}

\textcite{Smith1982} lays out a conceptual framework for modeling microeconomic systems, such as an economic experiment, in terms of an interactive relationship between an environment, an institution, and agent behavior.
In this framework agents send messages to the institution which then maps those messages according to pre-set rules into commodity outcomes.
This framework provides the valuable insight that \enquote{\textelp{} agents do not choose direct commodity allocations.
\textit{Agents choose messages, and institutions determine allocations via the rules that carry messages into allocation}} [emphasis in the original]\parencite[926]{Smith1982}.
Thus the data which we observe from an experiment is derived from message producing behavior which is said to be a function of the environment for that agent and the institution.
This mapping of messages into allocations does provide the experimenter with valuable information, but only if four sufficient conditions are met for a controlled microeconomic experiment as discussed in \textcite{Smith1982} and \textcite{Harrison1989}.

\subsection{Salience and Potential Violations}

Of the four sufficient conditions proposed by \textcite{Smith1982}, the first, non-satiation, is equivalent to the common requirement of most theories of utility that there exists a reward mechanism such that the subject should not be satiated in it, and should be interpreted in the same way.
The second and third are of primary importance in an experiment attempting to elicit what Smith refers to as \enquote{home-grown} preferences; preferences that are not induced by the experimenter in a laboratory, but instead are the subject's own latent preferences from outside the laboratory.


The second sufficient condition is Saliency.
\textcite[931]{Smith1982} defines this as the condition in which\enquote{Individuals are guaranteed the right to claim a reward which is increasing (decreasing) in the goods (bads) outcomes, $x_i$, of an experiment.}
\textcite[223]{Harrison1994} notes that the above definition combined with the non-satiation requirement leads to a mapping of a message $m'$ to a reward $v'$ instead of $m''$ that maps into $v''$, whenever $v' > v''$.
This has also been interpreted by \textcite{Bruner2011} to mean that the manner in which messages are mapped to rewards by the institution is understood by the subject, even if it is stochastic, otherwise there exists an institutional failure to induce values.
In the syntax of \textcite{Smith1982}:
\begin{equation}
	\label{eq:S1982:I}
	I^i = \left(M^i,h^i(m),c^i(m),g^i(t_0,t,T) \right) \equiv I^i_p = \left(M^i_p, h^i_p(m) ,c^i_p(m), g^i_p(t_0,t,T) \right)
\end{equation}

\noindent where $I$ represents the property rights of agent $i$, and the subscript $p$ on the right side of the equality indicates the perceived property rights of agent $i$.
$M$ represents the language imposed by the institution, i.e. the set of all messages that can be sent, $h$ represents the process which maps messages to rewards, $c$ represents the processes which maps messages to costs, and $g$ is the governing process which indicates at which point events, including the elicitation of messages, will occur from the beginning of the experiment, $t0$, to the end of the experiment, $T$. 

Should any of the elements of $I_p^i$ not be equivalent to their corresponding element in $I^i$, subjects may believe that they are guaranteed the right to claim a reward which differs from the reward that will be granted by the institution given their message.
Or in the \textcite{Harrison1994} definition, it could lead to a message $m''$ mapping to $v''$ when $v' > v''$ due to the subject believing that $m''$ maps to $v'$ or that $v'' > v'$.

An example of this apparent mis-mapping of messages and rewards could be that a simple lack of understanding by the agents about their own property rights leads to a lack of salience.
The degree to which the equivalence of equation (\ref{eq:S1982:I}) holds could depend on both the complexity of the property right endowment and the ability of the agent to comprehend her own endowment.
Various tax incentives, for instance, endow a proportion of a population with potentially large savings via a tax credit or deduction conditional on citizens behaving in a certain way.
However, these incentives may be too complex to comprehend and thus do not motivate citizens to make the choices that the policy intended even if the citizens would otherwise be willing.

A more complex way in which the equivalence of equation (\ref{eq:S1982:I}) would fail is a fundamental mistrust of the experimenter.
That is, the subject may fully understand the institution's communication of the  elements of the property right endowment, but doesn't believe that the institution will uphold these rights.
This in a way alludes to one of the experimental theories proposed by \textcite[629]{Grether1979}, that a potential cause of preference reversals in experiments conducted by psychologists was that subjects were in experiments conducted by psychologists: 
\enquote{Subjects nearly always speculate about the purposes of experiments and psychologists have the reputation for deceiving subjects.
It is also well known that subjects' choices are often influenced by what they perceive to be the purpose of the experiment.} 

Economic experiments designed to incentivize subjects to reveal their preferences generally rely on the assumption that the subject views the experimenter to be indifferent to the outcome of the experiment.
\textcite{Schneeweiss1973} explores this view as a alternative explanation of the \textcite{Ellsberg1961} paradox critique of the axioms of \textcite{Savage1954}.
The subjects of the \textcite{Ellsberg1961} experiments, rather than adopting different preferences for events which were \enquote{ambiguous} as opposed to simply uncertain, could view the experiment as a zero-sum two-person game between the experimenter and themselves.
\textcite{Schneeweiss1973} shows that if the subjects assume that the experimenter strategically wants to minimize the expected payout to subjects, the seemingly paradoxical behavior of the subjects can be explained as game theoretic optimal choice behavior.

\textcite{Kadane1992} also notes that if subjects in experiments are skeptical of the intentions of the experimenter, then the seemingly paradoxical behavior described in \textcite{Ellsberg1961} and \textcite{Allais1953} can be explained as a rational response to the possibility of being cheated.
It can be shown that should the agent assign any positive probability to the possibility of the experimenter selecting an outcome that would lead to the lowest expected payout given the subject's choice, both paradoxes fail to violate the axioms of \textcite{Savage1954}.

Though both the above examples require subjects to assume a profit maximizing experimenter, an agent does not need to believe the experimenter has selfish interests for there to be a disconnect between the property rights, as perceived by the agent, and the property rights intended to be induced by the institution.
\textcite[178]{Harrison2006} note that in experiments attempting to describe behavior\enquote{variously labeled \enquote{cooperation,} \enquote{altruism,} \enquote{reciprocity} or \enquote{confusion}}, the experimental methods used are often confounded by the manner in which the experimenter deals with the \enquote{residual} money left on the table after the experiment is over.
If subjects incorporate the residual claimant into their preference structure, subjects displaying \enquote{altruistic} behavior may in fact be attempting to manipulate the residual to the claimant.

In the bulk of these kinds of experiments the experimenter is the implied residual claimant, though not always.
\textcite{Harrison2006} conducted an experiment utilizing the popular \enquote{Dictator} game with four treatments which allowed for variation in both the \enquote{peasant} (the recipient of the money from the Dictator) and in the recipient of the residual funds.
In treatment \enquote{O}, the \enquote{peasant} was another subject paired with the Dictator, and in treatment \enquote{C}, the \enquote{peasant} was an unspecified charity.
In both treatments O and C the residual claimant was implied to be the experimenter (nothing specific was said about the recipient of the residual funds in the instructions to the subjects).
In the \enquote{O(C)} treatment, the \enquote{peasant} was another subject paired with the Dictator with the residual going to an unspecified charity, while in the \enquote{C(O)} treatment the \enquote{peasant} was an unspecified charity with the residual going to another subject randomly selected at the end of the experiment.

\textcite[196]{Harrison2006} find greater giving to the\enquote{peasant} in the C treatment compared to the O treatment, a greater giving to the \enquote{peasant} in the C(O) treatment compared to the C treatment, and a reduction in giving to the \enquote{peasant} in the O(C) treatment compared to the O treatment.
Each of these differences was statistically different from zero.
These results imply that the subjects in this experiment preferred money from the experiment to go to a charity more than to the experimenter, and preferred the money to go to the experimenter more than to the other subjects.
The primary importance of this study is to demonstrate that subjects may incorporate the residual claimant of funds of an experiment into their utility functions. 

Generally, if an agent views any \enquote{third party} (be this the experimenter, a charity, or even Nature) as another agent in the system, while the experimenter views this \enquote{third party} as being outside of the economic system, this could conceivably cause any element in $I^i_p$ to differ from its corresponding element in $I^i$.
Most apparent however is the potential for $h_i(m) \neq h_i^p(m)$.

Though the above examples require the agent to view the set of agents in a system differently than the experimenter views the set of agents, this isn't necessary for the agent to believe the institution will not uphold the agent's property right as endowed.
For instance, the agent may believe she has superior knowledge of the mechanism which maps messages to rewards thus causing $h_i(m) \neq h_i^p(m)$.
In many experiments, subjects are asked to make a choice between lotteries, with their chosen lottery being played out for a real reward.
The mechanism used to select the outcome of a lottery is almost always some physical device, such as a coin flip, a dice roll, or a bingo cage, the physics of which may be well known by the subject to result in certain outcomes with different likelihoods than the institution suggests; the outcome of flipping a US quarter is not precisely a 50/50 gamble between heads and tails for instance.
In this instance, the choice between lotteries is the message, the outcome of the lottery is the reward, and the mechanism which selects the outcome of the lottery selected is the mechanism which maps the message to the reward.
Asymmetrical beliefs about the reward mechanism can lead to a failure to induce salience as $h_i(m) \neq h_i^p(m)$.

Should either the subject or the experimenter not understand the other or should the subject mistrust  the institution, there can be a failure of salience.
However, the latter can be said to be the result of a certain preference structure{\footnotemark}, while the former is usually an experimental artifact.
The institution could fail to properly communicate the endowed property rights, there could be a lack of technical ability on behalf of the subject to comprehend her property rights as endowed, or the actual institutional endowment could be misspecified by the experimenter when observing messages, for instance, by ignoring an agent's perception of additional agents.

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	For instance, the greater the potential loss to the experimenter (or gain to the agent), the more the agent may prefer to discount fortuitous events and overweight bad events.
	This could be interpreted as mistrust being a determinant of the probability weighting function in Rank Dependent Utility Theory.	
}


Both misunderstanding and mistrust could potentially affect the  messaging behavior of subjects in an experiment.
In the syntax of \textcite{Smith1982}, the degree of (mis)understanding could be reflected by the technology element, $T^i$, of equation (\ref{eq:S1982:e}) below, while mistrust would be reflected in the utility element, $u^i$, of equation (\ref{eq:S1982:e}) below.
Both elements ultimately shape the behavioral process which determines messages, defined in equation (\ref{eq:S1982:m}):

\begin{align}
	e^i &= (u^i, T^i, \omega^i)\label{eq:S1982:e}\\
	m^i &\simeq \beta^i(e^i|I)\label{eq:S1982:m}
\end{align}

In equations (\ref{eq:S1982:e}) and (\ref{eq:S1982:m}), $e^i$ is called the environment of agent $i$ which is determined by the agents utility structure, $u^i$, technology endowment, $T^i$, and wealth endowment, $\omega^i$.
An agent's behavior, $\beta^i$, then maps the subject's environment conditional on the institutionally granted property right, $I$, to the message space, $m^i$.
It is this message space which is observed by the institution and ultimately mapped to a reward.

These two ideas are of course not the only ways in which salience could be experimentally violated.
A much used experimental method is that of asking subjects for responses to hypothetical questions.
There is a general disagreement, even a \enquote{gentle aggression}{\footnotemark}, between experimental economists and experimental psychologists about the use of hypothetical rewards and whether a subject's intrinsic motivation to complete a task proficiently is sufficient to produce a salient mapping of messages to  rewards in an experiment.
\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	The view of \textcite{Hertwig2001} concerning the methodological critique by \textcite{Smith1982} of both experimental economics and experimental psychology.	
}

\textcite[624]{Grether1979} state their case against the use of hypothetical rewards in exploring economic theor:
\enquote{No attempt is made to expand the theory to cover choices from options which yield consequences of no importance.\textelp{} Thus the results of experiments where subjects may be bored, playing games, or otherwise not motivated, present no immediate challenges to theory.} 
This is later discussed specifically in the context of using of imaginary money as a means to provide salience.

\textcite[31]{Camerer1999} note that from 1970-97 not a single experimental study was published in the \textit{American Economic Review} in which all subjects face only hypothetical rewards, indicating that economists are typically hostile to the idea of intrinsic motivation being sufficient to produce saliency.
\textcite{Camerer1999} show in their analysis of a non-random sample of the experimental literature that increasing financial incentives from zero to positive but low stakes typically improves performance over some domain of experimental tasks, in particular tasks which are effort-responsive like judgment, problem-solving, or clerical tasks, but they find that increasing stakes from some low level to a relatively higher level does little to improve performance and sometimes hinders it.
With respect to tasks for which there is no normative level of performance to be measured, such as games, auctions or choices between risky lotteries as in the \textcite{Grether1979} experiments, \textcite[34]{Camerer1999} state tha\enquote{the most typical result is that incentives do not affect mean performance, but incentives often reduce variance in responses.}
A reduction of variance in responses could lead to a reduction in apparent violations of EUT such as the preference reversals of \textcite{Grether1979}.

\textcite[8]{Camerer1999} state however, that \enquote{The extreme positions, that \textins{material} incentives make no difference at all, or always eliminate persistent irrationalities, are false.}, and in no uncertain terms state \enquote{\textit{There is no replicated study in which a theory of rational choice was rejected at low stakes in favor or of a well-specified behavioral alternative, and accepted at high stakes} \textelp{} and nothing in any sensible understanding of human psychology suggests that it would [be].} [emphasis in the original], \parencite*[33-34]{Camerer1999}.
This echoes earlier statements by \textcite[246]{Smith1993} that \enquote{\textelp{} rewards matter, and that neither of the polar views - only reward matters, or reward does not matter - are sustainable across the range of experimental economics} and that this view is \enquote{common sense}.

Should a subject have no intrinsic motivation to respond to a task but values money, the introduction of monetary rewards for responses can potentially induce saliency by changing the mapping of messages from non-valued hypothetical rewards to valued monetary rewards.
If a subject does have some degree of intrinsic motivation to respond to a task \enquote{correctly} but also values money, the introduction of monetary rewards for responses can potentially make the gross reward of sending a certain message \enquote{dominate} the subjective costs of sending that message when intrinsic motivation alone wouldn't have sufficed.

\subsection{Dominance and Potential Violations}

Dominance is the third necessary precept of conducting a valid experiment proposed by \textcite{Smith1982} and elaborated on b \textcite{Harrison1989, Harrison1992}.
\textcite[934]{Smith1982} defines dominance as selecting rewards such th \enquote{The reward structure dominates any subjective costs (or values) associated with participation in the activities of an experiment.}
\textcite[1426]{Harrison1992} refines this definition and states that dominanc \enquote{requires that the reward of sending a message corresponding to a null hypothesis be \enquote{perceptibly and motivationally greater} than the reward of sending an alternative hypothesis.}

If the messages corresponding to the null and alternative hypotheses are $m_0$ and $m_a$, respectively, then dominance requires that the values associated with sending each of these messages, $v_0$ and $v_a$ respectively, be such that $v_0 > v+a + \delta$, where $\delta$ is the subjective cost to the agent of sending message $m_0$ instead of message $m_a$ \parencite[1427]{Harrison1992}.
This concept is illustrated in Figure (\ref{fig:H1992:Dom-a}) below from \textcite[1427]{Harrison1992}:

\begin{figure}[h!]
	\centering
	\caption{ \textcite{Harrison1992} }
	\label{fig:H1992:Dom}
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=\linewidth]{H1992-a.png}
		\caption{}
		\label{fig:H1992:Dom-a}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=\linewidth]{H1992-b.png}
		\caption{}
		\label{fig:H1992:Dom-b}
	\end{subfigure}
\end{figure}


The potential experiments in Figure (\ref{fig:H1992:Dom-a}) have been constructed such that the value to the subject of sending the message corresponding to the null hypothesis is equivalent for both experiments.
However, only Experiment B has a value associated with sending the alternative hypothesis that is less than $v_0 - \delta$.
Thus only Experiment B satisfies dominance for this particular set of null and alternative hypotheses.

The difference between salience and dominance in the reward medium is obvious in this example: the subject does in fact value the medium and is not satiated in the medium that is being returned to her for sending messages $m_0$ and $m_a$ in both experiments, satisfying salience.
But, only in Experiment B is there a sufficient difference in her valuation of the reward medium from sending $m_0$ instead of $m_a$ for her to send the message $m_0$ instead of $m_a$.

It is easy to extend this idea to a scenario in which one or more composite alternative hypotheses are being tested against a single point-null hypothesis.
In this case there exists a set of messages \enquote{close} to $m_0$, $\overbar{m}$, which provide rewards that are not sufficiently different from $v_0$ to warrant sending $m_0$.
Similarly there will be a set of messages \enquote{far} enough from $m_0$, $\hat{m}$, such that the value of sending any of these messages is sufficiently different from  that the subject would be motivated to send messages from the set of  instead of .
This can be seen in of Figure (\ref{fig:H1992:Dom-b}) from \textcite{Harrison1992} above.

There is no reason to believe that $\delta$ shouldn't vary from subject to subject or from task to task.
Looking at Figure (\ref{fig:H1992:Dom-a}), Experiment B clearly satisfies dominance for the subject in question and the task requiring the sending of either  or , but a different subject might have a larger subjective cost of sending  instead of  making  and causing a failure of dominance.
Looking at Figure (\ref{fig:H1992:Dom-b}), the set of messages in  correspond to those messages which provide rewards which are valued sufficiently differently from  to dominate the subjective cost of sending message ,but it cannot be said that any message in  satisfies dominance for any message in .


\textcite{Harrison1989} argues that if message $m_0$ is the optimal choice for a subject conforming to EUT in a particular experiment, an observance of the choice of $m_a$ is only relevant as a critique of EUT if dominance is satisfied for that task.
\textcite{Harrison1994} replicated the experiments of\textcite{Grether1979} with only minor differences and observed roughly the same proportion of subjects displaying the apparent preference reversal phenomenon.
However, assuming the subject correctly reported their direct preference for either the $P$ bet of the \$ bet, but mis-reported their true selling price with the BDM mechanism, the difference in expected income for a subject of displaying a preference reversal versus the expected income if they have reported a consistent selling price averaged only \money{0.006}. 
For such a small value of $v_0 - v_a$ \enquote{one must nihilistically insist that subjects have a sufficiently low threshold $\delta$, perhaps even claiming $\delta = 0$, in order to conclude that such observations allow one to reject the null hypothesis}\parencite[1428]{Harrison1992}.
\textcite[237]{Harrison1994} concludes\enquote{that the subjects in these preference reversal experiments had virtually no incentive to behave any more consistently than they did.}

\section{\texorpdfstring{\textcite{Holt2002}}{Holt \& Laury (2002)} Multiple Price List and Apparent Inconsistencies}

The preference reversal phenomenon of \textcite{Grether1979} is not the only instance of apparent violations of EUT to be replicated by experimentalists.
The \textcite{Ellsberg1961} paradox is a famous early example, as well as repeated over-bidding with respect to the Nash predicted bids in laboratory auctions by \textcite{Cox1982}, \textcite{Cox1983, Cox1983a, Cox1988}.


\textcite[160]{Cox1985} and \textcite[749]{Harrison1989} both note that this overbidding behavior is consistent with risk-averse subjects, but that the bid deviations are too heterogeneous to be consistent with subjects who are uniformly risk-averse.
\textcite{Cox1985} conduct an experiment which attempts to test for heterogeneous risk preferences of subjects and conclude that their experiments provide \enquote{evidence against the compound lottery axiom of EUT} \parencite[165]{Cox1985}.
\textcite{Harrison1989}, though accepting that deviations in bids from Nash predicted outcomes could be caused by risk-averse subjects, argues that the experiments performed did not meet the dominance criteria for a valid experiment.
Thus, the (empirical) question of the degree of heterogeneity in risk preferences among subjects and its influence on bidding behavior.


\textcite[1291]{Hey1994} note that the \enquote{experimentally observed violations of expected utility theory (EUT) have stimulated a deluge of generalized preference functions, almost all containing  EUT as a special case.}
\textcite{Hey1994} conduct a series of experiments on 80 subjects requiring the subjects to state their preference for one lottery across each of 100 lottery pairs to test if subjects conform to EUT (or the \enquote{Dual Theory} of \textcite{Yaari1987}) in favor of risk-neutrality, and whether subjects conform to any of 8 various generalizations of EUT in favor of EUT.
They report substantial evidence against risk-neutrality, and it is clear from their dataset that there is a great deal of heterogeneity in subjects deviating from risk neutrality.
\textcite[1322]{Hey1994} state tha \enquote{we are tempted to conclude by saying that our study indicates that behavior can be reasonably well modeled \textelp{} as \enquote{EU plus noise.}} 

\textcite[1644]{Holt2002} note that bidding behavior in auctions can be used to elicit risk attitudes and that the over-bidding with respect to the Nash predicted outcomes had been attributed to risk aversion.
They propose using a multiple price list (MPL) as a tool for experimentalist to control for individual heterogeneity in risk preferences and conduct an experiment to test whether the extent of risk aversion in subjects is dependent on the stakes of the tasks the subjects are presented.

 
The MPL has been widely used to elicit \enquote{homegrown} preferences for risk for several decades.
The earliest use of the MPL method is considered to be \textcite{Miller1969}, but \textcite{Binswanger1980, Binswanger1981} is regarded as the first experimental economist to identify risk attitudes using an MPL with real payoffs.
The MPL was further developed by \textcite{Schubert1999} and \textcite{Holt2002}.

The instrument employed by HL requires subjects to make a series of binary choices between two lotteries, $A$ and $B$, across ten lottery pairs.
The instrument used in the \enquote{low-stakes} treatment of HL is as follows:

\begin{table}[h!]
	\caption{ \textcite{Holt2002} \\ The Ten Paired Lottery-Choice Decisions with Low Payoffs }
	\begin{tabularx}{\textwidth}{cccc}
		Row \# & Option A                                    & Option B                                    & \cnline{Expected Payoff\\Difference} \\\hline
		1      & 1/10 of  \money{2.00}, 9/10 of \money{1.60} & 1/10 of  \money{3.85}, 9/10 of \money{0.10} &  \money{1.17}                        \\
		2      & 2/10 of  \money{2.00}, 8/10 of \money{1.60} & 2/10 of  \money{3.85}, 8/10 of \money{0.10} &  \money{0.83}                        \\
		3      & 3/10 of  \money{2.00}, 7/10 of \money{1.60} & 3/10 of  \money{3.85}, 7/10 of \money{0.10} &  \money{0.50}                        \\
		4      & 4/10 of  \money{2.00}, 6/10 of \money{1.60} & 4/10 of  \money{3.85}, 6/10 of \money{0.10} &  \money{0.16}                        \\
		5      & 5/10 of  \money{2.00}, 5/10 of \money{1.60} & 5/10 of  \money{3.85}, 5/10 of \money{0.10} & -\money{0.18}                        \\
		6      & 6/10 of  \money{2.00}, 4/10 of \money{1.60} & 6/10 of  \money{3.85}, 4/10 of \money{0.10} & -\money{0.51}                        \\
		7      & 7/10 of  \money{2.00}, 3/10 of \money{1.60} & 7/10 of  \money{3.85}, 3/10 of \money{0.10} & -\money{0.85}                        \\
		8      & 8/10 of  \money{2.00}, 2/10 of \money{1.60} & 8/10 of  \money{3.85}, 2/10 of \money{0.10} & -\money{1.18}                        \\
		9      & 9/10 of  \money{2.00}, 1/10 of \money{1.60} & 9/10 of  \money{3.85}, 1/10 of \money{0.10} & -\money{1.52}                        \\
		10     & 10/10 of \money{2.00}, 0/10 of \money{1.60} & 10/10 of \money{3.85}, 0/10 of \money{0.10} & -\money{1.85}                        \\\bottomrule
	\end{tabularx}
\end{table}

The logic of the HL MPL is straightforward.
In all ten lottery pairs, the monetary outcomes of all $A$ lotteries are the same, and similarly with the $B$ lotteries.
Every lottery is comprised of two possible outcomes, with the higher outcome in the $B$ lotteries being greater than the higher outcome in the $A$ lotteries, and the lower outcome in the $B$ lotteries being less than the lower outcome in the $A$ lotteries.
The probability of receiving these outcomes changes from pair to pair.
At the top of the list, the probability of receiving the high amount from each lottery is only 0.1, while the probability of receiving the lower amount is 0.9.
Moving from the top to the bottom of the list, the probability of receiving the higher amount in each lottery increases by 0.1 for each row until at the bottom of the list, row 10, the probability of receiving the higher amount is equal to 1, collapsing the decision to a choice between two certain outcomes.


If a subject has strictly monotonic utility for money, an EUT maximizer should either prefer option A initially and then working down the rows eventually prefer option B for the remaining rows, or the subject should prefer B for all rows.
However, it is often observed that subjects will \enquote{switch} back and forth between selecting lottery A and selecting lottery B.
This is commonly called \enquote{multiple switching behavior} (MSB) \parencite{Bruner2011}.
Data displaying MSB has often been described as \enquote{inconsistent} with an EUT maximization.
\textcite[1645]{Holt2002} describes a subject switching once from A to B when the B lottery becomes sufficiently attractive as what a risk averse subject \enquote{should} do in the HL MPL, implying that MSB is contrary to theory.


\textcite[347]{Harrison2007} notes that a subject could be indifferent between the lotteries of certain pairs, which would explain why a subject displayed MSB.
In fact, under EUT with a deterministic theory of choice specification and some mild assumptions, a subject displaying MSB must be indifferent to the lotteries in lottery pairs between the first switch and the last switch.
This is shown in Appendix A.
\textcite{Harrison2007} conduct an experiment in which some subjects are offered an \enquote{indifferent} option and note that the proportion of subjects who are not offered the indifference option expressing MSB almost equals the proportion of subjects offered the indifference option  selecting the indifference option.
While this is very suggestive that MSB is caused by indifference, it should be noted that the indifference option was played out by the experimenter randomly selecting either option $A$ or option $B$ for payment.
The selection of the indifference option could therefore represent a preference for a compound lottery of $A$ and $B$, and not an indifference between $A$ and $B$.


Choosing option $A$ in row 10 is also an apparent violation of EUT that is not so easily believed to be caused by indifference.
Since there is no uncertainty in the outcomes of either lottery $A$ or lottery $B$, a choice of $A$ apparently violates the axiom of monotonicity.
It is possible that a subject who chooses $A$ in row 10 has a very good motivation to do so, perhaps because of some influence from outside of the experiment, and could potentially still be making choices in accordance with EUT.
As noted by \textcite[930]{Smith1982}: \enquote{It is hard to find an experimentalist who regards anything as self evident, including the proposition that people prefer more money to less}
This is mentioned merely as a caveat to proclaiming a general loss of rationality on behalf of the subjects making such choices. It is more believable that such subjects are making a mistake in choosing $A$ in row ten.

The extent of this type of behavior in economic experiments is not entirely clear.
Experimental procedures often vary from experimenter to experimenter and form experiment to experiment.
For instance, \textcite{Holt2002} note that some subjects \enquote{crossed out and changed} their responses to choices near their switch point.
If the experimental design hadn't allowed subjects to change their responses, or if the design made it cumbersome to do so, then there might have been more observed \enquote{inconsistent} responses than reported. 

While many experimenters report the number or proportion of subjects switching multiple times, some experimenters exclude subjects who display this behavior from their analysis or only report the number of \enquote{safe} choices (the lottery $A$ choices).
\textcite[1648]{Holt2002} did an analysis without the\enquote{inconsistent} subjects but note that \enquote{The average number of safe choices increases slightly in some treatments when we restrict our attention to those who never switch back, but typically by less than 0.2 choices} and ultimately left \enquote{inconsistent} subjects in their final analysis.
When experimenters only report safe choices, they often don't discriminate between subjects who switched once or multiple times or if one of those \enquote{safe} choices was a choice of A in row 10.
However, if 10 safe choices are reported, then clearly one of them was a choice of lottery $A$ in row 10.

\textcite[9]{Filippin2014} collected datasets of 54 published replications of HL to examine gender differences in estimates for risk attitudes.
\textcite[10-11, 17-18]{Filippin2014} also briefly discuss the number of \enquote{inconsistent} subjects in the aggregated dataset they collected.
Their tables 4 and 7 are combined and reproduced below.

\begin{table}[h!]
	\caption{ \textcite{Filippin2014} \\ Prevalence and Type of \enquote{Inconsistent} Behavior }
	\label{tb:F2014:Prev}
	\begin{adjustbox}{width=1\textwidth}
	\begin{tabular}{lccccccc}
		                                          & \multirow{2}{*}{Detail}  & \multicolumn{3}{c}{Consistent Subjects}  & \multicolumn{3}{c}{\cnline{Inconsistent Subjects}}     \\
		                                          &                          &          Males & Females & Total         &        Males & Females & Total                \\\hline
		                       Microdata          & Full                     &          2119  & 2205    & 4324          &          411 &     502 &  913                 \\
\cnline{\# of safe choices + consistency} & \multirow{2}{*}{Partial} &           504  &  408    &  912          &           64 &      98 &  162                 \\
\cnline{\# of safe choices only}          &                          &           375  &  324    &  699          &            3 &       1 &    4                 \\
		Summary Statistics                        & Summary                  &           413  &  359    &  772          &              &         &                      \\\hline
		Total                                     &                          &          3411  & 3296    & 6707          &          478 &     601 & 1079                 \\\hline
										          &                          & \multicolumn{2}{l}{Inconsistent Choices}&&  \multicolumn{3}{c}{\cnline{\% Inconsistent Subjects}} \\          
		                                          &                          &         Number & Out Of  &               &        Males & Females & Total                \\\hline
		Switching from B to A                     &                          &           973  & 6962    &               &         12.1 &    15.8 & 14.0                 \\
		Always Option A                           &                          &           100  & 6334    &               &          1.8 &     1.3 &  1.6                 \\
		Always Option B                           &                          &             6  &  383    &               &          1.4 &     1.7 &  1.5                 \\\hline
		Total                                     &                          &          1079  &         &               &              &         &                      \\\bottomrule
	\end{tabular}
	\end{adjustbox}
\end{table}



Table (\ref{tb:F2014:Prev}) shows to some extent to potential reporting bias of \enquote{inconsistent} behavior in experiments.
Of the 6707 subjects, there was insufficient data to tell if any type of \enquote{inconsistent} behavior occurred with 772 subjects, those with \enquote{Summary} detail, and a further 699 subjects in which it was only possible to tell if there was an apparent violation of monotonicity, those with \enquote{Partial} detail and only reporting the number of safe choices.
About 21.5\% of the data reports insufficient information to determine the extent of inconsistent behavior.

In the first part of Table (\ref{tb:F2014:Prev}), if we consider only the \enquote{Full} detail data and the \enquote{Partial} detail data which indicates whether or not subjects were \enquote{consistent}, there were 1075 out of 5236 subjects who displayed some sort of inconsistency, about 20.5% of subjects.
\textcite[1647]{Holt2002} reported 28 of 212 (13.2\%) of their subjects exhibited MSB.

While this is not as substantial a proportion of subjects acting in apparent violation of EUT as in the \textcite{Grether1979} preference reversal phenomenon, it is not a trivial proportion.
Additionally most of the potential explanations for the preference reversal phenomenon proposed by \textcite{Grether1979} should be considered resolved given the many replications of HL.
Almost all of the proposed experimental method explanations can be generally rejected: the observance of this behavior is not a low frequency event, nor are sample sizes small; most of the subjects in these experiments (including all of the original HL subjects) were either university students or faculty who can hardly be considered unsophisticated subjects; almost all the experimenters were economists.
The question of confusion or misunderstanding however remains open, along with many of the theoretical critiques.

Two of the theoretical critiques of the \textcite{Grether1979} experiments deserve particular note.
In the HL experiments, subjects were presented with several MPLs and were told that one of their responses would be chosen at random and played out for real earnings.
Most experimenters take advantage of this \enquote{pay one} mechanism in order to increase the stakes for each individual question without breaking their budget.
This \enquote{pay one} mechanism however, requires that an independence axiom hold between choices in for a pattern of choices with a single switch point to be utility maximal across all preferences.
This is no different from the critique noted by \textcite{Holt1986} and \textcite{Karni1987} that should a subject have preferences which are in line with RDU, then there is no apparent violation of economic theory by M.

Similarly, the use of a \enquote{pay one} mechanism may dilute the payoffs of outcomes to the point where the difference in the value of option $A$ versus option $B$ fails to satisfy the dominance criteria of \textcite{Smith1982}.
The HL MPL is structured in such a way that a subject will confront a lottery pair in which she will be near (or entirely) indifferent between the two options.
The \enquote{pay one} mechanism decreases the expected difference in the value of the options by in effect multiplying the probability of each outcome in the lotteries by 0.10. 

The two lottery pairs that the subject is closest to being indifferent to will always be the two on either side of the switch point.
If MSB is party due to a failure to satisfy dominance, it should occur with greater frequency near this point.
\textcite[1648]{Holt2002} \enquote{Even for those who switched back and forth, there is typically a clear division point between clusters of $A$ and $B$ choices, with few 'errors' on each side} and that responses that were crossed out and changed generally were around the switch point \parencite*[1646]{Holt2002}.
\textcite[1647-1648]{Holt2002} further note that the rate of MSB was lowest for their high stakes treatments and highest for their hypothetical stakes treatment.
The way the instrument is built and the frequency of MSB across different treatments suggest that a failure of dominance may be a large factor in explaining the frequency of MSB.

While it may be more believable that dominance is at play for MSB than the non-monotonic choice of lottery $A$ in row 10, dominance failure shouldn't be ruled out a priori for non-monotonic choices.
Take for example, a choice between \money{0.01} and \money{0.02}.
Even if the outcomes of both options are guaranteed, the value difference is likely to be very small, and thus more likely to fail the dominance criteria.
Similarly, because of the \enquote{pay one} mechanism, the expected cost of choosing $A$ in row 10 of the HL MPL is only \money{0.185}.
This may be high in comparison to the cost associated with the generally observed MSB, but it is not unfathomably high.

A failure to induce salience could also help explain some \enquote{inconsistent} choices.
If subjects don't comprehend the two-part payment mechanism (selecting one lottery from the list for payment, then playing the lottery out to determine the reward), or more generally how the probabilities associated with outcomes mapped to (presumably valued) monetary rewards, then there is a failure to induce salience.
A failure to induce salience seems less likely than a failure of dominance when explaining MSB given that most MSB is clustered around what could be called a \enquote{true} switching point and that the remaining choices seem \enquote{consistent} with a salient reward mechanism.
It does however seem more likely that there is a failure of salience for subject who selected lottery $A$ in row 10.

\section{Stochastic Choice as an Explanation of \enquote{Inconsistent} Choices}

It is easy to imagine the theoretical possibility that a subject's preference ordering among a set of alternatives is mapped perfectly without error to the the messages which will realize the optimal outcome for that subject.
In this case, the various theories models have specific predictions as to what elements belong in the chosen set given any set of preferences consistent with that model.
Any occurrence of some alternative within the chosen set which isn't predicted is therefore an apparent violation of the utility theory in question given this mapping assumption.
As has been discussed with respect to the \textcite{Grether1979} and \textcite{Holt2002} replications, the mass of empirical data collected over the past few decades has shown that such apparent violations are common, and that there is a need to \enquote{attempt to modify the theory to account for \textins{these} exception\textins{s} without simultaneously making the theory vacuous} \textcite[634]{Grether1979}.
Such a modification that potentially explains observed choices of subjects which appear to be inconsistent with some predetermined utility theory is that observed choices by subjects are a product of a choice process that is at least in part stochastic, and not wholly deterministic.


The first description of choice as a stochastic process appears to be by \textcite{Edwards1954}, with notable early contributions by \textcite{Luce1958}, \textcite{Debreu1958}, \textcite{Davidson1959}, \textcite{Becker1963}, \textcite{Luce1965}.
Stochastic choice models add elements of randomness to utility models which allow for a degree of error during the evaluation of various alternatives, a degree of randomness of the preference relation used  in the evaluation of alternatives, and/or randomness in the selection of an alternative to belong to the chosen set.
These stochastic models are used as complements to, rather than substitutes for, deterministic theories of utility.
As such, they generally (though not always) seek to link deterministic preference relations, $A \succeq B$, to probabilities of choice, ${\Prob}(A) \geq {\Prob}(B)$.

There are various ways to accomplish this linking of ideas, the most common of which are discussed by \textcite{Wilcox2008}.
Generally, these models fall into one of two groups: Random Preference (RP) models, or deterministic preference with a random error models.
The most common deterministic preference with random error models consist of Strong Utility (SU) models, Strict Utility models (a subset of SU models), and Strong Utility's superior derivatives Moderate Utility (MU) models.
I lump SU and MU models into the same group because although they differ on several key points, they both implement stochasticity by assuming some error in the evaluation of alternatives.
They differ by their treatment of this error, with SU models assuming it is homoscedastic and MU models requiring it to be heteroscedastic in a particular fashion over the domain of potential outcomes.
RP models differ from the rest of these by imposing randomness in the preference relation used to evaluate the alternatives.

A notable third group (with only one member I'm aware of) could be considered deterministic preferences with a stochastic choice strategy.
The sole member model in this group was proposed by \textcite{Machina1985} in which randomness is explained as subjects having convex indifference curves in the Machina Triangle space \textcite{Machina1987} and seeking mixtures of alternative lotteries in order to maximize a deterministic preference.
The stochastic mixture is said to be deterministically more preferred to any of the \enquote{pure} lottery options which make up the mixture for such subjects.
This theory implies that there is no error in the evaluation of alternatives, no error in the choice of the stochastic mixture, and no randomness of preferences, while still predicting noisy observed choices.
This theory however has fallen out of favor, and \textcite{Hey1995} provide strong experimental evidence against it.
Because of the large degree of determinant preference behavior in this model, it is not considered in the rest of this text when discussing stochastic choice models.

Another concept called \enquote{trembles}, a term derived from the notion of a \enquote{trembling hand} equilibrium developed by \textcite{Selten1975}, suggests that some choices are made completely at random with no consideration for the underlying values of the alternatives.
Trembles can be implemented by assuming that there is no error in the evaluation of alternatives, no randomness of preferences, and that all of the apparently inconsistent choices are mistakes.
Trembles can also be imposed on top of other stochastic models to transform the \enquote{true} choice probabilities derived from the stochastic models into observed probabilities of choice.
Because in either case the probability of a tremble does not depend on any preference relation, trembles will be left out of the proceeding discussion on stochastic models unless otherwise specifically noted.

In order to discuss stochastic models in more depth, first some notation will be borrowed from \textcite{Wilcox2008}.
Let $S_m$ and $R_m$ be two lotteries in lottery pair $m$ which apply discrete probability distributions $s_{m0} , \ldots , s_{m(I-1)}$ and $r_{m0} , \ldots , r_{m(I-1)}$ respectively to a set of $I$ outcomes in $Z = \lbrace z_0 , \ldots , z_{(I-1)} \rbrace$.
Let the context of lottery pair $m$, $c_m$, be the set of outcomes in $Z$ with non-zero probabilities applied to them by any lottery in pair $m$.
Assume that for any lottery pair $m$, $z_0 > \ldots > z_{(I-1)}$.
Finally, let $P_m^n = {\Prob}(y_m^n = 1) $ represent the probability that subject $n$ chooses lottery $S$ in pair $m$, and let $1-P_m^n = {\Prob}(y_m^n = 0)$ equal the probability that subject $n$ chooses lottery $R$ in pair $m$.
It is this concept of probability of choice which is linked to the deterministic concept of the preference relation $\succeq$.

With this notation in place we can define the manner in which the preference relation  is most commonly linked to a probability of choice.
Assuming for now that a subject has an EUT structure: 

\begin{equation}
	\label{eq:W2008:VSVR}
	V( S_m | \beta^n )  \equiv \sum_{z=0}^{I-1} s_{mz} u^n_z   ~~,~~  V( R_m | \beta^n ) \equiv \sum_{z=0}^{I-1} r_{mz} u^n_z
\end{equation}

\noindent where $u_z^n$ is the utility of prize $z$ given some elements of the vector of structural parameters $\beta^n$, and $V(X_m|\beta)$ is a value function determined by properties of lottery $X_m$ and the vector of structural parameters.
The structural parameters $\beta^n$ can be the utilities of the outcomes themselves, or the determining parameters of some parametric function of utility.
Equation (\ref{eq:W2008:VSVR}) can be easily transformed to be represented by rank dependent utility with no loss of generalization.
The $\beta^n$ vector would simply have to additionally include parameters defining the probability weights.
Thus, for any transitive structure:

\begin{equation}
	S_m \succeq^n R_m \Leftrightarrow  V( S_m | \beta^n ) \geq V( R_m | \beta^n ) \Leftrightarrow {\Prob}( y^n_m=1 ) \geq {\Prob}( y^n_m=0 )
\end{equation}

RP models posit that for every choice task faced by the subject, a preference relation is drawn randomly from some distribution of preference relations and then the subject makes a choice in accordance with the randomly drawn preference relation.
Econometrically it is possible to model choice such that once the preference relation is drawn, further randomness is added by having the evaluation of the alternatives involve some error process, as in SU and MU models.
However, this is almost never done.
Usually subjects conforming to RP models are said to draw the preference relation randomly from a distribution, and then make a choice deterministically with respect to the preference relation.
Thus the probability of choosing any lottery conditional on this randomly drawn preference is either 0 or 1:

\begin{equation}
	{\Prob}(y_m^n = 1 | \beta^{n*}) = \lbrace 0,1 \rbrace
\end{equation}

\noindent where $\beta^{n*}$ is the vector of parameters randomly drawn by subject $n$.
Given this relationship, the unconditional choice probability is just the probability of observing $\beta^{n*}$ given some joint distribution of the elements of $\beta$, $G_\beta(x|\alpha^n)$, where $\alpha^n$ is a vector of parameters which defines the shape of the distribution.

\noindent Let $B_m= \lbrace B | V(S_m | \beta) \geq V(R_m|\beta) \rbrace$.
Then the unconditional probability that a subject chooses lottery $S_m$ is:

\begin{equation}
	P_m^n = \int_{\beta \in B} dG_\beta(x | \alpha^n)
\end{equation}

\noindent that is, the probability of the choice is simply the probability of observing a $\beta$ vector which deterministically conforms to that choice.

The collection of SU and MU models represent preferences as stable across choice tasks but with an error of some kind when the utilities of the lotteries are evaluated.
These models are very similar to commonly used latent variable models, with SU models assuming that the latent variable is homoscedastic and MU models assuming that the latent variable is heteroscedastic.
Much in the same way as a standard logit model, SU and MU models state that this latent variable, $y_m^{n*}$, relates to the observed choice such that $y_m^n = 1 \Leftrightarrow y_m^{n*} \geq 0$, thus $P_m^n = {\Prob}(y_m^{n*} \geq 0)$.
The latent variable takes the form:

\begin{equation}
	\label{eq:W2008:ym}
	y_m^{n*} = V(S_m | \beta^n) - V(R_m | \beta^n) - \frac{\epsilon}{\lambda^n}
\end{equation}

\noindent where $\epsilon$ is a random variable with a mean of 0, some standard variance and a symmetric c.d.f $F(\cdot)$ where $F(0) = 0.5$.
Together with $\frac{1}{\lambda^n}$, this term represents the degree of noise in the evaluation of alternatives.
Equation (\ref{eq:W2008:ym}) is transformed into a choice probability by applying some c.d.f $F(\cdot)$:

\begin{equation}
	\label{eq:W2008:Pm}
	P_m^n = F\left( \lambda^n [V(S_m | \beta^n) - V(R_m | \beta^n)] \right)
\end{equation}

As $\lambda^n$ approaches infinity, equation (\ref{eq:W2008:Pm}) will approach either 0 or 1, while as $\lambda^n$ approaches 0, equation (\ref{eq:W2008:Pm}) will approach 0.5.
Should the function $F(\cdot)$ take the form of the logistic c.d.f. then the choice probabilities can be calculated by:

\begin{equation}
	\label{eq:W2008:Pm2}
	P_m^n = \frac{\exp \left[ \lambda^n \times V(S_m | \beta^n) \right]}{  \exp \left[ \lambda^n \times V(S_m | \beta^n) \right] + \exp \left[ \lambda^n \times V(R_m | \beta^n) \right] }
\end{equation}

Because utility structures such as EUT and RDU are unique up to affine transformations, $\lambda^n$ can be any arbitrarily chosen constant and choice probabilities would still be preference order preserving.
The choice of $\lambda_m$ is however a defining distinction between SU and MU models.
\textcite{Wilcox2008} proposes and \textcite{Wilcox2011} expands upon a MU model called \enquote{contextual utility} (CU) model. This expands equation (\ref{eq:W2008:Pm2}) by setting $\lambda^n$ to the following:

\begin{equation}
	\lambda^n = \frac{1}{\lambda^{n*} \left[ u^n_{m0}(z) - u^n_{m(I-1)}(z) \right]}
\end{equation}

\noindent where $\left[ u^n_{m0}(z) - u^n_{m(I-1)}(z) \right]$ is the difference in utility of the greatest utility outcome and the least utility outcome in the context of pair $m$, and $\lambda^{n*}$ can continue to be adjusted with the same effects as $\lambda^n$ in equation (\ref{eq:W2008:Pm}).
It is this property which makes the latent random variable defined in equation (\ref{eq:W2008:ym}) heteroscedastic with respect to the context of the lottery pair.
It has several appealing implications.

First and foremost, it allows the \enquote{more risk averse than} relation derived by \textcite{Pratt1964} for deterministic risky choice to be extended to the\enquote{stochastically more risk averse than} relation across multiple contexts.
\textcite[89]{Wilcox2011} defines it thus: \enquote{Agent a is stochastically more risk averse than agent b \textelp{} iff $P^a > P^b$ for every \textins{mean preserving spread} pair $\lbrace S, T \rbrace$.}
A mean preserving spread (MPS) pair is simply a pair of lotteries with equal expected values.
SU models only allow such relations within contexts, while CU allows for this relation across contexts.
Second, CU only conforms to moderate stochastic transitivity, hence its inclusion as a MU model.
This allows CU to be descriptively more appealing as potential choice patterns which violate strong stochastic transitivity are acceptable with moderate stochastic transitivity.

Stochastic choice models can add a great deal of traction to utility theories which would otherwise falter when applied to apparently inconsistent choice data.
As the difference in value between any two alternatives approaches 0, the choice probabilities of the two alternatives approach each other.
The HL MPL for example is structured in such a way to confront the subject with a list of lottery pairs in which the lotteries get closer and closer in value before diverging in value.
With a deterministic choice process, this structure leads to a choice pattern with a single switch point.
With a stochastic choice process, a choice pattern with a single switch point is only the most likely choice pattern for a subject with preferences in accordance with EUT. 

For any given set of preferences and a modest degree of noise, a choice pattern displaying MSB clustered around the switch point that would be produced by a deterministic choice process is often only marginally less likely than a choice pattern with one switch point.
As noted previously, \textcite[1648]{Holt2002} observed MSB with this kind of clustering.
In this way, stochastic choice models can explain behavior which may otherwise be taken as to imply a failure of dominance.
Also, as noted previously, when the stakes were raised in the HL experiments, the extent of MSB was reduced.
With SU models, this could be potentially explained as the increase in stakes causing an increase in the difference in values of the two alternative lotteries, which would lead to choice probabilities moving closer to 0 or 1.
This however, is not the case with CU models which would normalize the difference to be the same for any scaling of outcomes.

SU and MU models do incorporate an often overlooked idea about what the choices by subjects ultimately amount to.
In particular, it is often suggested, but seldom explored, that occasionally choices by a subject must in fact be inconsistent with the subject's own underlying latent preferences.
As stated by \textcite{Holt1986}⁠:\enquote{Each subject must be making some error or mistake or whatever when answering the questions.}

A choice error can be defined as the selection by a subject of an option among a set of alternatives which does not provide the greatest utility among the set of alternatives.
More generally, to include scenarios where subjects are asked to make multiple selections among alternatives, it is the selection by a subject of an option among a set of alternatives which doesn't belong to the set predicted by a deterministic choice process and some predetermined theory of utility.
As such, errors can only arise conditional on some predetermined theory.

A choice error in this context should not be interpreted as a violation of imposed utility theory.
Any choice error requires that the manner in which the various alternatives are evaluated and ranked be consistent with the subject's latent preference structure, but in the mapping of the subject's preference to the choice space, some noise is introduced that leads to a sub-optimal choice.

Concluding Remarks

Economic orthodoxy over the past half century has been presented with several challenges to the way it characterizes how an agent makes a choice between alternatives in her choice set.
One of these challenges in the form of experiments initially conducted by psychologists, but later replicated by economists, spearheaded the discussion by observing a high frequency \enquote{preference reversals} which seemingly contradicted Expected Utility Theory.
As stated by \textcite{Grether1979}: \enquote{Taken at face value the data are simply inconsistent with preference theory and have broad implications about research priorities in economics.}

The challenge to explain the mounting apparent violations of contemporary economic theory however did not go unheeded.
Theorists noted that it wasn't necessary to forgo the transitivity axiom as suggested by \textcite[623]{Grether1979}, which along with the completeness axiom forms the basis what is considered\enquote{rationality} in economics.
Instead, it was shown by \textcite{Holt1986} and later by \textcite{Karni1987} that should the independence axiom be rejected, there exist preferences which conform to the observed apparent violation of choice.
The \enquote{Anticipated Utility} theory of \textcite{Quiggin1982}, now referred to as \enquote{Rank Dependent Utility}, provides an axiomization of such a theory of utility without the independent axiom.
A more radical departure from Expected Utility Theory was \enquote{Regret  Theory} initially proposed independently by \textcite{Bell1982} and \textcite{Loomes1982}, then axiomized by \textcite{Fishburn1987}, which abandons the transitivity axiom altogether.
\textcite{Loomes1989} test this theory on a replication of the \textcite{Grether1979} experiments and find that it fits the entire dataset better than Expected Utility Theory.

Economics as an empirical science has also progressed greatly over the past half century, notably with \textcite{Smith1982} defining the necessary precepts of conducting a valid controlled economic experiment
Using the framework of these precepts, \textcite{Harrison1994} addresses the \textcite{Grether1979} experiments directly by stating that the dominance criteria put forth by \textcite{Smith1982} wasn't met in the original experiment and that several of the subsequent replications which purport to address the dominance issue do not do so.
Some experimental modifications employed in replications in fact may decrease the saliency of the rewards offered.
In this line of thought, the theory is less to blame than the experiments employed.
\textcite[236-239]{Harrison1994} replicated the\textcite{Grether1979} experiments with some modifications to increase the cost of reporting a selling price inconsistent with a subject's own latent preferences and observed a precipitous drop in the proportion of subjects displaying an apparent preference reversal.

A powerful supplement to current economic theory is the idea of choice as a stochastic processes as opposed to a deterministic one.
Some stochastic models regard apparent violations of economic theory as the result of some randomness of latent preferences while others regard them as \enquote{mistakes} or \enquote{choice errors} from stochastic noise in the evaluation of alternatives.
Such models are powerful as they make only very mild requirements on the structure of underlying preferences if any at all, and create a framework for these preferences to be mapped to choices.
As such most stochastic models are equally applicable to Expected Utility Theory, Rank Dependent Utility, or Prospect Theory \parencite{Kahneman1979, Tversky1992}, and can encompass and enhance the explanatory power of these utility theories.

\break

\section{Appendix A - MSB as Deterministic Indifference}

Lemma (1): If independence holds, and we have $L_0 \succeq L_1$ and $L_2 \succeq L_3$, then we must also have $aL_0 + (1-\alpha)L_2 \succeq \alpha L_1 + (1 - \alpha) L_3 \forall \alpha \in (0,1)$


\begin{proof}
	Given $L_0 \succeq L_1$ and $L_2 \succeq L_3$
	\begin{flalign*}
		\alpha L_0 + (1 -\alpha) L_2 \succeq \alpha L_1 + (1-\alpha) L_2                                     &&  \text{by independence}             &\\
		\alpha L_1 + (1 -\alpha) L_2 \succeq \alpha L_1 + (1-\alpha) L_3                                     &&  \text{by independence}             &\\
		\alpha L_0 + (1 -\alpha) L_2 \succeq \alpha L_1 + (1-\alpha) L_2 \succeq \alpha L_1 + (1-\alpha) L_3 &&  \text{by transitivity of $\succeq$}&\\
		\text{therefore}                                                                                     &&                                     &\\
		aL_0 + (1-\alpha)L_2 \succeq \alpha L_1 + (1 - \alpha) L_3                                           &&                                     &
	\end{flalign*}
\end{proof}

\noindent Any three rows of lottery pairs in the \textcite[623]{Grether1979} MPL conform to the following

\begin{equation*}
	A_1 = \alpha (A_0) + (1-\alpha) A_2 , B_1 = \alpha(B_0) + (1-\alpha) B_2 ~~ \textit{for some} ~\alpha \in (0,1)
\end{equation*}

\noindent An example of a multiple switch from a MPL is the following:

\begin{equation*}
	A_0 \succeq B_0 , B_1 \succeq A_1 , A_2 \succeq B_2
\end{equation*}

\noindent A multiple switch in the MPL implies indifference between lotteries of the interior lottery pair:
\begin{align*}
	\text{Since} & A_0 \succeq B_0 , A_2 \succeq B_2\\
	\text{then}  & A_1 \succeq B_1 , \text{by Lemma (1) and reduction of compound lotteries (ROCL)}\\
	\text{therefore} & A_1 \sim B_1 , \text{by completeness of} \succeq
\end{align*}

\noindent If any two lottery pairs in an MPL style instrument display preference relations in the same direction, then every lottery pair which is a linear combination of those two lottery pairs must have the same preference direction if we hold on to EUT and ROCL, otherwise the subject must be indifferent.


\onlyinsubfile{
\newpage
\printbibliography[segment=1, heading=subbibliography]
}



\onehalfspacing
\setcounter{chapter}{1}
\chapter{Normative Justification for Stochastic Models}

\lltoc
%%\tableofcontents

The recent interest in the ability of stochastic choice models to explain choice behavior that seemingly violates Expected Utility Theory (EUT) has led to a variety of calls for, and attempts to, seek out a \enquote{true} stochastic model or combination of  models which best describe observed choice behavior in experiments.
The first call for such a research effort was apparently \textcite{Edwards1954}, who accused economics of becoming \enquote{exceedingly elaborate, mathematical, and voluminous} \textcite[380]{Edwards1954} in its attempt to explain the diversity of empirical choice data and criticized economists as \enquote{mak\textins*{ing} assumptions, and from these assumptions they deduce theorems which presumably can be tested, though it seems unlikely that the testing will ever occur.}
\textcite{Edwards1954} proposed that individuals may be making choices stochastically as opposed to deterministically, which married some of the extent findings of psychology at the time with economics to help explain the data, both from psychology and economics.

A more recent call to study stochastic models was issued by \textcite[1321]{Hey1994} after conducting rigorous subject-by-subject tests of some of the popular proposed alternatives to EUT, alongside EUT.
They conclude that \enquote{possibly the overriding feature of our analysis is the importance of error \textelp{} Perhaps we should now spend some time on thinking about the noise, rather than about even more alternatives to EU?}
A wealth of stochastic models has resulted from economists and psychologists taking up the project proposed by \textcite{Hey1994}.
This chapter seeks to describe the results of this effort to improve the descriptive capabilities of this call to research, and introduce a much needed discussion of the normative promise of some of these models.


\section{The Specification of Stochastic Models}

The number of models developed by researchers engaged in the stochastic project can largely be categorized into three classes of stochastic models.
\textcite[1301]{Hey1994} proposed a stochastic choice model which incorporates a random error term into the evaluation of the lotteries by subjects.
The roots of this type of model date back to \textcite{Fechner1966a} and \textcite{Luce1959}, and has subsequently been called a \enquote{Strong Utility} (SU) or \enquote{Fechnerian} model.
There are, however, a large number of models that have been derived from the SU model, and so we will refer generally to this class of models as \enquote{Random Error} (RE) models.
\textcite{Harless1994} had undertaken their own analysis of various alternatives to EUT and suggested a stochastic model which allows for subjects to potentially disregard their underlying preferences and choose between the available options with equal probability.
The models in this class are called the \enquote{Constant Error} or \enquote{Tremble} (TR) models.
\textcite{Loomes1995} reconsidered and generalized a model initially proposed by \textcite{Becker1963} called the \enquote{Random Preference} (RP) model which, in its most popular form, allows for subjects to have some distribution of preference relations from which they randomly choose every time they evaluate a choice situation.
Generally, any model that calls for an agent to have a distribution of preference relations belongs to the RP class.{\footnotemark}

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	There are other members of the RP model class that are less commonly utilized, one of which will be discussed later.
	For now, when referring to the RP model, we refer to the formulation specified by \textcite{Loomes1995}, where one preference relation is drawn per decision situation.
}

A less popular class of stochastic choice models proposed by \textcite{Machina1985} and \textcite{Chew1991}, suggests that subjects have deterministic preferences for \enquote{stochastic options} and thus deliberately engage in adding randomness to their choices.
That is, subjects could have convex indifference curves in the Marshack-Machina Triangle space,{\footnotemark} and therefore a probabilistic (linear) mixture of two lotteries lies on a higher indifference curve than any two lines which lie on the same curve.

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	The Marshack-Machina Triangle was developed by \textcite{Machina1987} as a way to represent the relation of lotteries with up to 3 outcomes and preferences for those lotteries.
	Each vertex of the triangle represents an outcome, and any point in the triangle represents a lottery.
	Any point on a vertex of the triangle represents a lottery with a 100\% composition of one outcome.
	Any interior point represents a lottery composed of a mixture of outcomes, with the relative proportion of any outcome in the lottery defined by its geometric distance from its corresponding vertex.
	If the independence axiom holds, a straight line between any two points in the triangle space indicates all the lotteries to which agent would be indifferent.
	Parallel lines thus indicate either an increase or decrease in preference.
	A strictly convex curve connecting 2 lottery points represents a violation of the independence axiom.
}

\textcite{Hey1995} tested the \enquote{stochastic options} theory of \textcite{Machina1985} using the \enquote{Quadratic Mixture} model of \textcite{Chew1991} and find strong evidence against it.
The model itself has some restrictive aspects for estimation: \enquote{First, the likelihood function, although continuous everywhere, is not smoothly so; there are kinks in the function with resulting discontinuities in the derivatives.
Second, for certain parameter sets, certain observations are \textit{impossible}} [emphasis in the original]\parencite*[164]{Hey1995}.
Out of a sample of 45 subjects, \textcite{Hey1995} find only 4 subjects that they can fit the model to at all, and of these 4, for only 2 does the \enquote{Quadratic Mixture} model fit better than a RE type model, and of these 2, for only one subject are the estimated coefficients plausible \parencite*[167]{Hey1995}.
It appears that continued investigation of this class of models has essentially ceased since these results.
Keeping with this pattern, when referring to stochastic models for the remainder of this text we do not include this class of models in our definition.

These general classes of stochastic choice constitute the bulk of the research on stochastic models, with the RE models possibly being the most widely employed models when estimating utility parameters from choice data.
To better understand these models and their implication, we will begin by defining some high level notation to characterize how these models operate.

For each option $j$ in a set of alternatives $t$, stochastic models generate a probability that an agent will select that option from the set.
These probabilities are referred to as \enquote{choice probabilities} and are generally related to an underlying determinisitic relation of preference.
First, we will define the Rank Dependent Utility (RDU) structure as formulated by \textcite{Quiggin1982}, which nests EUT as a special case, as the deterministic structure of preference.
Second we will define the manner in which RP, TR, and RE  models relate this deterministic structure to the stochastic specification of probabilities of choice.

RDU is characterized by the following function:
\begin{equation}
	\label{eq2:RDU}
	RDU = \sum_{i=1}^{I} \left[ w_i(p) \times u(x_i) \right]
\end{equation}
\noindent where $i$ indexes the outcomes, $x_i$, from $\{1,\ldots,I\}$ with $i=1$ being the smallest outcome in the lottery and $i=I$ being the greatest outcome in the lottery, $u(\cdot)$ returns the utility of its argument, $w_i(\cdot)$ returns the decision weight applied to outcome $i$ given the distribution of probabilities ranked by outcome, $p$.

The utility function $u(\cdot)$ can take many functional forms due to its property of being unique up to an affine transformation, and can be normalized in various was, as illustrated by \textcite{Hey1994}.
It will sometimes be useful to use a functional form to make certain concepts clearer and in such cases the constant relative risk aversion (CRRA) function will be employed:
\begin{equation}
	\label{eq2:CRRA}
	u(x) = \frac{x^{(1-r)}}{(1-r)}
\end{equation}
\noindent where $r$ is the coefficient of relative risk aversion \parencite{Pratt1964}.
Other popular functions such as the constant absolute risk aversion (CARA) function, or the Expo-Power function \parencite{Saha1993} can also be employed without loss of generality.

The decision weight function, $w_i(\cdot)$, takes the form:
\begin{equation}
	\label{eq2:dweight}
	w_i(p) =
	\begin{cases}
		\omega\left(\displaystyle\sum_{j=i}^I p_j\right) - \omega\left(\displaystyle\sum_{k=i+1}^I p_k\right) & \text{for } i<I \\
		\omega(p_i) & \text{for } i = I
	\end{cases}
\end{equation}
\noindent where the probability weighting function, $\omega(\cdot)$, can take a variety of parametric or non-parametric forms.
Many functions have been proposed for $\omega(\cdot)$; One is the \enquote{Inverse-S} shaped function popularized by \textcite{Tversky1992}:
\begin{equation}
	\label{eq2:pw:kahneman}
	\omega(p_i) = \frac{p_i^\gamma}{\biggl(\sum\limits_{k=0}^{I-1} p_k^\gamma\biggr)^{ \frac{1}{\gamma} } }
\end{equation}

\noindent Another is the power function used by \textcite{Quiggin1982}:
\begin{equation}
	\label{eq2:pw:quiggin}
	\omega(p_i)=p_i^\gamma
\end{equation}

\noindent The flexible function proposed by \textcite{Prelec1998} is also popular:
\begin{equation}
	\label{eq2:pw:prelec}
	\omega(p_i)=\exp(-\beta(-\ln(p_i))^\alpha)
\end{equation}

\noindent where $\alpha > 0$ and $\beta > 0$.
In all cases there exist values for the shaping parameters which allow $w_i(p) = p_i$, the special case of EUT.
When both a decision weight function applied to probabilities and a utility function applied to outcomes are defined, we have what is called a utility structure.

To make a general point about notation, consider lottery $j$ with $I_j = 2$ possible outcomes, and lottery $k$ with $I_k = 3$ possible outcomes.
Suppose that $x_i^j \neq x_i^k \; \forall i$.
A lottery $j^*$ can be constructed with $I_{j^*}= I_j + I_k = 5$ such that it is equivalent to lottery $j$ by adding the outcomes in lottery $k$ to lottery $j$ and setting the probabilities associated with each of these added outcomes equal to $0$.
Similarly for lottery $k$.
This equivalence property holds for all EUT and RDU functional forms as zero probability outcomes are given no weight in either structure.
The common set of combined outcomes is what \textcite{Wilcox2008} refers to as the choice scenario's \enquote{context}.
Throughout this chapter, the $j^*$ form of lotteries will be assumed whenever utilizing notation concerning the composition of individual lotteries.
This allows for identical notation to be utilized when comparing the probabilities of ranked outcomes across lotteries.

We now define a single choice scenario or task, $t$, as a discrete set of $J$ mutually exclusive options from which a subject is asked to select one for payment.
The most common form of such a task is a binary choice problem where subjects are presented with 2 alternatives and asked to select one for payment, $t=\left\{X_1,X_2\right\}$ .
Each element of $t$, $X_j$, is a vector of the option's observable characteristics, such as various outcomes and the associated probability of those outcomes in a lottery.
When presented with such a task, should the subject have a deterministic choice process and preference structure, the subject is assumed to choose option $j$ over the alternative $k$ if and only if the utility of option $j$ was at least as great the utility of option $k$:
\begin{equation}
	\label{eq2:ychoice}
	y_t = j \;\Leftrightarrow\; X_{jt} \succcurlyeq X_{kt} \;\Leftrightarrow\; G(\beta_n , X_j) \geq G(\beta_n , X_k)
\end{equation}

\noindent where $G(\cdot)$ is some utility structure such as RDU in equation (\ref{eq2:RDU}), $\beta_n$ is the unobservable vector of parameters of the utility structure for subject $n$, such as probability weights and utilities of outcomes, $X$ is defined above, and $y_i=j$ is a function that simply records which option $j$ is selected.

In this deterministic case, the preference relation $\succcurlyeq$ provides all the necessary conditions for the creation of a utility function $G(\cdot)$, meaning it is complete, transitive, and continuous.
Since this is the case, $\succcurlyeq$ necessarily provides a complete ranking of all the available alternatives in task $t$.
It will be convenient to denote this ranking explicitly throughout this chapter by setting the $j$ subscript of option $X_{jt}$ equal to its ranking in task $t$:
\begin{equation}
	\label{eq2:outcomerank}
	X_{1t} \succcurlyeq^n X_{2t} \succcurlyeq^n \ldots \succcurlyeq^n X_{jt} \succcurlyeq^n \ldots \succcurlyeq^n X_{Jt}\\
\end{equation}

\noindent This allows us to rank the utility of the $J$ options in task $t$ likewise:
\begin{equation}
	\label{eq2:utilityrank}
	G(\beta_n,X_{1t}) \geq G(\beta_n,X_{2t}) \geq \ldots \geq G(\beta_n,X_{jt}) \geq \ldots \geq G(\beta_n,X_{Jt})
\end{equation}

With $y_t$ defined and the options in task $t$ ranked, we can also define the set of options in task $t$ not selected by subject $n$ as follows:
\begin{equation}
	\label{eq2:emptyset}
	Z = t \,\backslash\, y = \{z \in t \;|\; z \notin y \}
\end{equation}

Similar to equation (\ref{eq2:utilityrank}), we can set the $j$ subscript of the $J-1$ unchosen options in $Z$ equal to their respective ranking in $Z$:
\begin{equation}
	\label{eq2:Zutilityrank}
	G(\beta_n,X_{1t}^Z) \geq G(\beta_n,X_{2t}^Z) \geq \ldots \geq G(\beta_n,X_{jt}^Z) \geq \ldots \geq G(\beta_n,X_{(J-1)t}^Z)
\end{equation}

With these base definitions in place, generalized formulations of the classes of stochastic models can be specified.
As stated above, the RP model characterizes each observed choice made by an agent as conforming to a deterministic preference relation which is drawn at random from a set of such relations whenever the agent is confronted with a choice scenario.
While the set preference relations can have a discrete distribution, the RP model is most commonly discussed in terms of utility functions with the relevant parameter vector, $\beta_n$, being continuously distributed according to some density function, $F_n(\beta | \alpha)$.
In this definition, $\alpha$ is a vector containing the necessary parameters to define the shape of the distribution.
Thus the probability of choice in a RP model is simply the probability that a vector $\beta_n^*$ is drawn from the distribution governed by $F_n(\beta | \alpha)$ that would deterministically satisfy that choice:
\begin{equation}
	\label{eq2:RP0}
	{\Prob}(y_t=j) = {\Prob}(j=1) = {\Prob}\left( \beta_n^* \,|\, G(\beta_n^*,X_{jt}) \geq G(\beta_n^*,X_{1t}^Z)\right)
\end{equation}

\noindent If we let $ B_t = \left\{ \beta_n^* \,|\, G(\beta_n^*,X_{jt}) \geq G(\beta_n^*,X_{1t}^Z)\right\}$, given the density function $F_n(\beta | \alpha)$:
\begin{equation}
	\label{eq2:RP.f}
	{\Prob}(y_t=j) = \int_{\beta \in B_t} dF_n(\beta|\alpha)
\end{equation}

Note the implication concerning first order stochastic dominance (FOSD){\footnotemark} with the above specification. Should $X_j$ FOSD $X_k$, there is no monotonic preference relation $\beta^*$ that will allow $G(\beta^*,X_{kt}) \geq G(\beta^*,X_{jt})$.
Thus, if we observe $y_t = k$ in such a scenario, the RP model collapses econometrically.

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	Lottery $j$ first order stochastically dominates (FOSD) lottery $k$ iff:
	\begin{align*}
		\forall \, x_i , \; \sum_i^I p_i^j \; \geq \; \sum_i^I p_i^k \quad \textit{and} \quad \exists \, x_i , \; \sum_i^I p_i^j \; > \; \sum_i^I p_i^k
	\end{align*}
	where $i$ ranks the outcomes of lotteries $j$ and $k$ as described in equation (\ref{eq2:RDU}).
	All deterministic theories of utility require the dominating option to be chosen over the dominated option.
}

RE models assume that the utility of each option is evaluated with some error term, which is assumed to be homoscedastic with the SU model and generally assumed to be heteroscedastic with its derivatives, but with a mean of $0$ in either case.
A choice is characterized as incorporating this error.
Assuming a binary choice scenario, the error terms and utility functions must satisfy the following given the choice of option $j$:
\begin{align}
	\label{eq2:RE0}
	\begin{split}
		G(\beta_n,X_{jt}) + \epsilon_{jt} \;&\geq\; G(\beta_n,X_{kt}) + \epsilon_{kt}\\
		\left[G(\beta_n,X_{jt}) + \epsilon_{jt}\right] \;&-\; \left[G(\beta_n,X_{kt}) + \epsilon_{kt}\right] \geq 0
	\end{split}
\end{align}

\noindent Setting $\epsilon_{jt} - \epsilon_{kt} = \epsilon_t\lambda_n$, where $\lambda_n$ is proportional to the standard deviation of $\epsilon_t$,{\footnotemark} we can rewrite equation (\ref{eq2:RE0}) as:
\begin{align}
	\label{eq2:RE1}
	\begin{split}
		G(\beta_n,X_{jt}) &- G(\beta_n,X_{kt}) + \epsilon_t\lambda_n \geq 0\\
		\epsilon_t \geq \frac{1}{\lambda_n} \left[ G(\beta_n,X_{jt}) \right.  &- \left. G(\beta_n,X_{kt}) \right]
	\end{split}
\end{align}

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	It is useful to recognize that what is described as \enquote{noise} in the data is determined by the variance (or standard deviation) of the error term, not its mean.
	If the sign and magnitude of the mean of the error were anything but 0, choices would reveal a biased preference, but if the variance is sufficiently small, the choices are unlikely to reveal apparent deviations from a utility theory.
}

\noindent Thus for RE models, the probability option $j$ is chosen is given by:
\begin{align}
	\label{eq2:RE.2}
	\begin{split}
	{\Prob}(y_t = j) &= {\Prob}\left(  \epsilon_t \geq \frac{1}{\lambda_n} \left[ G(\beta_n,X_{kt}) - G(\beta_n,X_{jt}) \right] \right)\\
	&= 1 - F\left( \dfrac{G(\beta_n,X_{kt}) - G(\beta_n,X_{jt})}{D(\beta_n,X_t)\lambda_n^* }  \right)
	\end{split}
\end{align}

\noindent where $\lambda^*$ is a precision parameter that remains after $\lambda_n$ is adjusted by $D(\beta_n,X)$ for heteroscedastic models.
As $\lambda^*$ approaches $0$, choice probabilities approach $0$ or $1$, while as $\lambda^*$ approaches $\infty$, choice probabilities approach $0.5$.
The asterisk will be dropped from the remaining formulae to save space.
$F(\cdot)$ is some cumulative distribution function (cdf) such that $F(0) = 0.5$ and $F(x) = 1 - F(-x)$.
Usually $F(\cdot)$ is taken to be either the normal or logistic function, but any distribution function satisfying the previous conditions is acceptable.
When discussing the SU model in throughout this chapter, what is referred to is the model specified in equation (\ref{eq2:RE.2}) with $D(\beta_n,X_t) = 1$.
This results in the SU model being homoscedastic.

If utilizing the logistic function, equation (\ref{eq2:RE.2}) resembles a latent index model popularly used in a variety of econometric applications, but with a non-linear latent index.
While equation (\ref{eq2:RE.2}) represents the common 2 option case, using the logistic cdf, the RE model can be rewritten to accomodate $J$ alternatives:
\begin{equation}
	\label{eq2:RE.f}
	{\Prob}(y_t=j) =\dfrac{\exp\!\left( \dfrac{ G(\beta_n,X_{jt}) }{ D(\beta_n,X_{t})\lambda_n }  \right)}{ \displaystyle\sum_{i=1}^J \left[ \exp\!\left( \dfrac{ G(\beta_n,X_{it}) }{ D(\beta_n,X_{t})\lambda_n }  \right)  \right]  }
\end{equation}

With the TR model the \enquote{observed} probability of choice, ${\Prob}(y_n=j)$, needs to be distinguished from the choice probability which would be modeled should the tremble not exist, ${\Prob}_0(y_n=j)$.
The agent is said to \enquote{tremble} with probability $\phi_n$ and select among the available options with equal probability, and with probability $(1-\phi_n)$ select an option according to the underlying process:
\begin{equation}
	\label{eq2:TR.f}
	{\Prob}(y_t=j) = (1-\phi) {\Prob}(y_t=j) + \frac{\phi}{J}
\end{equation}
When \textcite{Harless1994} proposed the TR model, the underlying choice process was made deterministic, assuming that ${\Prob}_0(y_t=1) = 1$.
\textcite{Loomes2002} however, proposed that ${\Prob}_0(y_t=j)$ was generated from the RP model as specified in equation (\ref{eq2:RP.f}).

\section{The Empirical Support for Stochastic Models}

The previous section provided for the econometric specification of the classes of stochastic models typically utilized in the literature to estimate parameters from choice data.
The choice of model to utilize however, has not been ad hoc;
because each stochastic model assigns very specific assumptions to the nature of the \enquote{noise} or randomness in choice data, these assumptions \enquote{amount to identifying restrictions which may affect the relative performance of the theories under scrutiny} \parencite[1091]{Ballinger1997}.
In much the same way as the various alternatives to EUT were proposed and then received rigorous testing, stochastic models have also been rigorously tested on the basis of their identifying restrictions.

\textcite{Ballinger1997} engaged in detailed tests of the SU and TR models, along with various assumptions about the heterogeneity of subjects, and find generally mixed results.
The various models must be combined with somewhat unsavory assumptions about the nature of the heterogeneity of the population to make them statistically plausible.
The TR model performs the worst, and requires the most assumptions.
Ultimately \textcite[1104]{Ballinger1997} conclude by continuing the call for development and testing of the stochastic component of choice.

\textcite{Carbone1997} investigates the RP model, in addition to the TR and SU models, by estimating each model for each subject in the experiment, and finds that the SU model performs the best of the three, with RP a close second.
\textcite[307]{Carbone1997} notes that if the set of alternative lotteries contains a lottery that stochastically dominates the others, the RP model requires the subject to always select the stochastically dominating lottery from the set, and that \enquote{this feature is of importance as it seems to capture well the experimental evidence.}
This feature of RP models, however, presents a problem when estimating preferences from choice data because although violations of FOSD typically constitute a relatively small fraction of choices observed in experiments, this small fraction is frequently replicated in experiments.

\textcite{Loomes1998} (LS) performed a similar investigation of the RP, TR, and SU models and strongly reject the TR model and to a lesser extent the SU model.
The SU model over-predicts violations of FOSD; however, they note, as \textcite{Carbone1997} did, that even one violation of stochastic dominance in a dataset is sufficient to cause the stand-alone RP model to collapse econometrically, and thus LS reject the model due to the few observations where stochastic dominance was violated.
LS note however that the RP model can potentially accommodate these violations if it is combined with another stochastic choice model, such as the TR model.
This point will be discussed in more detail subsequently.
LS also report systematic deviations from EUT at the edges of the \DIFdelbegin \DIFdel{Marshak-Machina }\DIFdelend \DIFaddbegin \DIFadd{Marschak-Machina }\DIFaddend triangle, and suggest that these cannot be fully accommodated by any of the stochastic models.
In these instances, they suggest it is EUT that fails, not the stochastic model.

\textcite{Loomes2002} also test the RP, TR, and SU models.
They recognize that \enquote{\textins*{t}here is no obvious reason to assume that only one of these forms of randomness is present} \parencite*[106]{Loomes2002}.{\footnotemark}
When faced with a choice situation, an agent may be best characterized as randomly drawing a preference from some set of preferences (RP model), evaluating the choice situation given that randomly drawn preference with some error (SU model), and then, with some positive probability, selecting an option irrespective of the agent's evaluation (TR model).
Practically, this means estimating additional parameters and making clear the identifying restrictions of any combination of these models, but mathematically these models are not mutually exclusive.{\footnotemark}

\addtocounter{footnote}{-2}
\stepcounter{footnote}\footnotetext{
	This is a point with which we only partly agree.
	While we agree that there isn't an obvious reason why some models cannot be jointly present, there \textit{is} an obvious restriction on combining stochastic models: normative coherence.
	As will be expanded on later, the RP model fails to satisfy this restriction.
}
\stepcounter{footnote}\footnotetext{
	To illustrate the combination of RP, RE, and TR models derived in equations (\ref{eq2:RP.f}), (\ref{eq2:RE.f}), and (\ref{eq2:TR.f}):
	\begin{align*}
		{\Prob}(y_t=j) = \frac{\phi}{J} + (1-\phi)\int_{\beta \in B_t}  {\Prob}\left(  \epsilon_t \geq \frac{1}{\lambda} \left[ G(\beta_n,X_{kt}) - G(\beta_n,X_{jt}) \right] \,\big|\, \beta \right) dF_n(\beta|\alpha)
	\end{align*}
	This model would require the estimation of $\alpha, \lambda$ and $\phi$.
}

\textcite{Loomes2002} report that the best fitting stochastic model was RP plus TR paired with RDU.
At least two other interesting conclusions were made: The estimated probability of TR diminished with the number of questions answered by the subjects, as did apparent deviations from EUT, and in addition, when pairs with one lottery that stochastically dominates the other are removed from estimation, it is no longer clear that the RP model is superior to the SU model.
This result suggests that \enquote{trembles} can be un-learned.
\textcite{Hey2001} and \textcite{Moffatt2002} report similar results from experiments where it appears that noise is reduced with repetition.
\textcite{Hey2001} also reports diminishing deviations from EUT with repetition.

Other than the prominent TR, SU, and RP models, there are a variety of alternatives that receive less attention, most of which are derivatives of the SU model with heteroscedastic error terms as opposed to the homoscedastic error of SU.{\footnotemark}
While TR and RP models can be manipulated in different ways to possibly explain more of the observed choice behavior,{\footnotemark} such attempts often leave underlying, core problems with these models unattended to.
For instance, if TR models predict that with some probability choices will be made irrespective of underlying preferences, why then should this probability vary depending on certain special cases of choice scenarios faced by the subject? Even with flexible distributions of RP models, there is no underlying utility theory which allows violations of FOSD, hence standard, stand-alone RP models can never accommodate such observed violations.{\footnotemark}
In contrast, the ability to manipulate the error term of the SU model in a tractable manner is part of what makes the SU model and its derivatives such popular models of stochastic choice.

\addtocounter{footnote}{-3}
\stepcounter{footnote}\footnotetext{ The SU model posits an error term with a variance that is independent of the domain of the utility function it is added to, thus it is said to be homoscedastic.
If the error term is correlated with some part of the domain of the utility function it is added to, it is said to be heteroscedastic.
There are many ways in which this correlation may occur, leading to a large variety of heteroscedastic models.}
\stepcounter{footnote}\footnotetext{ E.g, trembles could apply differently to FOSD pairs and non-FOSD pairs, RP models could assume flexible distributions of the agent's preferences such as the Logit-Normal or Gamma distributions.}
\stepcounter{footnote}\footnotetext{ However, non-standard RP models can sometimes accommodate violations of FOSD.
An example of this is a model which specifies agents as randomly drawing a new preference relation for every option in a set of alternatives instead of randomly drawing one preference relation per set of alternatives.
we will explore the implications of this type of model, which we call the Random Preference Per Option (RPPO) model, later.
For now, we will note that the RPPO model is very rarely utilized in the literature on stochastic models.}

To understand the motivations for developing the differing SU derivative models, we will briefly describe the concept of stochastic transitivity.
Borrowing from \textcite[210]{Wilcox2008}, consider three pairs of lotteries: $\{C,D\}$, $\{D,E\}$, and $\{C,E\}$, designated lotteries $1$, $2$, $3$, respectively.
$P_1$ is the probability of choosing $C$ in lottery $1$, and $P_2$ and $P_3$, are the probabilities of choosing $D$ and $C$ from lotteries $2$ and $3$, respectively.
We can define three forms of stochastic transitivity as follows:
\begin{align*}
	\text{Strong Stochastic Transitivity (SST):} \qquad \mathit{min}(P_1,P_2) \geq 0.5 &\Rightarrow P_3 \geq \mathit{max}(P_1,P_2) \\
	\text{Moderate Stochastic Transitivity (MST):} \qquad \mathit{min}(P_1,P_2) \geq 0.5 &\Rightarrow P_3 \geq \mathit{min}(P_1,P_2)\\
	\text{Weak Stochastic Transitivity (WST):} \qquad \mathit{min}(P_1,P_2) \geq 0.5 &\Rightarrow P_3 \geq 0.5
\end{align*}

Stochastic transitivity (ST) enforces a probabilistic form of transitivity for the same reasons that the non-stochastic transitivity axiom is employed for deterministic theories of choice: it is a mathematically convenient, and normatively useful way to model the choice process of a viable economic agent.
Its consequence is that agents must make choices in a way that are at least stochastically consistent with economic success in an incentivized environment.
Each version of ST makes descriptive and normative predictions which are operationalized by the stochastic model which incorporates them.
For each proposed model described below, a particular version of ST is utilized because of its perceived superiority either descriptively or normatively.
The SU model, for instance, requires SST, whereas most of the proposed derivatives of SU attempt to relax this requirement in favor of either MST or WST.

\textcite{Hey1995a} proposed three RE models with heteroscedastic error terms and conducted an experiment with 80 subjects to compare the heteroscedastic models to the homoscedastic SU model, (H.1).
In all three models, the Normal distribution was utilized for $F(\cdot)$.
The first heteroscedastic model, (\ref{eq2:Hey2}), modeled the variance of the error as an exponential function of the time taken by the subject to give an answer to the question $m$ and a corresponding coefficient:
\begin{align*}
	\tag{H.2}
	\label{eq2:Hey2}
	D(\beta_n,X) &= \exp(\alpha \times m)\\
	\lambda_n &= 1
\end{align*}
Thus if $\alpha > 0$, the longer (shorter) it takes a subject to answer the question, the more (less) \enquote{noisy} the subject's responses should be.

The second heteroscedastic model, (H.3), modeled the error as an exponential function of the absolute value of the difference in utility of the alternatives multiplied by a coefficient, $\alpha$:
\begin{align*}
	\tag{H.3}
	\label{eq2:Hey3}
	D(\beta_n,X) &= \exp\left(\alpha \times \lvert G(\beta_n,X_{kt}) - G(\beta_n,X_{jt}) \rvert\right)\\
	\lambda_n &= 1
\end{align*}
Thus, if $\alpha < 0$, the larger the difference in utility of the alternatives, the smaller the noise.

The third heteroscedastic model, (H.4), modeled the error as an exponential function of the \enquote{difficulty} of the question, $d$, multiplied by a coefficient, $\alpha$.
In this specification, $d$ is the average number of outcomes per option in the set of alternatives.
\begin{align*}
	\tag{H.4}
	\label{eq2:Hey4}
	D(\beta_n,X) &= \exp(\alpha \times d)\\
	\lambda_n &= 1
\end{align*}
Thus, if $\alpha > 0$, the greater (smaller) the average number of outcomes per option, the greater (smaller) the noise.
All of the heteroscedastic models nest the homoscedastic SU model as a special case (when $\alpha=0$).
While (\ref{eq2:Hey3}) and (\ref{eq2:Hey4}) did not perform particularly well, (H.1) was rejected in favor of (\ref{eq2:Hey2}) for 27 of 80 subjects at the 1\% level, and 36 subjects at the 5\% level \parencite*[639]{Hey1995a}.

Another derivative called the \enquote{Wandering Vector} (WV) model was proposed initially by \textcite{Carroll1980} and expanded on by \textcite{Carroll1991}.
It makes the standard deviation of the error proportional to the Euclidean distance of the probability vectors of the two alternative lotteries, $j$ and $k$.
\begin{align*}
	D(\beta_n,X) = \left[  \sum_{i=1}^I (p_i^j - p_i^k)^2 \right]^{1/2}
\end{align*}
The original rationale for this model was to incorporate MST into a stochastic model: \enquote{for many realistic multidimensional stimulus domains, SST seems \textit{too} strong.
On the other hand, WST seems too weak.} [emphasis in the original] \parencite*[343]{Carroll1991}.
This model was proposed in the psychology literature to accommodate noisy perceptions of multidimensional stimuli, but this can be utilized as an economic model by reinterpreting the noisy perception of stimuli as noisy measurement of utility.

\textcite{Wilcox2011} expands on the \enquote{Contextual Utility} (CU) model initially proposed in \textcite{Wilcox2008}.
It makes the standard deviation of the error proportional to the difference in utility of the greatest non-zero probability outcome and the utility of the least non-zero probability outcome.
\begin{align*}
	\label{eq2:W.cu}
	\begin{split}
		&D(\beta_n,X_t) = \mathit{max}[u(x_{it})] - \mathit{min}[u(x_{it})]\\
		&\mathit{st.}\; w_i(x_{it}) \neq 0
	\end{split}
\end{align*}
This model also satisfies MST and additionally allows for the \enquote{more risk averse than} relation of \textcite{Pratt1964} to be extended to the stronger \enquote{stochastically more risk averse than} relation.
The \enquote{stochastically more risk averse than} relation of the CU model allows for interpersonal comparisons of risk-aversion in a way that is potentially more meaningful than with the SU model \parencite*[221]{Wilcox2008}.

\textcite{Busemeyer1993} propose \enquote{Decision Field Theory} (DFT), which is limited in that it is only applicable to a pair of alternatives where one alternative is a certainty and the other is a lottery of only 2 outcomes.
If we define the set of outcomes that belong to the lottery as $H = \{x \in X_j \,|\, p_x < 1\} = \{h_1,h_2\}$ where $h_2 > h_1$ we have:
\begin{align*}
	D(\beta_n,X) = \left[ u(h_2) - u(h_1) \right] \sqrt{w_{h_1}(p)[1-w_{h_2}(p)]}
\end{align*}
The reasoning behind DFT is ultimately psychological.
\textcite{Busemeyer1993} posit that in cases where objective probabilities of outcomes are unknown, an agent may sample from past experiences with the same decision problem to estimate what the objective probabilities are.
This kind of decision problem is deemed choice under \enquote{uncertainty} rather than choice under \enquote{risk}.
\enquote{Decision field theory was developed for this more natural type of uncertain decision problem} \parencite*[436]{Busemeyer1993}.

\textcite{Blavatskyy2014} proposes a model (BF) deemed \enquote{Stronger Utility} similar to the \enquote{incremental EU advantage model} initially proposed by \textcite{Fishburn1987}.
It makes the standard deviation of the error proportional to the difference in the utility of two abstract lotteries.
The first abstract lottery is constructed to stochastically dominate all lotteries in the proposed decision scenario, but can itself be stochastically dominated by any other lottery which also scholastically dominates the proposed lotteries.
The second abstract lottery is constructed to be stochastically dominated by both lotteries proposed in the decision scenario, while stochastically dominating any other lottery which is also stochastically dominated by both of the proposed lotteries.
For FOSD pairs, this specification attaches a probability of 1 to the dominating option and 0 to the dominated  option.

The three models proposed by \textcite{Hey1995} don't make any special predictions about the likelihood of choosing options in particular scenarios, such as with FOSD pairs, other than to hypothesize that they will improve on the explanatory fit of the SU model.
They also require the estimation of additional parameters.
The (H.2) and (H.4) models are very similar to the method utilized by \textcite[142]{Harrison2008a} in which observable characteristics are modeled as linear covariates of the core parameters to be estimated.
However, \textcite{Hey1995} models the standard deviation to be exponential functions of these observable characteristics instead of linear functions, making the heteroscedasticity multiplicative rather than additive.
The linear specification utilized by \textcite{Harrison2008a} is used to control for observable heterogeneity of subjects, not aspects of the choice scenario.
Hey's (H.3) model, however, seems to be in the same line of thinking as the subsequent derivatives of the SU model.

The other RE models mentioned above, however, often do add new implications which generally help ease some of the shortcomings of the SU model.
The CU and the DFT models both have the benefit of extending the \enquote{more risk averse than} relation of \textcite{Pratt1964} to the \enquote{stochastically more risk averse than} relation.
DFT additionally requires that as the lottery becomes closer to first order stochastically dominating the {\CE}, the probability of selecting the dominant option approaches 1.
The BF model also requires that the probability of selecting the dominant option is always 1.
Both the WV and the CU models enforce MST as opposed to the more restrictive strong SST,  as required by SU models.
The CU, WV, DFT, and BF models don't require the estimation of any additional parameters on top of those required by the SU model, so any improvement of explanatory fit by them is free in terms of degrees of freedom used in estimation.

\textcite{Wilcox2008} provides a detailed discussion of the necessary implications of the TR, RP,  and SU models, along with some of the SU model's derivatives.
He also discusses various well known events which can sometimes be attributed to stochasticity in choice: the Common Ratio Effect, low-frequency, but persistent, violations of FOSD, and changes in choice probabilities when lotteries are simply scaled.{\footnotemark}
Treatment is also given to whether models hold to various degrees of stochastic transitivity, whether they are descriptive about the \enquote{more risk averse than} relation, and how well the various models perform at predicting in-sample and out-of-sample choices.{\footnotemark}

\addtocounter{footnote}{-2}
\stepcounter{footnote}\footnotetext{ Borrowing again from \textcite[249]{Wilcox2008}: Consider four pairs of lotteries, $\{C,E\}$, $\{D,E\}$,$\{C,E'\}$, $\{D,E'\}$, and make the probability of selecting the first lottery in pair $\{C,E\}$, $P_{\mathit{ce}}$, and similarly for the remaining pairs.
Simple Scalability requires that $P_{\mathit{ce}} > P_{\mathit{de}} \iff P_{\mathit{ce}'} > P_{\mathit{de}'}$.
This requirement is only met by transitive utility structures, such as EUT and RDU, combined with stochastic models that meet SST.}
\stepcounter{footnote}\footnotetext{ This particular topic was given extensive attention in \textcite{Wilcox2007}}

\textcite{Wilcox2008} estimates WV, CU, RP, SU, and an early variation of SU proposed by \textcite{Luce1958} called \enquote{Strict Utility} on the dataset from \textcite{Hey2001}.
He employs the  method developed by \textcite{Vuong1989} to test if the log-likelihoods of the fitted models are significantly different from each other.
\textcite[273]{Wilcox2008} finds that given an RDU structure, the CU model fits significantly better ($p=0.013,p<0.0001$) than the WV and \enquote{Strict Utility} models in-sample, and significantly better ($p<0.0001, p=0.0005, p<0.0001, p<0.0001$) than the SU, RP, WV, and \enquote{Strict Utility} models out-of-sample.
Given an RDU structure, the RP model fits significantly better ($p=0.0388,p<0.0001$) than the WV and \enquote{Strict Utility} models in-sample, and significantly better ($p=0.049, p<0.0191, p<0.0001$) than the SU, WV, and \enquote{Strict Utility} models out-of-sample.
Neither the CU or RP models fit significantly better or worse than the SU model in-sample with a RDU structure.
In all cases where the CU and RP models both fit better than a third model, the CU model fits better by a greater margin than the RP model.

With an EUT structure, the CU model significantly bests every model except the SU model in-sample, and bests every model out-of-sample, while the RP model fits significantly worse ($p<0.058$) than the SU model and only bests the \enquote{Strict Utility} significantly ($p<0.0001$) in-sample, but fits significantly better ($p=0.051,p=0.016,p=0.078$) than the SU, WV, and \enquote{Strict Utility} models out-of-sample.
In addition to fitting better than the RP model in a direct comparison, the CU model fits better than every other model that the RP model also bests, and by a greater margin than the RP model.

From these results it is clear that \enquote{Strict Utility} is a poor model in terms of goodness of fit given the alternatives: it doesn't significantly fit better than any alternative model, regardless of the utility theory, either in-sample or out-of-sample.
The WV model only does marginally better: the only model it fits significantly better than is the \enquote{Strict Utility} model.

The more interesting story in light of the literature up to this point is the comparison of the SU, CU, and RP models.
Considering in-sample fit, the SU model fits significantly better than the RP model with EUT, and with RDU there is no significant difference in goodness of fit.
Out-of-sample the RP model fits  significantly better than the SU model under both EUT and RDU.
This echos some of the mixed evidence up to this point concerning which of these two models is superior.
New to the competition are the various SU derivatives.
Two of these, the WV and \enquote{Strict Utility} models, perform relatively poorly in goodness of fit compared to the alternatives, but CU is shown to have generally superior performance compared to all the proposed models.
The CU model has a greater log-likelihood than than all of the other models in all of the various test conditions: in-sample or out-of-sample, with EUT or RDU.
This difference is statistically significant for many of the comparisons as noted above.

This discussion is not meant to be an exhaustive list of every proposed derivative of the SU model and their implications.
Such a list would be very long and many of these derivative models deserve detailed discussion in their own right.
This discussion simply serves to demonstrate that, as put by \textcite[277]{Wilcox2008}, \enquote{we are witnessing a fertile period for stochastic model innovation now.}
Nearly all of this innovation has come from the RE class of models by changing the error term in the SU model from being homoscedastic to heteroscedastic, in very particular ways that have testable implications.
The only apparent non-SU derived innovation was to combine the TR model with the RP model to help explain the low-frequency, but persistent, violations of FOSD observed in economic experiments.{\footnotemark}
Given the variety of theoretical implications of the various stochastic models and the repeatedly demonstrated sensitivity of goodness of fit measures to alternative stochastic models, it is no wonder that \textcite[275]{Wilcox2008} concludes: \enquote{It is hard to escape the conclusion that decision research could benefit strongly from more work on stochastic models.}

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{ This combination of models however is not an innovation to the RP model in itself as such a combination is just as possible with the SU model and any of its derivatives.
As stated earlier, such a combination fails to address a core problem with the RP model: normative coherence.}

While such a conclusion is undoubtedly true, there is a question relevant to economics concerning these models which has been sidelined in the continuing effort to find the \enquote{true} or \enquote{best} stochastic model: \enquote{What are the likely welfare implications of an economic agent's choices in an incentivized environment given an assumed stochastic model of choice?} This is the primary question of this chapter.
Answering this question helps to draw the distinction between economics and decision theory or psychology.
We will argue that answering this question puts reasonable, restricting conditions on the econometric question \enquote{what is the best stochastic model to employ?}

\section{Utility and its Relation to Welfare}

With the RDU structure defined, and the stochastic models specified, we can define the basis of what will become our proposed metrics for individual welfare: the certainty equivalent.
For any salient lottery $X_j$, and any vector $\beta_n$, there exists some certain outcome, $\CE_j$, such that subject $n$ is indifferent between the lottery and the certainty equivalent:
\begin{equation}
	\label{eq2:CE.indiff}
	X_j \sim^n {\CE}_j \;\Leftrightarrow\; G(\beta_n,X_j) = G(\beta_n, {\CE}_j)
\end{equation}

Combining the RDU structure from equation (\ref{eq2:RDU}) with the utility function defined in equation (\ref{eq2:CRRA}), we can define the {\CE} as follows:
\begin{align}
	\label{eq2:CEcalc}
	\begin{split}
		&\sum_{i=0}^{I-1} w_i(p) \frac{x_{ij}^{(1-r)}}{(1-r)} = \frac{ {\CE}_j^{(1-r)}}{(1-r)}\\
		&{\CE}_j =  \left( (1-r) \times \sum_{i=0}^{I-1} w_i(p) \frac{x_{ij}^{1-r}}{(1-r)} \right)^{ \displaystyle\nicefrac{1}{(1-r)} }
	\end{split}
\end{align}

Thus if we assume some vector of $\beta_n$, of which $r$ and the parameters governing $w_i(p)$ are elements, we can easily calculate the {\CE} of lottery $X_j$.{\footnotemark}
If the utility function employed is monotonically increasing in the domain, as the CRRA function is, then this leads to the  logical corollary of equation (\ref{eq2:utilityrank}):
\begin{equation}
	\label{eq2:CErank}
	{\CE}_{n1} \geq {\CE}_{n2} \geq \ldots \geq {\CE}_{nj} \geq \ldots \geq {\CE}_{nJ}
\end{equation}

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{ In general, the {\CE} of any lottery can easily be calculated with numerical methods even if an analytical solution doesn't exist.
This is because the {\CE} must lie in the interval between the lowest outcome and the highest outcome.
Numerically, one can just iterate through this interval until equation (\ref{eq2:CEcalc}) is satisfied, or employ an optimization routine to look for the {\CE} directly.}

With equations (\ref{eq2:CEcalc}) and (\ref{eq2:CErank}), we can also see that the {\CE} can itself be considered a utility function: it is complete, transitive, and continuous, which is all that is required for a utility function to be well defined.
Utilizing the {\CE}s of options in a task is useful because of its ability to be considered a utility function, but also because it allows utility to be normalized to the units of the outcomes.

We can employ the notation used for the set of unchosen alternatives, $Z$, derived in equation (\ref{eq2:emptyset}), to rank the ${\CE}$s of each unchosen alternative just as in equation (\ref{eq2:Zutilityrank}):
\begin{equation}
	\label{eq2:CEZ}
	{\CE}_{n1}^Z \geq {\CE}_{n2}^Z \geq \ldots \geq {\CE}_{nj}^Z \geq \ldots \geq {\CE}_{n(J-1)}^Z
\end{equation}

Utilizing these {\CE}s, four metrics are proposed to help measure welfare.
If an agent with deterministic preferences and a deterministic choice process is presented with two lotteries to chose from, $X_1$ and $X_2$, she would choose $X_1$ and receive a welfare change of ${\CE}_1 - {\CE}_2$.
This is the thought behind the first metric.
With this metric, a change in welfare is measured as the difference between the {\CE} of the option chosen and the {\CE} of the highest ranked alternative option:
\begin{equation}
	\label{eq2:WCt}
	\Delta W_{nt} = {\CE}_{nyt} - {\CE}_{n1t}^Z = {\CE}_{nt}^R
\end{equation}

This welfare metric is similar to the notion of compensating equivalence in standard consumer theory.
If equation (\ref{eq2:WCt}) is positive, it calculates the minimum amount of money the agent would need to be compensated in order to change her choice.
If this metric is negative, it calculates the maximum the agent should be willing to pay in order to change her choice.

Another metric, which also utilizes the {\CE}s, characterizes welfare received by choosing an option as a proportion of the {\CE} of the option chosen and the {\CE} that was ranked highest in the task:
\begin{equation}
	\label{eq2:WPt}
	\%W_{nt} = \frac{ {\CE}_{ny} }{ {\CE}_{n1} }
\end{equation}

\noindent A variation of (\ref{eq2:WCt}) which can be used to make statements about welfare across tasks could be:
\begin{equation}
	\label{eq2:WCT}
	\Delta W_{nT} = \sum_{t=1}^T \left( {\CE}_{nyt} - {\CE}_{n1t}^Z \right)
\end{equation}

\noindent A similar variation of (\ref{eq2:WPt}) could be:
\begin{equation}
	\label{eq2:WPT}
	\%W_{nT} = \frac{\displaystyle\sum_{t=1}^{T} {\CE}_{ny} }{\displaystyle\sum_{t=1}^{T} {\CE}_{ny}}
\end{equation}

All of these metrics have strengths and weaknesses.
Metric (\ref{eq2:WCt}) is more relevant to the case of deterministic choice as it can change from task to task, while metrics (\ref{eq2:WPt}) and (\ref{eq2:WPT}) will become more relevant when discussing stochastic choice models and modest claims about inter-subject welfare.
Any agent would be best off by making a choice which maximizes either of these metrics.

\subsection{Special Case of Random Preferences: The Random Preference Per Option Model}

Before beginning the discussion of welfare, a final model belonging to the RP class will be noted which requires a more involved explanation.
It could be the case that an agent's choices are best characterized by a version of the RP model where a different $\beta^*_{nj}$ is drawn to evaluate every option in the set of alternatives.
We will refer to this type of RP model as the \enquote{Random Preference Per Option} (RPPO) model.

When evaluating option $j$, a standard preference relation is drawn from a distribution of preference relations that ranks all the $J$ alternatives, including option $j$, according to this preference relation:
\begin{equation}
	\label{eq2:RPPO.jorank}
	X_{1t} \succcurlyeq^{nj} X_{2t} \succcurlyeq^{nj} \ldots \succcurlyeq^{nj} X_{jt} \succcurlyeq^{nj} \ldots \succcurlyeq^{nj} X_{Jt}
\end{equation}

\noindent A utility function exists which represents these preference relations is shaped by $\beta_n^j$:
\begin{equation}
	\label{eq2:RPPO.jurank}
	G(\beta_n^j,X_{1t}) \geq G(\beta_n^j,X_{2t}) \geq \ldots \geq G(\beta_n^j,X_{jt}) \geq \ldots \geq G(\beta_n^j,X_{Jt})
\end{equation}

As was shown in equation (\ref{eq2:CEcalc}), a {\CE} can be calculated for each of these $\beta_n^j$ conditional utility functions such that:
\begin{equation}
	\label{eq2:RPPO.jCErank}
	{\CE}^j_{n1} \geq {\CE}^j_{n2} \geq \ldots \geq {\CE}^j_{nj} \geq \ldots \geq {\CE}^j_{nJ}
\end{equation}

In equations (\ref{eq2:RPPO.jorank}), (\ref{eq2:RPPO.jurank}), and (\ref{eq2:RPPO.jCErank}), the ordinal ranking of the set of alternatives is the same.
As stated previously, the {\CE} of an option has the same utility function properties as $G(\cdot)$, and is additionally normalized by the units of the options themselves.
If only one $\beta_n$ vector is drawn to derive cardinal values for the set of alternatives, we have the RP model discussed previously.

But, with RPPO models, when evaluating another option $k$, such that $k \neq j$, another, potentially different, preference relation is drawn and all of the $J$ alternatives, including both $j$ and $k$, are ranked according to this preference relation:
\begin{equation}
	\label{eq2:RPPO.korank}
	X_{1t} \succcurlyeq^{nk} X_{2t} \succcurlyeq^{nk} \ldots \succcurlyeq^{nk} X_{jt} \succcurlyeq^{nk} \ldots \succcurlyeq^{nk} X_{Jt}
\end{equation}

\noindent A utility function exists which represents these preference relations shaped by $\beta_n^k$:
\begin{equation}
	\label{eq2:RPPO.kurank}
	G(\beta_n^k,X_{1t}) \geq G(\beta_n^k,X_{2t}) \geq \ldots \geq G(\beta_n^k,X_{jt}) \geq \ldots \geq G(\beta_n^k,X_{Jt})
\end{equation}

\noindent And again, a {\CE} can be calculated for each of these $\beta_n^k$ conditional utility functions such that:
\begin{equation}
	\label{eq2:RPPO.kCErank}
	{\CE}^k_{n1} \geq {\CE}^k_{n2} \geq \ldots \geq {\CE}^k_{nj} \geq \ldots \geq {\CE}^k_{nJ}
\end{equation}

The difference between the realizations of equations (\ref{eq2:RPPO.jCErank}) and (\ref{eq2:RPPO.kCErank}) is twofold.
First, the different $\beta_n^*$ vectors may lead to different ordinal rankings of the same set of alternatives.
Second, if $\beta_n^j \neq \beta_n^k$, then there may be two different cardinal evaluations for the same option.

The RPPO model takes the cardinal value of each option, evaluated using its own $\beta_n^*$  vector, and constructs an ordinal ranking of the set of alternatives based on these individual evaluations.
To deal with the potential issue of comparing different utility functions cardinally, the utility functions $G(\cdot)$ should be normalized somehow.{\footnotemark}
In line with the previous discussion, we will assume a normalizing function which produces a {\CE} for each option based on its individually drawn $\beta_n^*$ vector.

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{ Without the normalization, the RPPO model requires an unusual interpretation of preference relations to accommodate particular aspects of relatively common $G(\cdot)$ functions.
An example will be presented later that will make this clearer.}

Adding the superscripts $\{1,2,\ldots,x,\ldots,X\}$  to the {\CE} to indicate the option that it is associated with, and the subscripts $\{1,2,\ldots,j,\ldots,J\}$ to the {\CE} to represent its rank in the set of alternatives conditional on its individual $\beta_n^x$ vector, we could have the following ordinal ranking:
\begin{equation}
	\label{eq2:RPPO.CErank.f}
	{\CE}^1_{n1} \geq {\CE}^2_{n2} \geq \ldots \geq {\CE}^x_{nj} \geq \ldots \geq {\CE}^X_{nJ}
\end{equation}

Notice that the superscripts match the subscripts in this example, but this need not always be the case.
The superscripts represent the unranked options, while the subscripts represent the RPPO ranked options.
The following could also represent an ordinal ranking from the RPPO model:
\begin{equation}
	\label{eq2:RPPO.CErank.a}
	{\CE}^3_{n1} \geq {\CE}^1_{n2} \geq \ldots \geq {\CE}^x_{nj} \geq \ldots \geq {\CE}^X_{nJ}
\end{equation}

The RPPO model, as discussed here, is characterized as having random preference parameters, but is otherwise deterministic in characterizing choice.
That is, this RPPO model characterizes an agent as choosing the option with the highest individually evaluated {\CE}.
Just as with the RP model, additional stochasticity can be imposed by including measurement error as with RE models and/or a tremble event as with TR models.
For now, these additional elements create unnecessary mathematical complexity for the current discussion, but they will be touched on briefly later.
Just as in equation (\ref{eq2:emptyset}), the non-chosen options can be expressed as the set of $J-1$ alternatives in task $t$ that doesn't include the chosen option:
\begin{equation}
	\label{eq2:RPPO:emptyset}
	Z = t \,\backslash\, y = \{z \in t \;|\; z \notin y \}
\end{equation}


\noindent The RPPO model therefore constructs a choice function as follows:
\begin{equation}
	\label{RPPO.y0}
	y_t = x \Leftrightarrow {\CE}_{nj}^x \geq {\CE}_{nk}^z \quad \forall z \in Z
\end{equation}

That is, $y_t$ is a function that indicates that option $x$ is chosen in task $t$ if and only if the {\CE} associated with option $x$ is greater than or equal to the {\CE} of any other option $z$.
The probability of $y_t = x$ is determined by the joint probability of observing the set $\bigl\{\beta_n^x,\{\beta_n^Z\}\bigr\}$, such that:
\begin{equation}
	\label{eq2:RPPO.y1}
	{\CE}(\beta_n^x,X_{1t}) \geq {\CE}(\beta_n^z,X_{jt}) \forall z \in Z
\end{equation}

\noindent Call such a set $\mathbf{B^t_n}$.
The probability of $y_t=x$ is therefore:
\begin{equation}
	{\Prob}(y_t=x) = \int_{\beta_n^x \in \mathbf{B^t_n}}\int_{\beta_n^Z \in \mathbf{B^t_n}} f_{\mathbf{B^t_n}}\!\left(\beta_n^x,\{\beta_n^Z\}|\alpha\right) \;d\beta_n^x \; d\beta_n^Z
\end{equation}

\noindent where $f_{\mathbf{B^t_n}}(\beta_n^x,\{\beta_n^Z\}|\alpha)$ is the joint density of the elements of $\mathbf{B^t_n}$, the shape of which is governed by the vector $\alpha$.

\section[The Stochastic Money Pump: A Tool for Describing Welfare \texorpdfstring{\\}{}Accumulation]{The Stochastic Money Pump: A Tool for Describing Welfare\\Accumulation}

With the various classes of stochastic models defined, we will begin the discussion of the welfare implications of these models by first introducing a decision problem which resembles the \enquote{Money Pump} argument against intransitive structures which exists with deterministic choice theory, though with several important distinctions that will be made clear later.
We will refer to this relatively simple thought experiment as a \enquote{Stochastic Money Pump} (SMP).
Assume that there is an experimental economist who, through cleverly selected choice problems, is able to correctly identify the utility structure and stochastic process governing the choices of subjects with perfect knowledge.
That is, the utility structure and relevant parameters $\beta_n$, as well as the correct stochastic model and relevant parameters that completely characterize some subject $n$ are all known by the experimenter.

The experimenter then offers to sell a lottery ticket to the subject for some amount of money, and should the subject agree to buy the ticket, the experimenter offers to buy the ticket back from the subject for a lower amount of money.
The subject can refuse the initial purchase, buy the ticket and refuse to sell the ticket back, or buy the ticket and sell it back to the experimenter.
How often is the experimenter successful in extracting the difference between the buying and selling price of the ticket from the subject without giving the subject anything, and what are the welfare implications of this pair of transactions?
The various classes of stochastic models can all have different welfare implications while predicting similar observed choice behavior.

To make this example concrete, we can work this problem out numerically assuming 3 different subjects, Amy, Beth, and Cate.
Amy operates with a random preference model of choice, Beth operates with a contextual utility model of choice, and Cate makes choices deterministically but with a tremble.
Amy, Beth, and Cate all have the same utility structure of the RDU special case where $w_i(p)=p_i$ for all $p_i$ and incorporate the CRRA utility function from equation (\ref{eq2:CRRA}).
Amy's distribution function $F_n(\beta|\alpha)$ is $N(\mu,\sigma^2) = N(0,0.01)$, thus normal with $\alpha$ featuring a mean equal to 0 and a standard deviation of 0.1.
Beth operates a $\beta$ vector that is composed of $r=0$, and a $\lambda_n = 0.015$.
Cate operates with a $\beta$ vector that is composed of $r=0$ and a probability of trembling of $\phi = 0.816$.
All values picked in this example are for ease of calculation, but the following implications hold when generalized to different parameter values.

The lottery ticket has a 0.5 probability of an outcome of 10 and a 0.5 probability of an outcome of 100, and thus an expected value of 55.
The experimenter offers to sell each of the subjects the lottery for 55.50, and to buy the lottery back at 54.50.
These values are 0.50 above and below the {\CE} of the lottery for Beth and Cate, and  0.50 above and below the mean {\CE} of the lottery for Amy.
The probability of the experimenter successfully extracting money costlessly is approximately equal for all three subjects:

\begin{equation}
	\label{eq2:pr.extraction}
	{\Prob}(\mathit{Extraction}) = {\Prob}(\mathit{Buy}) \times {\Prob}(\mathit{Sell}) \approx 0.167
\end{equation}

\noindent The manner in which the this probability is reached is different for each subject:

\noindent For Amy,
\begin{align}
	\label{eq2:Amy}
	\begin{split}
		B_{\mathit{Buy}} &= \{ \beta_A |\; G(\beta_A,X_{\mathit{Lottery}}) \geq G(\beta_A,X_{\mathit{Buy price}})\}\\
		&= \{ r_A \big|\; r \leq -0.0232 \} \\
		B_{\mathit{Sell}} &= \{ \beta_A |\; G(\beta_A,X_{\mathit{Sell price}}) \geq G(\beta_A,X_{\mathit{Lottery}})\}\\
		&= \{ r_A \big|\; r \geq 0.0232 \} \\[0.5ex]
		{\Prob}(y_{\mathit{Buy}}=\mathit{Buy}) &= \int_{\beta \in B_{\mathit{Buy}}} dF_A(\beta|\alpha) = \phi(B_{\mathit{Buy}},0,0.01)\\[0.5ex]
		&\approx 0.408 \\
		{\Prob}(y_{\mathit{Sell}}=\mathit{Sell}) &= \int_{\beta \in B_{\mathit{Buy}}} dF_A(\beta|\alpha) = \phi(B_{\mathit{Sell}},0,0.01)\\[0.5ex]
		&\approx 0.408 \\
		{\Prob}(\mathit{Extraction}_A) &= {\Prob}(y_{\mathit{Buy}} = \mathit{Buy}) \times {\Prob}(y_{\mathit{Sell}} = \mathit{Sell})\\
		&\approx .167
	\end{split}
\end{align}

\noindent where $\phi$ is the cumulative normal distribution.

\noindent For Beth,
\begin{align}
	\label{eq2:Beth}
	\begin{split}
	D(\beta_B,X) \times \lambda_B &= 0.015[u(100) - u(10)] \times 1\\
	&= 1.35 \\
	{\Prob}(y_{\mathit{Buy}} = \mathit{Buy}) &=\dfrac{\exp\!\left( \dfrac{ G(\beta_B,X_{\mathit{Lottery}}) }{ D(\beta_B,X)\lambda_B }  \right)}{ \exp\!\left( \dfrac{ G(\beta_B,X_{\mathit{Lottery}}) }{ D(\beta_B,X)\lambda_B }  \right) + \exp\!\left( \dfrac{ G(\beta_B,X_{\mathit{Buy\ price}}) }{ D(\beta_B,X)\lambda_B }  \right)  }\\[0.5ex]
	&\approx 0.408 \\
	{\Prob}(y_{\mathit{Sell}} = \mathit{Sell}) &=\dfrac{\exp\!\left( \dfrac{ G(\beta_B,X_{\mathit{Sell\ price}}) }{ D(\beta_B,X)\lambda_B }  \right)}{ \exp\!\left( \dfrac{ G(\beta_B,X_{\mathit{Lottery}}) }{ D(\beta_B,X)\lambda_B }  \right) + \exp\!\left( \dfrac{ G(\beta_B,X_{\mathit{Sell\ price}}) }{ D(\beta_B,X)\lambda_B }  \right)  }\\[0.5ex]
	&\approx 0.408 \\
	{\Prob}(\mathit{Extraction}_B) &= {\Prob}(y_{\mathit{Buy}} = \mathit{Buy}) \times {\Prob}(y_{\mathit{Sell}} = \mathit{Sell})\\
	&\approx .167
	\end{split}
\end{align}

\noindent For Cate,
\begin{align}
	\label{eq2:Cate}
	\begin{split}
		{\Prob}_0(y_{\mathit{Buy}}) &=
		\begin{cases}
			1 &, \quad G(\beta_C,X_{\mathit{Lottery}}) > G(\beta_C,X_{\mathit{Buy\ price}})\\
			0.5 &, \quad G(\beta_C,X_{\mathit{Lottery}}) = G(\beta_C,X_{\mathit{Buy\ price}})\\
			0 &, \quad G(\beta_C,X_{\mathit{Lottery}}) < G(\beta_C,X_{\mathit{Buy\ price}})
		\end{cases} \\
		{\Prob}_0(y_{\mathit{Sell}}) &=
		\begin{cases}
			1 &, \quad G(\beta_C,X_{\mathit{Sell\ price}}) > G(\beta_C,X_{\mathit{Lottery}})\\
			0.5 &, \quad G(\beta_C,X_{\mathit{Sell\ price}}) = G(\beta_C,X_{\mathit{Lottery}})\\
			0 &, \quad G(\beta_C,X_{\mathit{Sell\ price}}) < G(\beta_C,X_{\mathit{Lottery}})
		\end{cases}\\
		{\Prob}(y_{\mathit{Buy}}&=\mathit{Buy}) = (1-\phi) {\Prob}_0(y_{\mathit{Buy}}) + \frac{\phi}{J}\\
		&=(1-0.816)(0) + (0.816)/2\\
		&=0.408\\
		{\Prob}(y_{\mathit{Sell}}&=\mathit{Sell}) = (1-\phi) {\Prob}_0(y_{\mathit{Sell}}) + \frac{\phi}{J}\\
		&=(1-0.816)(0) + (0.816)/2\\
		&=0.408\\
	{\Prob}(\mathit{Extraction}_C) &= {\Prob}(y_{\mathit{Buy}} = \mathit{Buy}) \times {\Prob}(y_{\mathit{Sell}} = \mathit{Sell})\\
	&\approx .167
	\end{split}
\end{align}

While the observed choice behavior is identical for all three subjects, the welfare implications are not.
According to the metrics defined by equations (\ref{eq2:WCt}) and (\ref{eq2:WPt}), this decision problem has the same welfare implications for Beth and Cate:
\begin{align}
	\label{eq2:BCwelfare}
	\begin{split}
		\Delta W_{(B,C),\mathit{Buy}} = {\CE}_{(B,C),\mathit{Lottery}} - {\CE}_{(B,C),\mathit{Buy\ Price}} &= 55 - 55.5 = -0.50\\
		\Delta W_{(B,C),\mathit{Sell}} = {\CE}_{(B,C),\mathit{Sell\ Price}} - {\CE}_{(B,C),\mathit{Lottery}} &= 54.5 - 55 = -0.50\\
		\% W_{(B,C),\mathit{Buy}} = \frac{{\CE}_{(B,C),\mathit{Lottery}}}{{\CE}_{(B,C),\mathit{Buy\ Price}}} &= \frac{55}{55.5} \approx 0.99\\
		\% W_{(B,C),\mathit{Sell}} = \frac{{\CE}_{(B,C),\mathit{Sell\ Price}}}{{\CE}_{(B,C),\mathit{Lottery}}} &= \frac{54.5}{55} \approx 0.99
	\end{split}
\end{align}

In this case, the welfare implications of such decision problem are clear for both the TR and RE  models: with a roughly $0.167$ probability, Beth and Cate will make 2 consecutive \enquote{mistakes} or \enquote{choice errors}, which results in 1 unit of money and 1 unit of {\CE} being extracted from each of them.

The other potential results are easy to calculate.
With a ${1- {\Prob}(y_{\mathit{Buy}}} = \mathit{Buy}) = 0.592$ probability, Beth and Cate make no mistakes and experience a welfare gain:
\begin{align}
	\begin{split}
		\Delta W_{(B,C),\mathit{Buy}} &= {\CE}_{(B,C),\mathit{Buy\ Price}} - {\CE}_{(B,C),\mathit{Lottery}} = 55.5 - 55 = 0.50\\
		\% W_{(B,C),\mathit{Buy}} &= \frac{{\CE}_{(B,C),\mathit{Buy\ Price}}}{{\CE}_{(B,C),\mathit{Buy\ Price}}} = \frac{55.5}{55.5} = 1
	\end{split}
\end{align}

With a $ {\Prob}(y_{\mathit{Buy}} = \mathit{Buy})(1 - {\Prob}(y_{\mathit{Sell}}= \mathit{Sell})) \approx 0.242$ probability, Beth and Cate make the mistake of buying the lottery ticket, but not the mistake of selling it back for less:
\begin{align}
	\begin{split}
		\%W_{(B,C),T} &= \frac{\displaystyle\sum_{t=1}^{T} {\CE}_{(B,C),y,t} }{\displaystyle\sum_{t=1}^{T} {\CE}_{(B,C),1,t}} = \frac{55 + 55}{55.5 + 55} \approx 0.995 \\
		\Delta W_{(B,C),T} &= \sum_{t=1}^T \left( {\CE}_{(B,C),y,t} - {\CE}_{(B,C)1,T}^Z \right)= \genfrac{}{}{0pt}{}{55 - 55.5}{+ 55.5 - 55} = 0
	\end{split}
\end{align}

The RP model characterizing Amy's choices, however, does not result in an intuitive understanding of the welfare implications of this decision problem.
The RP model discussed here, the stand-alone RP model, requires that every choice by Amy be characterized by a deterministic preference relation according to some vector $\beta_A$ randomly drawn from a distribution.
Thus:
\begin{align}
	\label{eq2:RP.welfare}
	\begin{split}
		\Delta W_{(A),\mathit{Buy}} &= {\CE}_{(A),\mathit{Lottery}} - {\CE}_{(A),\mathit{Buy\ Price}} \geq 0\\
		\Delta W_{(A),\mathit{Sell}} &= {\CE}_{(A),\mathit{Sell\ Price}} - {\CE}_{(A),\mathit{Lottery}} \geq 0\\
		\% W_{(A),\mathit{Buy}} &= \frac{{\CE}_{(A),\mathit{Lottery}}}{{\CE}_{(B,C),\mathit{Lottery}}} = 1\\
		\% W_{(A),\mathit{Sell}} &= \frac{{\CE}_{(A),\mathit{Sell\ Price}}}{{\CE}_{(B,C),\mathit{Sell\ Price}}} = 1
	\end{split}
\end{align}

According to the metric definition in (\ref{eq2:WCt}) and the decision process for Amy defined in (\ref{eq2:Amy}), the $\Delta W$ welfare evaluations in (\ref{eq2:RP.welfare}) must be weak inequalities.
However, the only situation where $\Delta W_{(B,C),\mathit{Buy}} = 0$ is when $r=-0.0232$, which has a probability of $0$ given that $F_A(\beta|\alpha)$ is continuous.
Similarly for the choice between selling or not selling.
With a probability approaching $1$, the RP model predicts that should an extraction occur the choices causing the extraction leave the subject with positive welfare.

Before moving on to the normative implications of these welfare characterizations, we revisit the SMP thought experiment with two new entrants, Dana and Emma.
Suppose that Dana's choices are characterized as being in accordance with the RPPO model discussed previously, and Emma operates a tremble model as defined by \textcite{Loomes2002}, where $ {\Prob}_0$ is defined by the RP model.
We can pose the same questions concerning Dana and Emma's choices that we asked of Amy, Beth, and Cate's choices: \enquote{How often is the experimenter successful in extracting the difference between the buying and selling price of the ticket from the subject without giving the subject anything and what are the welfare implications of this pair of transactions?}
As we will see below, the answers to these questions for Dana are exactly the same as for Amy, and though the math involved with Emma is slightly more complicated, the unintuitive interpretation of welfare caused by the RP model remains.

Suppose that for Dana, the marginal distributions of each option's $\beta_A^*$ vector used to construct $f_{\mathbf{B_n^t}}(\beta_n^ x,\beta_n^ z|\alpha)$ are identical and uncorrelated.{\footnotemark}
Also, Dana's marginal distribution functions are all $N(\mu,\sigma^2) = N(0,0.01)$, thus normal with $\alpha$ consisting of a mean equal to $0$ and a standard deviation of $0.1$.
The joint density function, $f_{\mathbf{B_n^t}}(\beta_n^x,\beta_n^z|\alpha)$, is therefore:
\begin{align}
	\begin{split}
		N_2&(\mu,\Sigma) \\
		\mu =\begin{Bmatrix}\mu_x \\ \mu_z\end{Bmatrix} &= \begin{Bmatrix}0\\0\end{Bmatrix}\\
		\Sigma =\begin{Bmatrix} \sigma_x^2 & \rho\sigma_x\sigma_z \\  \rho\sigma_x\sigma_z & \sigma_z^2 \end{Bmatrix} &=
	\begin{Bmatrix} 0.01 & 0 \\  0 & 0.01 \end{Bmatrix}
	\end{split}
\end{align}

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	These assumptions are made for mathematical simplicity in the following example.
	There is no obvious reason why it should be necessary that these distributions be identical or uncorrelated, though the conceptual result would be the same even if they were not.
}

\noindent where $\mu$ is the vector of means, $\Sigma$ is the covariance matrix for the joint density function $f_{\mathbf{B_n^t}}(\beta_n^x,\beta_n^z|\alpha)$.
The choice behavior for Dana is as follows:

\noindent For Dana,
\begin{align}
	\begin{split}
		{\CE}_{\mathit{Buy\ Price}} &= \mathit{Buy\ Price} \;\forall\; \beta_D\\
		{\CE}_{\mathit{Sell\ Price}} &= \mathit{Sell\ Price} \;\forall\; \beta_D\\[1.5ex]
		\mathbf{B_D^{\mathit{Buy}}} &= \{ \beta_D^x,\beta_D^z | {\CE}_{\mathit{Lottery}}^x \geq {\CE}_{\mathit{Buy\ Price}}^Z \}\\
		&= \{ r_D^x,r_D^Z | r_D^x \leq -0.0232, r_D^Z \in \Re\}\\[1.5ex]
		\mathbf{B_D^{\mathit{Sell}}} &= \{ \beta_D^x,\beta_D^z | {\CE}_{\mathit{Sell\ Price}}^x \geq {\CE}_{\mathit{Lottery}}^Z \}\\
		&= \{ r_D^x,r_D^Z | r_D^x \geq 0.0232, r_D^Z \in \Re\}\\[1.5ex]
		{\Prob}(y_{\mathit{Buy}} = \mathit{Buy}) &= \int_{\beta_D^x \in \mathbf{B^t_D}}\int_{\beta_D^Z \in \mathbf{B^t_D}} f_{\mathbf{B^t_D}}\!\left(\beta_D^x,\{\beta_D^Z\}|\alpha\right) \;d\beta_D^x \; d\beta_D^Z\\
		&= \phi(r_D^Z \leq -0.0232,0,0.01) \times \phi(r_D^x \in \Re,0,0.01)\\
		&= 0.408 \times 1\\
		{\Prob}(y_{\mathit{Sell}} = \mathit{Sell}) &= \int_{\beta_D^x \in \mathbf{B^t_D}}\int_{\beta_D^Z \in \mathbf{B^t_D}} f_{\mathbf{B^t_D}}\!\left(\beta_D^x,\{\beta_D^Z\}|\alpha\right) \;d\beta_D^x \; d\beta_D^Z\\
		&= \phi(r_D^x \in \Re,0,0.01) \times \phi(r_D^Z \geq 0.0232,0,0.01)\\
		&= 1 \times 0.408\\
	{\Prob}(\mathit{Extraction}_D) &= {\Prob}(y_{\mathit{Buy}} = \mathit{Buy}) \times {\Prob}(y_{\mathit{Sell}} = \mathit{Sell})\\
	&\approx .167
	\end{split}
\end{align}

This thought experiment presents a special case where the RPPO model essentially reduces to the standard RP model.
This is due to the fact that the {\CE} of any certain amount of money is equal to that amount of money.
Because this is true, the distributions of the $\beta_D$ vectors associated with the buying and selling prices are irrelevant.{\footnotemark}

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	Take any degenerate lottery $X$ comprised of a single outcome $x$ with a probability of $p_x =1$.
	The utility of this lottery is $U_X = w_x( p_x )u_x(x )$, where $w_x$ is any probability weighting function and $u_x$ is any utility function.
	Since $w_x(p_x=1)=1$ for every probability weighting function, $U_X=u_x(x)=u_x({\CE}_x)$.
	Since $u_x$ is a well-defined utility function, ${\CE}_x=x$ is a solution for equation (\ref{eq2:CE.indiff}) for every $u_x$ and every $x$ when $p_x=1$.
	This solution is unique when $u_x$ is monotonic as the CRRA function employed in the example is.
}

The reason why the utility functions are normalized can also be made clear with this  example.
The CRRA function described in (\ref{eq2:CRRA}) and utilized in the above example has some interesting properties around $r=1$: $u(x|r) = \ln(x)$ at $r=1$, $u(x|r) \to \infty$ as $r \to 1$ from the left, and $u(x|r) \to -\infty$ as $r \to 1$ from the right.{\footnotemark}
If the RPPO model didn't normalize the CRRA function to its {\CE}, the set of $\{\beta_n^x,\{\beta_n^Z\}\}$  would be contradictory in its elements due to the properties of the CRRA function around $1$.
To demonstrate, assume that the utility of the lottery is evaluated with $r_n^x = -0.0232$: what values of $r_n^Z$ satisfy equation (\ref{eq2:CEcalc}) such that Dana would decide to purchase the lottery? We might expect that since $r_n^x = -0.0232$ is the value of $r_n$ that sets the utility of the lottery and the utility of the buy price equal to each other,  should the buy price be evaluated with greater risk aversion than the lottery, equation (\ref{eq2:RPPO.y1}) will hold.
That is, we might expect that should $r_n^Z > -0.0232$ Dana would prefer the lottery over the buy price.

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	The use of $\ln(x)$ for $r =1$ is not as ad hoc as it may seem.
	\textcite[1333]{Wakker2008} shows that if equation (\ref{eq2:CRRA}) is normalized, it can be seen \enquote{that the normalized logarithmic function is the limit of the normalized power functions for $r$ tending to $0$ \textins{1}, both from above $(r >0)$ \textins{$r>1$} and from below $(r<0)$ \textins{$r<1$}:}
	\begin{align*}
		\lim_{r \to 0} \frac{x^r - c^r}{d^r - c^r} = \frac{\ln(x) - \ln(c)}{\ln(d) - \ln(c)} \quad \forall \; x>0 , d>c>0
	\end{align*}
	While \textcite{Wakker2008} uses the single exponent version of the power function, the same limit applies to the formulation of the CRRA function used in equation (\ref{eq2:CRRA}), with the bracketed values of $r$ in the above quote representing the revised limits.
}

Intuitively this makes sense: an increase in risk aversion corresponds to an increase in the concavity of the utility function which implies lower utility as risk-aversion increases for a given outcome.
While this is true when the CRRA function is normalized to its {\CE}, this isn't true without the normalization.
Without the normalization, $\beta_n^Z$ consists of $-0.023 \leq r_n^Z \leq 0.9814$ and $r_n^Z > 1$.

The gap of $(0.9814,1)$ is due to the properties of the CRRA function around 1.
The un-normalized RPPO model allows for a relatively risky option to be chosen over a relatively less risky option should the less risky option be evaluated using a preference relation indicating intense risk aversion, but not when the less risky option is evaluated using a preference relation indicating only moderate risk aversion.
This is intuitively backwards, though mathematically possible.
The possibility of this kind of gap is not removed even if the marginal distributions which make up $f_{\mathbf{B^t_n}}(\beta_n^x,\{\beta_n^Z\}|\alpha)$ are correlated and can be exacerbated if they are not identical.

Now, suppose Emma operates a TR model with the ${\Prob}_0$ choice probabilities generated by the RP model described for Amy and the tremble parameter described by Cate.
Emma's choice behavior is defined as follows:

\noindent For Emma,
\begin{align}
	\label{eq2:Emma}
	\begin{split}
		B_{\mathit{Buy}} &= \{ \beta_E |\; G(\beta_E,X_{\mathit{Lottery}}) \geq G(\beta_E,X_{\mathit{Buy price}})\}\\
		&= \{ r_E \big|\; r \leq -0.0232 \} \\
		B_{\mathit{Sell}} &= \{ \beta_E |\; G(\beta_E,X_{\mathit{Sell price}}) \geq G(\beta_E,X_{\mathit{Lottery}})\}\\
		&= \{ r_E \big|\; r \geq 0.0232 \} \\[0.5ex]
		{\Prob}_0(y_{\mathit{Buy}}) &= \int_{\beta \in B_{\mathit{Buy}}} dF_E(\beta|\alpha) = \phi(B_{\mathit{Buy}},0,0.01)\\[0.5ex]
		&\approx 0.408 \\
		{\Prob}_0(y_{\mathit{Sell}}) &= \int_{\beta \in B_{\mathit{Buy}}} dF_E(\beta|\alpha) = \phi(B_{\mathit{Sell}},0,0.01)\\[0.5ex]
		&\approx 0.408 \\
		{\Prob}(y_{\mathit{Buy}}=\mathit{Buy}) &= (1-\phi) {\Prob}_0(y_{\mathit{Buy}}) + \frac{\phi}{J}\\
		&=(1-0.816)(0.408) + (0.816)/2\\
		&= 0.483072\\
		{\Prob}(y_{\mathit{Sell}}=\mathit{Sell}) &= (1-\phi) {\Prob}_0(y_{\mathit{Sell}}) + \frac{\phi}{J}\\
		&=(1-0.816)(0.408) + (0.816)/2\\
		&= 0.483072\\
		{\Prob}(\mathit{Extraction}_E) &= {\Prob}(y_{\mathit{Buy}} = \mathit{Buy}) \times {\Prob}(y_{\mathit{Sell}} = \mathit{Sell})\\
		&\approx 0.233
	\end{split}
\end{align}

We have a more complicated result with Emma when we attempt to describe her welfare.
The preferences in this model are provided by the aspects that belong to the RP model.
This means that not only is ${\Prob}_0(y_{\mathit{Buy}})$ the probability that Emma would chose to buy the lottery should she not experience a \enquote{tremble}, but it is also the probability that the choice to buy the lottery is the result of greater utility being accumulated from the lottery ticket than the buying price.
Similarly for ${\Prob}_0(y_{\mathit{Sell}})$ and the choice to sell the ticket.
Thus, given ${\Prob}(\mathit{Extraction}_E)$, ${\Prob}_0(y_{\mathit{Buy}})$, and ${\Prob}_0(y_{\mathit{Sell}})$, we have:
\begin{align}
	\begin{split}
		{\Prob}\left(\% W_{(E),\mathit{Extraction}} = 1\right) &= {\Prob}(\mathit{Extraction}_E) \times {\Prob}_0(y_{\mathit{Buy}}) \times {\Prob}_0(y_{\mathit{Sell}})\\
		&= 0.233 \times 0.408 \times 0.408\\
		&\approx 0.0388
	\end{split}
\end{align}

That is, we characterize Emma as having the 1 unit of money extracted by the SMP, \textit{and} this extraction as having resulted in optimal welfare for Emma $3.88\%$ of the time.
Similarly, this probability can be interpreted as a lower bound on ${\Prob}(\Delta W_{(E),\mathit{Extraction}} \geq 0)$.

The probability that the welfare surplus metric is positive in the event of an extraction is equivalent to the probability of an extraction occuring times the probability that the welfare change from buying the ticket plus the welfare change from selling the ticket is positive:
\begin{align*}
{\Prob}(\mathit{Extraction}_E) &\times {\Prob}(\beta_{\mathit{Buy}},\beta_{\mathit{Sell}} \big| \; {\CE}_{\mathit{Lottery}}^{Buy} - {\CE}_{\mathit{Buy Price}}^{Buy} + {\CE}_{\mathit{Sell Price}}^{Sell} - {\CE}_{\mathit{Lottery}}^{Sell} )\\
{\Prob}(\mathit{Extraction}_E) &\times {\Prob}(\beta_{\mathit{Buy}},\beta_{\mathit{Sell}} \big| \; {\CE}_{\mathit{Lottery}}^{Buy} - {\CE}_{\mathit{Lottery}}^{Sell} \geq 1 )
\end{align*}
If we set $\mathbf{\beta_{\mathit{B,S}}} = \{ \beta_{\mathit{Buy}},\beta_{\mathit{Sell}} \big| \; {\CE}_{\mathit{Lottery}}^{Buy} - {\CE}_{\mathit{Lottery}}^{Sell} \geq 1\}$,{\footnotemark} we have:
\begin{align}
	0.233 \times \int_{\beta_{\mathit{Buy}} \in \mathbf{\beta_{\mathit{B,S}}}} \int_{\beta_{\mathit{Sell}} \in \mathbf{\beta_{\mathit{B,S}}}} F(\beta_{\mathit{Buy}} | \alpha) F(\beta_{\mathit{Sell}}|\alpha) d\beta_{\mathit{Buy}} d\beta_{\mathit{Sell}} \geq 0.0388
\end{align}

This complication arises because Emma's choice function has both TR and RP elements.
Sometimes Emma will value the prospect of buying the lottery ticket extremely highly, not tremble, and choose to buy, and then value the prospect of selling the ticket back only somewhat negatively, tremble, and then sell it back.
The welfare gained in the buying choice can therefore sometimes outweigh the welfare lost in the selling choice, resulting in a net positive change of welfare.
Note that every time Emma values the buying of the ticket \textit{and} the selling of the ticket positively, the net change in welfare will also be positive.
Thus, $0.0388$ constitutes a lower bound on ${\Prob}(\Delta W_{(E),\mathit{Extraction}} \geq 0)$.

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	Recall that the {\CE} of an certain amount is always that certain amount.
	So the {\CE} of the "Buy Price" is $55.5$, and the {\CE} of the sell price is $54.5$ for any utility function.
	Therefore ${\CE}_{\mathit{Buy Price}} - {\CE}_{\mathit{Sell Price}} = 1$ for all utility functions.
}

\section{The Normative Coherence of Stochastic Models}

%DIF >  The Craft of Economics
%DIF >  Edward E. Leamer
%DIF >  p 25 -  Fortunately, our goal as economists is not soundness, but usefulness.
%DIF >  p 26 - We would make progress if we could agree that \textit{our models are neither true nor false; our models are sometimes useful and sometimes misleading}.
%DIF >  p 30 - The primary goal \textins{of economics} should not be to amuse each other with mathematical complexities... \textins{it} should be to design policy interventions - policies that are intended to help achieve social objectives, notably the highest level of well-being for the largest number of people.
\DIFaddbegin 

%DIF >  Pigou - The Economics of Welfare, 3rd edition 1928
%DIF >  The complicated analyses which economists endeavour to carry through are not mere gymnastic. They are instruments for the bettering of human life

\DIFaddend Having clarified the welfare implications of several representative stochastic models, we will begin the discussion of the normative implications of these models.
\DIFdelbegin \DIFdel{There may be some objection to the interpretation of these stochastic models as normative theories of economic choice because the intent behind the development }\DIFdelend \DIFaddbegin \DIFadd{When a variety of stochastic models were detailed by \textcite{Becker1963}, they were intended as a way to }\enquote{circumvent the difficulty} \DIFadd{associated with the problem that }\enquote{the preference choices of the chooser are are often inconsistent with each other.}
\DIFadd{In laying out the implications }\DIFaddend of these models\DIFdelbegin \DIFdel{was descriptive in nature, not normative}\DIFdelend \DIFaddbegin \DIFadd{, \textcite{Becker1963} detail descriptive implications about the frequency at which certain types of choices would be observed, but do not make any normative claims.
The intent behind developing these models was to provide greater descriptive veracity to Expected Utility Theory, apparently while maintaining EUT as the normative force behind these models}\DIFaddend .
\DIFdelbegin \DIFdel{With this }%DIFDELCMD < \enquote{descriptive-only} %%%
\DIFdel{interpretation, there is nothing to say normatively about these models ;
all the normative implications of these modelsderives from orthodox economic utility theory }\DIFdelend \DIFaddbegin 

\DIFadd{The historical course that lead to EUT becoming the dominant orthodox theory appears to have started with a descriptive justification, then a normative justification.
\textcite{Moscati2016} details the correspondences between Paul Samuelson, Leonard Savage, Jacob Marschak, and Milton Friedman discussing the axiomatization of EUT by \textcite{VonNeumann1944} and its burgeoning acceptance as the orthodox theory of choice involving risky outcomes.
The correspondences highlight Samuelson's strong initial reluctance to accept EUT on based on his dissatisfaction with the}\DIFaddend , \DIFdelbegin \DIFdel{in particular, rational preference theory (RPT) guided by the so-called }%DIFDELCMD < \enquote{consistency}{\footnotemark} %%%
\DIFdel{axioms: completeness, transitivity, and often}%DIFDELCMD < {\footnotemark} %%%
\DIFdel{continuity and monotonicity.
The stochastic elements of these models are merely econometric necessities bolted onto RPT, so thecharacterization goes, with all the power and limitations this implies.
However, any notion of }%DIFDELCMD < \enquote{consistency} %%%
\DIFdel{associated with stochastic models must be of a conceptually different nature than RPT because of the inherent probabilistic nature of choice built into such models.
We argue that this probabilistic nature provides normative defences where RPT is weak for certain stochastic models.
}\DIFdelend \DIFaddbegin \DIFadd{at the time unnamed, independence axiom, calling it a }\enquote{gratuitously-arbitrary-special-implausible hypothesis} \parencite[225]{Moscati2016}\DIFadd{.
Savage, and to a lesser extent Marschak and Friedman, advocated for EUT as being descriptively accurate, theoretically simple, and, eventually, normatively robust.
Samuelson had strong reservations about the descriptive veracity of EUT, advocated by both Savage and Friedman, stating that the phenomena associated with gambling are }\enquote{infinitely richer} \DIFadd{than EUT permitted }\parencite[227]{Moscati2016}\DIFadd{.
Friedman also admitted that in order to be able to explain certain gambling phenomena, EUT would }\enquote{need complication} \parencite[229]{Moscati2016}\DIFadd{.
Eventually, however, Samuelson was persuaded of EUT's normative force by Savage's discussion of what would become known as the }\enquote{Sure-Thing Principle}\DIFadd{, without necessarily relenting on the descriptive claims.
}\DIFaddend 

\DIFdelbegin %DIFDELCMD < \addtocounter{footnote}{-2}
%DIFDELCMD < \stepcounter{footnote}%%%
\footnotetext{\DIFdel{Technically, consistency is associated with axioms of revealed preference such as the weak axiom of revealed preference (WARP), strong axiom of revealed preference (SARP), or the generalized axiom of revealed preference (GARP).
	However, consistency is often ascribed to the }%DIFDELCMD < \enquote{rational} %%%
\DIFdel{preference relation.
	For a preference relation to be rational, it is necessary that choices said to be generated by the relation must also satisfy WARP.
	Satisfaction of WARP however, is not sufficient for the construction of a rational preference relation }%DIFDELCMD < \parencite[13]{Mas-Colell1995}%%%
\DIFdel{.
	In particular, WARP does not require transitivity, whereas the rational preference relation does.
	The transitivity axiom, however, is often the target of critics of the normative justification of RPT through consistency.
}}
%DIFAUXCMD
%DIFDELCMD < \stepcounter{footnote}%%%
\footnotetext{\DIFdel{Completeness and transitivity are the only axioms required for a }%DIFDELCMD < \enquote{rational} %%%
\DIFdel{preference relation.
	The continuity axiom allows for the derivation of a utility function, while the monotonicity axiom adds structure to utility functions to make broad and powerful inferences.
	Thus, continuity and monotonicity are broadly assumed.
}}
%DIFAUXCMD
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{There are numerous projects that reject RPT as a sufficient descriptive theory of choice by agents and propose alternatives; indeed, the interest in stochastic models has been driven precisely because of the apparent descriptive failings of RPT.
A project deemed the Heuristics and Biases (HB) project led by work originating from \textcite{Kahneman1979} proposes alternative models of choice that are said to deviate from RPT systematically through mechanisms of }%DIFDELCMD < \enquote{loss aversion} %%%
\DIFdel{and probability weighting.
Another, deemed the Fast and Frugal Heuristics (FFH) or Ecological Rationality project states that agents }\textit{\DIFdel{may}} %DIFAUXCMD
\DIFdel{deviate systematically from RPT in environments where agents have low access to information, and employ satisficing heuristics instead.
Of these, only the FFH program has explicitly also made the case that it rejects RPT as a normative theory as well as a descriptive theory}\DIFdelend \DIFaddbegin \DIFadd{What is meant by normative force in these discussions is the definition of what a }\enquote{rational} \DIFadd{agent }\enquote{ought} \DIFadd{to do, though not necessarily what they actually do.
Marschak in correspondence with Samuelson makes this distinction:
}\enquote{It may be \textit{usual} for village carpenters \textelp{} to deviate from the advice of Euclidian geometers \textelp{} All the same, they would be better advised to behave rationally by following Euclid} \parencite[229]{Moscati2016}\DIFadd{.
In relenting to Savage's normative arguments, Samuelson concedes that the normative value of the Independence Axiom and by extension EUT makes it useful as an assumption }\enquote{defining \enquote{rational} behavior} \parencite[231]{Moscati2016} \DIFadd{despite maintaining that EUT doesn't provide }\enquote{a very illuminating explanation} \DIFadd{of gambling or investment behavior even }\enquote{as a first approximation} \parencite[232]{Moscati2016}\DIFaddend .

The \DIFdelbegin \DIFdel{debate about the descriptive and normative promises and troubles of RPT, HB, and FFH has been going on for a few decades now, and doesn't look to be abating any time soon.
Rather than attempt to arbitrate the arguments for and against the various projects, we will seek to apply some of the critiques and justifications used in this debate to the examples of stochastic models discussed }\DIFdelend \DIFaddbegin \DIFadd{appeal of normative arguments, and their apparent superiority to descriptive veracity arguments in the case of accepting EUT, is based on their adding to a theory's ability to make statements about the welfare of agents in incentivized environments.
\textcite[preface to the third edition]{Pigou1929} prefaces his third edition with a comment to future students of economics:
}

\blockquote{
The complicated analyses which economists endeavour to carry through are not mere gymnastic.
They are instruments for the bettering of human life.
The misery and squalor that surround us, the injurious luxury of some wealthy families, the terrible uncertainty overshadowing many families of the poor - these are evils too plain to be ignored.
By the knowledge that our science seeks it is possible that they may be restrained.
Out of the darkness light!
To search for it is the task, to find it perhaps the prize, which the \enquote{dismal science of Political Economy} offers to those who face its discipline.
}

\noindent \DIFadd{\textcite[238]{Varian1996} writes: }\enquote{economics is a policy science and, as such, the contribution of economic theory to economics should be measured on how well economy theory contributes to the understanding and conduct of economic policy.}
\DIFadd{\textcite[30]{Leamer2012} echos this sentiment:
}\enquote{The primary goal \textins{of economics} should not be to amuse each other with mathematical complexities \textelp{} \textins{it} should be to design policy interventions - policies that are intended to help achieve social objectives, notably the highest level of well-being for the largest number of people.}{\footnotemark}

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	\DIFadd{This utilitarian conceptualization of the primary goal of economics can be relaxed somewhat without losing force.
	Policy interventions can, and often are, be crafted to improve the welfare of specific sub-populations.
	For instance, the kind of individuals referenced by Pigou may have a disproportionate number of policies crafted to improve their lot relative to their numbers in the total population without this seeming at odds with the goals of economics.
}}

\DIFadd{It is with these sentiments, both historical and contemporary, that we will interrogate the stochastic models presented }\DIFaddend in this chapter \DIFdelbegin \DIFdel{.
In doing so, we hope to establish that certain stochastic models add normatively coherent structure in addition to their descriptive capacities.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \DIFadd{as providing useful methodologies in the design and interpretation of policy interventions.
Critical to this object is the ability to make statements on how changes in stocks of assets affect the welfare of individuals.
}\DIFaddend The various criteria used to assess the normative validity of stochastic models will largely be interpreted from the works of \textcite{Grune-Yanoff2014}, \textcite{Berg2014}, and \textcite{Hands2014}.
\DIFdelbegin \DIFdel{\textcite[405]{Hands2014} notes that the FFH and RPT, and by extension HB, projects all rely on the concept of }%DIFDELCMD < \enquote{instrumental rationality} %%%
\DIFdel{(IR).
IR is a rationality that states }%DIFDELCMD < \enquote{If one's goal is $x$, one ought to do $y$}%%%
\DIFdel{.
That is, IR makes the statement that some means are rational ways to read certain ends, but makes no general recommendation as to what those ends must be }%DIFDELCMD < \parencite*[405]{Hands2014}%%%
\DIFdel{.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{We will be utilizing the framework of IR in the following discussion of the normative justification of stochastic models.
}\DIFdelend Normative criteria are relations of particular means and ends that describe what an agent \enquote{ought} do or not do in certain circumstances.
Economic theories purporting to be normatively justified must provide the mechanisms that satisfy these relationships.
In this framework, we will primarily be discussing what means stochastic models provide to reach ends that have commonly been employed as normative criteria.

\DIFdelbegin \DIFdel{These normative criteria, however, are often framed in the context of choice scenarios, which themselves may not make the specific underlying ends formally clear.
What is also potentially unclear is whether these normative criteria are chosen on the basis of observed reality or if they are derived some idealistic construction of agency.
That is, are normative criteria }%DIFDELCMD < \enquote{naturalized} %%%
\DIFdel{or are they }%DIFDELCMD < \enquote{idealized}%%%
\DIFdel{.
We will attempt to make clear this distinction when possible.
}\DIFdelend %DIF > These normative criteria, however, are often framed in the context of choice scenarios, which themselves may not make the specific underlying ends formally clear.
%DIF > What is also potentially unclear is whether these normative criteria are chosen on the basis of observed reality or if they are derived some idealistic construction of agency.
%DIF > That is, are normative criteria \enquote{naturalized} or are they \enquote{idealized}.
%DIF > We will attempt to make clear this distinction when possible.

\subsection{Economic Existence and Objective Betterness Criteria}

\DIFdelbegin \DIFdel{The concept of continued economic existence as a requirement of }\DIFdelend %DIF > The concept of continued economic existence as a requirement of an economic theory is likely the most common reason given as to why a theory is normatively justified.
\DIFaddbegin \DIFadd{For }\DIFaddend an economic theory \DIFdelbegin \DIFdel{is likely the most common reason given as to why a theory is normatively justified.
Broadly speaking, it states }\DIFdelend \DIFaddbegin \DIFadd{to gain normative, it should stipulate }\DIFaddend that an agent \DIFdelbegin \DIFdel{who is purported to make choices in accordance to the theory, }\DIFdelend ought not make choices systematically in such a way as to drive herself out of economic existence.
For example, this could mean that an economic theory should not normatively justify an agent's choice to deliberately put themselves into bankruptcy.{\footnotemark}

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	Bankruptcy here is in meant in the abstract sense of the loss of all assets without recourse to recover them.
	In the United States for instance, given what are called \enquote{Chapter 9} and \enquote{Chapter 11} bankruptcy provisions, it could be quite rational to engage in institutionally controlled bankruptcy under certain circumstances.
	In the interpretation intended, deliberately bankrupting oneself as is said to have been done by the Buddha or Jesus, should not be normatively justified, while making choices in line with Donald Trump's business practices, strangely, should be.
}

The popular, often informal, way \DIFdelbegin \DIFdel{RPT }\DIFdelend \DIFaddbegin \DIFadd{EUT }\DIFaddend is justified in light of this criteria is through its invulnerability to money pumps.
The traditional money pump is defined as a series of trades that will succeed in extracting the entirety of an agent's stock of assets, say some amount of good $A$, if the agent has intransitive preferences, such as $B \succcurlyeq A$, $C \succcurlyeq B$, $A \succcurlyeq C$ with at least one relation being strict.
This occurs by the extractor offering to trade his $B$ for the agent's $A$, then his $C$ for her $B$, and finally his $A - \epsilon$ for her $C$, where $\epsilon$ is a sufficiently small, but positive amount of good $A$ such that $A - \epsilon \succcurlyeq C$.
This process is repeated until the agent has no remaining quantity of good $A$, and is thus economically eliminated.

\textcite[402-403]{Hands2014} refers to this argument as \enquote{emperical elimination}:
\DIFdelbegin %DIFDELCMD < \blockquote{
%DIFDELCMD < This is the argument that agents who act in ways that violate RCT will (in fact) cease to exist or at least cease to play an active role among the relevant class of decision-makers.
%DIFDELCMD < The two most common forms of this argument are the money pump (for agents who have intransitive preferences and thus make choice mistakes) and the Dutch book\textelp{}
%DIFDELCMD < }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \blockquote{
This is the argument that agents who act in ways that violate \textins{rational choice theory} will (in fact) cease to exist or at least cease to play an active role among the relevant class of decision-makers.
The two most common forms of this argument are the money pump (for agents who have intransitive preferences and thus make choice mistakes) and the Dutch book\textelp{}
}
\DIFaddend 

\noindent while \textcite[336]{Grune-Yanoff2014} refers to it as \enquote{universal loss-avoidance considerations}:
\blockquote{
If an agent violates the transitivity condition on preferences, then that individual can be \enquote{money pumped}:
all wealth can be taken from her, simply by trading goods with her in a way that exploits her preference intransitivity\textelp{}
Consequently, to the extent that any one wants to avoid such sure losses, one must satisfy the corresponding internal consistency criteria.
}

\textcite{Cubitt2001} however, methodically decompose the argument that failure to satisfy consistency axioms, in particular transitivity, results necessarily in vulnerability to money pumps.
They develop a detailed methodology for describing decision problems without the need to specify an underlying theory of value that traditionally denotes rewards at nodes in decision trees \DIFdelbegin \DIFdel{.
Their first and most stark example of a behavioral correspondence that in no way implies transitivity but is nonetheless invulnerable to money pumps, can be defined thusly: }%DIFDELCMD < \enquote{never trade} \parencite[139]{Cubitt2001}%%%
\DIFdel{.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{Should an agent refuse to engage in any trade, there will necessarily be no opportunity for an extractor to employ a money pump on her, even if her preferences are, in fact, intransitive.
\textcite{Ross2014,Ross2014a} might disagree with this objection, perhaps by arguing that organizing trade through markets is the whole purpose of economics, and so an agent who doesn't trade no longer participates in economy and has }\textit{\DIFdel{de facto}} %DIFAUXCMD
\DIFdel{economically eliminated herself.
\textcite[140]{Cubitt2001} recognize a similar critique and respond by noting that the }%DIFDELCMD < \enquote{never trade} %%%
\DIFdel{heuristic }%DIFDELCMD < \enquote{is merely the simplest example of a behavior correspondence that, while invulnerable \textins{to money pumps}, violates the standard assumptions.}
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{\textcite{Cubitt2001} provide several other }\DIFdelend \DIFaddbegin \DIFadd{and provide several }\DIFaddend examples of how an agent could have preferences that violate consistency axioms and yet remain invulnerable to money pumps\DIFdelbegin \DIFdel{, including ones involving trading agents}\DIFdelend .{\footnotemark}
\DIFdelbegin \DIFdel{However, the existence of one example is sufficient to refute the claim that in order to be invulnerable to money pumps it is necessary that an agent conform to the standard consistency axioms.
}\DIFdelend \textcite[154]{Cubitt2001} conclude: \enquote{Thus, in relation to what we take to be their original objectives, money pump arguments are a failure.}

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	The reader is encouraged to consult \textcite{Cubitt2001} for a novel \DIFdelbegin \DIFdel{, useful, and incredibly terse }\DIFdelend methodology on atheoretic representations of decision problems, as well as the \DIFdelbegin \DIFdel{remaining }\DIFdelend examples indicated.
}

The critiques of \textcite{Cubitt2001} show that adherence to \DIFdelbegin \DIFdel{RPT }\DIFdelend \DIFaddbegin \DIFadd{EUT }\DIFaddend is not a necessary condition for invulnerability to a money pump, only a sufficient one.
\DIFdelbegin \DIFdel{However, the claim that an agent must be invulnerable to money pumps, or something like them, is still largely seen as a necessary condition for a normative theory.
We can interpret the notion that an agent must be invulnerable to money pumps into several, progressively stronger, normative criteria.
The first two are as follows:
}%DIFDELCMD < 

%DIFDELCMD < \newtheorem*{WEE}{Weak Economic Existence (WEE)}
%DIFDELCMD < \newtheorem*{MEE}{Moderate Economic Existence (MEE)}
%DIFDELCMD < \begin{WEE}
%DIFDELCMD < 	%DIFDELCMD < \label{th:WEE}%%%
%DIFDELCMD < 	%%%
\DIFdel{An agent ought not choose to directly eliminate herself.
}%DIFDELCMD < \end{WEE}
%DIFDELCMD < \begin{MEE}
%DIFDELCMD < 	%DIFDELCMD < \label{th:MEE}%%%
%DIFDELCMD < 	%%%
\DIFdel{An agent ought not make choices that would, if repeated consistently, lead to economic elimination.
}%DIFDELCMD < \end{MEE}
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{The money pump is almost never discussed in terms of the agent having her last stock of assets taken from her, only that consistent vulnerability to a money pump leads to economic elimination.
In some sense, it is taken as obvious by economists that no agent, when presented with the option of keeping their stock of assets or forfeiting it, would choose to keep their stock.
Instead, the money pump argument seems to suggest MEE as a normative criterion, though only because it implies that WEE is necessarily true.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{Both of these criteria imply the existence of some objective relation of }%DIFDELCMD < \enquote{betterness}%%%
\DIFdel{, }%DIFDELCMD < {\OB}%%%
\DIFdel{.
In particular, WEE implies that the all non-empty sets of assets are objectively }%DIFDELCMD < \enquote{better} %%%
\DIFdel{than an empty set of assets:
}\begin{displaymath}
	\DIFdel{%DIFDELCMD < \label{eq2:WEE}%%%
	A\ {\OB} \{\emptyset\} \quad \forall A \neq \{\emptyset\}
}\end{displaymath}
%DIFAUXCMD
%DIFDELCMD < 

%DIFDELCMD < \noindent %%%
\DIFdel{whereas the }%DIFDELCMD < {\OB} %%%
\DIFdel{relation for MEE could be defined as follows:
}\begin{align*}
	\DIFdel{%DIFDELCMD < \label{eq2:MEE}%%%
	\begin{split}
		A^\prime\ &{\OB} A \quad\forall A, A^\prime\\
		\mathit{s.t.}\quad A &= \{x_1,\ldots,x_n\}\\
		A^\prime &= \{x_1 + \epsilon_1,\ldots,x_n+\epsilon_n\} \ \forall x_n \\
		\epsilon_n &\geq 0 \ \forall \epsilon_n
	\end{split}
}\end{align*}
%DIFAUXCMD
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{\textcite[141]{Cubitt2001} define a relation similar to the one defined in equation (\ref{eq2:MEE}).
This relation, they state, }%DIFDELCMD < \enquote{coincides with \textit{weak statewise dominance}} %%%
\DIFdel{and that
}%DIFDELCMD < \enquote{Many theories of choice under uncertainty generate choice functions which respect statewise dominance and hence, within this setup, objective betterness.
%DIFDELCMD < 	Obviously, this is true of expected utility theory.
%DIFDELCMD < 	But it is also true of, for example, \textcite{Quiggin1982} rank-dependent expected utility theory \textins{RDU}.}
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{Thus, the normative criterion demonstrated by money pump thought experiment requires that the }%DIFDELCMD < \enquote{objective betternes} %%%
\DIFdel{relation of equation (\ref{eq2:MEE}) not be violated sufficiently many times or with sufficient magnitude that the agent is eliminated.
}\DIFdelend Indeed, it is possible for an agent to conform to standard consistency axioms of completeness and transitivity and still be economically eliminated\DIFdelbegin \DIFdel{should her preferences be discordant with this $\succcurlyeq^*$ relation}\DIFdelend .{\footnotemark}
\DIFdelbegin %DIFDELCMD < 

%DIFDELCMD < %%%
%DIF < \stepcounter{footnote}\footnotetext{
%DIF < 	The necessity of continued survival is a weak requirement of economic success.
%DIF < 	\textcite[143]{Cubitt2001} define a stronger criteria for objective \enquote{betterment} called \enquote{maximal opportunism}, which would require agents to take advantage of obvious, objectively better exchanges.
%DIF < 	One might even consider a range of economic sucess betweeen survival and maximal opportunism such that an agent is required to increase her welfare  through at least \textit{some} choices.
%DIF < 	These stronger criteria, however, do not seem to be utilized in any popular justifications of normative acceptance.
%DIF < }
%DIFDELCMD < 

%DIFDELCMD < \addtocounter{footnote}{-1}
%DIFDELCMD < \stepcounter{footnote}%%%
\footnotetext{\DIFdel{The poem }%DIFDELCMD < \enquote{Smart} %%%
\DIFdel{by Shell \textcite{Silverstein1974} exhibits such an agent.
	A son receives a dollar from his father and gleefully trades it for two quarters, and those two quarters for three dimes, and those three dimes for four nickles, and those four nickels for five pennies.
	It is clear that the son's preferences for these objects are both complete and transitive, satisfying the RPT axioms for consistency.
	Perhaps the son has not been economically eliminated, the five pennies do still have some value, but should there exist infinitely divisible denominations of hard currency, the son would approach elimination.
	The implied reaction of the father to his son's trades, lost on the son, suggests that such a set of preferences is normatively unacceptable.
}}
%DIFAUXCMD
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{It is somewhat odd to consider what set of objects would satisfy $\succcurlyeq^*$ given that the interpretation of utility in economics is as a subjective measure.
}\DIFdelend However, the \DIFdelbegin \DIFdel{lexicon of economics provides for objects called }%DIFDELCMD < \enquote{goods}%%%
\DIFdel{.
If we consider having more }%DIFDELCMD < \enquote{goods} %%%
\DIFdel{to be an objectively good thing, the monotonicity axiom can then be said to satisfy the requirement of sufficient adherence to $\succcurlyeq^*$ when applied to sets of }%DIFDELCMD < \enquote{goods}%%%
\DIFdel{.}%DIFDELCMD < {\footnotemark}
%DIFDELCMD < %%%
\DIFdel{That is, the requirement }\DIFdelend \DIFaddbegin \DIFadd{claim }\DIFaddend that an agent \DIFdelbegin \DIFdel{prefer a strictly greater stock of goods to her current allocation of goods is sufficient to ensure that an agent's choice between alternatives not involving uncertainty will not result in economic elimination.
Similarly, in scenarios where alternative options incorporate an element of risk, adherence to FOSD must be said to make the agent }%DIFDELCMD < \enquote{better off} %%%
\DIFdel{and violations of FOSD to make the agent }%DIFDELCMD < \enquote{worse off}%%%
\DIFdelend \DIFaddbegin \DIFadd{should not make choices in such a was as to have her stock of assets stripped away from her is still largely seen as a necessary condition for a normative theory.
More generally, we claim that for a theory to be useful in policy endeavors, having stocks of assets stripped away from an agent must be viewed as leaving the agent worse off.}{\footnotemark}
\DIFadd{We call this the economic existence (EE) criterion}\DIFaddend .

\DIFdelbegin %DIFDELCMD < \addtocounter{footnote}{-1}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \addtocounter{footnote}{-2}
\DIFaddend \stepcounter{footnote}\footnotetext{
	\DIFdelbegin \DIFdel{Such }\DIFdelend \DIFaddbegin \DIFadd{The poem }\enquote{Smart} \DIFadd{by Shell \textcite{Silverstein1974} exhibits such an agent.
	A son receives }\DIFaddend a \DIFdelbegin \DIFdel{restriction }\DIFdelend \DIFaddbegin \DIFadd{dollar from his father and gleefully trades it for two quarters, and those two quarters for three dimes, and those three dimes for four nickles, and those four nickels for five pennies.
	It }\DIFaddend is \DIFaddbegin \DIFadd{clear that the son's preferences for these objects are both complete and transitive, satisfying the axioms for consistency.
	Perhaps the son has }\DIFaddend not \DIFdelbegin \DIFdel{totally alien to economics}\DIFdelend \DIFaddbegin \DIFadd{been economically eliminated, the five pennies do still have some value, but should there exist infinitely divisible denominations of hard currency, the son would approach elimination}\DIFaddend .
	\DIFdelbegin \DIFdel{Individuals addicted to harmful substances may descriptively be best characterized as preferring more }\DIFdelend \DIFaddbegin \DIFadd{The implied reaction }\DIFaddend of \DIFdelbegin \DIFdel{these substances }\DIFdelend \DIFaddbegin \DIFadd{the father }\DIFaddend to \DIFdelbegin \DIFdel{less}\DIFdelend \DIFaddbegin \DIFadd{his son's trades}\DIFaddend , \DIFdelbegin \DIFdel{though in }\DIFdelend \DIFaddbegin \DIFadd{lost on }\DIFaddend the \DIFdelbegin \DIFdel{long run}\DIFdelend \DIFaddbegin \DIFadd{son}\DIFaddend , \DIFaddbegin \DIFadd{suggests that }\DIFaddend such \DIFaddbegin \DIFadd{a set of }\DIFaddend preferences \DIFdelbegin \DIFdel{often sadly lead to economic elimination.
	In these cases, it would be }\DIFdelend \DIFaddbegin \DIFadd{is }\DIFaddend normatively unacceptable\DIFdelbegin \DIFdel{to label these, potentially transitive and complete, preferences as resulting in an agent's increased }%DIFDELCMD < \enquote{betterment} %%%
\DIFdel{or welfare}\DIFdelend .
}
\DIFaddbegin \stepcounter{footnote}\footnotetext{
	\DIFadd{The requirement of }\enquote{just} \DIFadd{compensation in eminent domain provisions in the US implies that policy crofters agreed that stripping a citizen of her assets, even for the public good, leaves her worse off.
}}
\DIFaddend 

\DIFdelbegin \DIFdel{However, we do observe empirical cases of violations of MEE.
Firms on occasion consistently price products below their cost, or sufficiently above the market rates such that they end up failing.
Without going into the causes of why firms would choose actions which result in economic elimination, a weaker requirement to the economic elimination criterion can be utilized to describe these cases.
Rather than strictly prohibiting any set of choices, a normative theory must require that a set of choices which lead directly to economic elimination be described as making the agent }%DIFDELCMD < \enquote{worse off}%%%
\DIFdel{.
For example, rather than enforcing that
an agent ascribe to FOSD or strict monotonicity, an agent must be described as being worse off by violating FOSD or monotonicity.
}\DIFdelend \DIFaddbegin \DIFadd{\textcite[141]{Cubitt2001} define a relation communicating this necessity of not valuing less assets to more, which they state }\enquote{coincides with \textit{weak statewise dominance}} \DIFadd{and that
}\enquote{Many theories of choice under uncertainty generate choice functions which respect statewise dominance and hence, within this setup, objective betterness.
	Obviously, this is true of expected utility theory.
	But it is also true of, for example, \textcite{Quiggin1982} rank-dependent expected utility theory \textins{RDU}.}

\DIFaddend \textcite[112]{Marschak1950} seems to endorse this the notion \DIFaddbegin \DIFadd{of EE }\DIFaddend as a normative \DIFdelbegin \DIFdel{critera}\DIFdelend \DIFaddbegin \DIFadd{criterion}\DIFaddend , describing agents who chose dominated offers as worse off:
\enquote{In dealing with his environment (\enquote{nature} which includes \enquote{society}) a man who often makes mistakes in his inferences and his sums is, in the long run, apt to fare less well than if he had been a better logician and arithmetician.}

With this interpretation of \DIFdelbegin %DIFDELCMD < \enquote{Economic Elimination} %%%
\DIFdel{and }%DIFDELCMD < \enquote{Objective Betterness} %%%
\DIFdelend \DIFaddbegin \DIFadd{EE }\DIFaddend as a necessary criteria for a normative theory of choice, we return to the SMP thought experiment presented earlier.
In the SMP, at no point does an agent face a single choice that incorporates FOSD, thus taken in isolation, a choice to buy or sell the lottery ticket cannot be said to \DIFdelbegin \DIFdel{objectively }\DIFdelend \DIFaddbegin \DIFadd{necessarily }\DIFaddend reveal anything about changes in the agent's welfare.
Taken together, should an agent buy the ticket and then proceed to sell the ticket back for less money, the agent's choices have directly lead to her stock of assets being reduced by 1 unit.
A normatively acceptable theory of choice must, at a minimum, describe the agent as having become worse off than if she had never engaged with the trades.

This concept of describing objective betterment across aggregated choices is no different to previous uses of the standard money pump argument.
Utilizing the above example of a standard money pump, it isn't until the extractor seeks to trade back a reduced quantity of the agent's original endowment, $A - \epsilon$, for her current stock of assets, $C$, that an agent is said to be worse off.
\DIFdelbegin \DIFdel{Taken in isolation, a trade of $C$ for $A - \epsilon$ is meaningless.
}\DIFdelend Furthermore, all trades up to the final trade cannot be said to \DIFdelbegin \DIFdel{objectively }\DIFdelend \DIFaddbegin \DIFadd{necessarily }\DIFaddend make the agent worse off, they are simply transfers of different stocks of goods.
With all the trades aggregated together however, the final trade is what completes the extraction that leaves the agent \DIFdelbegin \DIFdel{objectively worse off.
}\DIFdelend \DIFaddbegin \DIFadd{with a smaller stock of assets.
}\DIFaddend 

\DIFdelbegin \DIFdel{In the SMP example, RPT can have two responses to the event of an extraction.
The first is to describe the agent as being indifferent to all trades, including a direct trade between the buy price and the sell price.
The second seeks to satisfy the condition of characterizing an extraction as leaving the agent as worse off by requiring that an agent never engage in the trade necessary to be money pumped.
An agent can either buy or not buy the lottery ticket, but in no circumstances should an agent also sell the ticket back.
However, having observed the buying }\textit{\DIFdel{and}} %DIFAUXCMD
\DIFdel{the selling the ticket, RPT is at a loss in attempting to describe the choices as anything other than indifference or as inconsistent with RPT.
But as \textcite{Cubitt2001} show, }%DIFDELCMD < \enquote{inconsistent} %%%
\DIFdel{correspondences need not lead to economic elimination, and therefore do not necessarily mean that the agent must be worse off.
It appears that the characterization of observed choices in terms of }%DIFDELCMD < \enquote{betterment} %%%
\DIFdel{as dichotomously }%DIFDELCMD < \enquote{consistent} %%%
\DIFdel{or }%DIFDELCMD < \enquote{inconsistent} %%%
\DIFdel{is precisely the problem the FFH program has with RPT }%DIFDELCMD < \parencite[380]{Berg2014}%%%
\DIFdel{.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{Some stochastic models, however, can alleviate the normative issues of RPT associated with these kind of problems.
}\DIFdelend All the stochastic models examined in the SMP thought experiment allow for the \DIFdelbegin \DIFdel{observed }\DIFdelend choices resulting in an extraction to occur.
All of the examples except for Emma even predict the extraction will occur with the same probability.
Additionally, every model allows for a mechanism to describe the agent's welfare at every choice.
However, it is only the TR and CU models associated with the Beth and Cate examples that satisfy the normative requirement described in this section.

Equations (\ref{eq2:Beth}) and (\ref{eq2:Cate}) show that the CU and TR models allow for the observed extraction to occur, while equation (\ref{eq2:BCwelfare}) \DIFdelbegin \DIFdel{shows that these models correctly align the subjective welfare assessment with the objective relation of betterment and state that these }\DIFdelend \DIFaddbegin \DIFadd{states that these }\DIFaddend agents are worse off than they would have been had they not engaged in the trades.
The TR and CU models would make similar allowances for the selection of dominated lotteries in FOSD lottery pairs, and also correctly align the subjective welfare assessment with the \DIFdelbegin \DIFdel{objective betterment relation}\DIFdelend \DIFaddbegin \DIFadd{EE criterion}\DIFaddend .
Even considering alternative RE models that assign a probability of $0$ to dominated lotteries in FOSD lottery pairs, and thus econometrically collapse with every proposed utility function having equal, $0$, likelihood, all proposed utility functions would \textit{still} coincide with the result of requiring the agent to be subjectively worse off.
Thus, it is a general result that stand-alone RE and TR models successfully adhere to the normative criteria described in this section.

The \DIFdelbegin \DIFdel{pure RPmodel, the RPPOmodel}\DIFdelend \DIFaddbegin \DIFadd{RP}\DIFaddend , \DIFaddbegin \DIFadd{RPPO, }\DIFaddend and the TR-RP models of Amy, Dana, and Emma however, all share the property that the extraction of 1 unit of wealth from the agents can be described subjectively as an increase in welfare.
For the RP and RPPO models, this description of an extraction as welfare improvement is guaranteed, while for the TR-RP model this description is only applicable sometimes.
Thus, we argue that this property of the RP class of stochastic models violates the normative criteria described in this section.


\subsection{Willingness to \enquote{Correct} Choices Criterion}

The willingness to correct choices (WCC) criteria is often interpreted in multiple ways.
A general version of WCC requires that should an agent deviate from the requirements of a theory of choice, should the agent be confronted with the deviation they will willingly \enquote{correct} their choices to conform with the theory.
Sometimes this argument states that should such a willingness to correct choices be observed empirically the theory is normatively justified, other times the willingness to correct choices need only be hypothetical.
This criteria seems to require multiple moving pieces.

First, an agent must make choices that apparently violate the economic theory, such as the kind of choices described in the money pump and SMP examples.
Secondly, someone, often characterized as an \enquote{expert} in decision problems, must confront the agent with the theory and a prescription of how the agent should make choices in light of this theory.
Finally, the agent, presumably having been convinced about the validity of the theory, chooses again and selects a set of choices that conform to the theory.
An alternate version of this criteria only requires that the agent in question be an \enquote{expert} or some kind of exemplary decision maker herself.

\DIFdelbegin \DIFdel{Should the confronter in this interaction be another agent, this criteria involves some degree of paternalism.
Should the choosing agent be considered an exemplary decision maker, then the paternalism of this interaction is two fold:
first the confronter's suggestion that the choosing agent has made }%DIFDELCMD < \enquote{incorrect} %%%
\DIFdel{choices is paternalistic, and secondly, the requirement that only an exemplary decision maker must be convinced of the superiority of the economic theory because non-exemplary agents will mimic the exemplary agents is also paternalistic.
Some scholars have strong views either for or against appeals to paternalism being used in normative justifications of theories of agency.
We do not explicitly take a stand on the appropriateness of paternalism in normative arguments one way or the other, rather, we simply note that certain versions of this normative criteria can be interpreted as an appeal to paternalism.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{The notion that subjects would change their choices to be in line with some proposed normative theory because the theory itself is convincing seems somewhat dubious as an empirical matter.
There could be any number of reasons why an agent would change her choices to conform with the suggestions of the }%DIFDELCMD < \enquote{confronter}%%%
\DIFdel{, only one of which is that she has been convinced of the validity of the theory.
Indeed, the version of WCC that suggests the }%DIFDELCMD < \enquote{confronter} %%%
\DIFdel{need only convince an exemplary decision maker presents us with the clearest case as to why an agent would change her choices: she is mimicking the behavioral patterns of an expert.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{If the }%DIFDELCMD < \enquote{confronter} %%%
\DIFdel{suggests that the optimal strategy in a choice problem is $X$ because it will lead to welfare improvement, should the agent consider the }%DIFDELCMD < \enquote{confronter} %%%
\DIFdel{to be an expert in welfare assessment, then she needn't understand the mechanisms as to how $X$ leads to a welfare improvement, only that the expert would choose $X$ in this problem and therefore it is likely in her interest to also choose $X$.
To present the WCC criterion in the reverse of how its often employed, we can imagine an experiment performed where the principal investigator of the study, introduced as an expert in economic theory, suggests to subjects that conform to one theory, say RPT, that they should instead make choices in conformance with some other theory or choice principal that minimally deviates from RPT in some theoretically significant fashion.
For instance, a theory that allows intransitive preferences such as Regret Theory }%DIFDELCMD < \parencite{Loomes1987, Bell1982}%%%
\DIFdel{.
It is difficult to imagine that }\textit{\DIFdel{no}} %DIFAUXCMD
\DIFdel{subjects would take on the suggestions of }\DIFdelend \DIFaddbegin \DIFadd{Such a confrontation of experts is famously said to have occurred at a conference on decision theory held in Paris in May 1952 between Lenard Savage and Maurice Allais }\parencites[1]{Allais1953}[221]{Moscati2016}\DIFadd{.
Savage, having presented arguments for EUT during the conference, was asked by Allais to choose a lottery ticket he would prefer to own from two pairs of lottery tickets.
Savage made choices over these two lottery pairs that violated the Independence Axiom of EUT, and was confronted by Allais with proof of }\DIFaddend the \DIFdelbegin \DIFdel{principal investigator and change their choices from RPT because of }%DIFDELCMD < \enquote{the theory being absolutely convincing.} \parencite[712]{Morgenstern1972}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \DIFadd{violation.
Allais argued that if even Savage did not make choices in accordance to EUT, it could not be accepted as a normative theory.
Savage replied that he had made a mistake in his choices, and having been confronted with the error was willing to correct his choices.
He argued that his willingness to change his choices having been confronted with his error was evidence in favor of the normative validity of EUT.
In the terms of his private correspondence with Samuleson, he would have nothing to }\enquote{reproach} \DIFadd{himself for in having changed his choices to be in accordance with EUT. }\parencite[230]{Moscati2016}
\DIFaddend 

\DIFdelbegin \DIFdel{We can dispense with the problems associated with paternalism in the WCC criterion by eliminating the }%DIFDELCMD < \enquote{agent-as-confronter} %%%
\DIFdel{aspect entirely. }\DIFdelend Most often, agents engaging in economically salient choices are not confronted by other agents directly with suggestions about how their choices could better conform to some normative theory.
Instead, agents are generally only confronted with the way their choices deviate from an economic theory indirectly through market forces.
We can reformulate the WCC criterion with market forces as the confronter of agents and pose the following question:
\DIFdelbegin %DIFDELCMD < \enquote{When confronted with salient market outcomes resulting from choices that are discordant with some theory, do agents willing change their choices to be in accordance with the theory in similar subsequent market interactions?}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \enquote{When confronted with salient market outcomes resulting from choices that are discordant with some theory, do agents willingly change their choices to be in accordance with the theory in similar subsequent market interactions?}
\DIFaddend 

\textcite{Chu1990} deliver \DIFdelbegin \DIFdel{strong }\DIFdelend evidence in favor of EUT responding to exactly this question.
They conduct an experiment replicating the design of \textcite{Grether1979}, which found frequent deviations from EUT, specifically, apparent violations of transitivity\DIFdelbegin \DIFdel{, a result replicated in many other experiments}\DIFdelend .
\textcite{Chu1990} differ from the previous replications of \textcite{Grether1979} by actively engaging in the arbitrage of subjects who committed apparent violations of transitivity, thus experimentally simulating the kind of market forces that would operate outside of the laboratory.
\textcite[910]{Chu1990} find that incidences of apparent violations of transitivity were eliminated from all subjects choices after an average of $1.71$ arbitrage transactions, and that \enquote{subjects displayed substantially fewer reversals \textins{apparently intransitive choices} after they were exposed to a marketlike environment in previous rounds of games.}
The largest number of arbitrage transactions needed to induce conformity to the transitivity axiom was $3$, and this number of transactions occurred for only one subject across all of their treatments.

\DIFdelbegin \DIFdel{If we consider violations of the MEE criterion discussed in the previous section as violations of }\textit{\DIFdel{any}} %DIFAUXCMD
\DIFdel{normative theory, then our }\DIFdelend \DIFaddbegin \DIFadd{Our }\DIFaddend revised WCC criterion requires that exposure to market forces must induce a \enquote{correction} to choices that do not consistently \DIFdelbegin \DIFdel{violate MEE}\DIFdelend \DIFaddbegin \DIFadd{lead to worse welfare outcomes, such as the arbitrage transactions implemented by \textcite{Chu1990}}\DIFaddend .
TR and RE models handle this requirement in 2 ways.
First, both classes of models are structured such that the most likely choice in every choice scenario is one that will leave the agent at least as well off as she currently is.
Thus there is a \DIFdelbegin \DIFdel{built in }\DIFdelend \DIFaddbegin \DIFadd{built-in }\DIFaddend correcting mechanism in these models.
Secondly, one could model the relevant stochastic parameters, $\phi$ in the case of the TR model and $D(\beta,X)$ or $\lambda$ in the case of RE models, as being determined in part by the number of choice problems \DIFaddbegin \DIFadd{(or arbitrage transactions) }\DIFaddend experienced with the assumption of a negative coefficient.
With this specification, increased market interaction would lead to lower probabilities of mistakes, and in the limit would result in choices conforming with \DIFdelbegin \DIFdel{RPT}\DIFdelend \DIFaddbegin \DIFadd{EUT}\DIFaddend , just as was observed in \textcite{Chu1990}.

However, \DIFdelbegin \DIFdel{since the RP class of models don't subscribe to MEE, }\DIFdelend it isn't clear that \DIFdelbegin \DIFdel{these }\DIFdelend \DIFaddbegin \DIFadd{RP }\DIFaddend models provide any guidance as to what should be corrected.
In the stand-alone RP and RPPO models, \textit{all} choices result in optimal welfare, even if aggregated choices result in the strict reduction in the agent's stock of assets.
Even if the parameters of the RP model are themselves determined by the number of choice scenarios experienced in such a way \DIFdelbegin \DIFdel{as to make choices more consistent with MEE, for instance, by making the standard deviation of the distribution described for Amy in the SMP example decrease with market experience}\DIFdelend \DIFaddbegin \DIFadd{that decreases the probability of a deviation from EUT}\DIFaddend , there is inherently no \DIFaddbegin \DIFadd{welfare relevant }\DIFaddend \enquote{correction} occurring;
agents can be characterized as just as well off or potentially better off by \textit{not} approaching consistency with \DIFdelbegin \DIFdel{MEE}\DIFdelend \DIFaddbegin \DIFadd{EUT}\DIFaddend .
Thus, the RP class of models do not provide \DIFdelbegin \DIFdel{normative coherence }\DIFdelend \DIFaddbegin \DIFadd{normatively useful statements }\DIFaddend with respect to the WCC criterion.

\DIFdelbegin \subsection{\DIFdel{Ought Implies Can (OIC) Criterion}}
%DIFAUXCMD
\addtocounter{subsection}{-1}%DIFAUXCMD
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{The two previous criteria for normative theories have involved defining what specific }%DIFDELCMD < \enquote{oughts} %%%
\DIFdel{are recommended by the theory and discussing whether they are reasonable.
A somewhat different take on a requirement for normative acceptance is the notion that the }%DIFDELCMD < \enquote{oughts} %%%
\DIFdel{recommended by a theory must, in reality, be possible to be obtained.
This criteria has been put forward by the FFH project as an argument against RPT because, they claim, }\textit{\DIFdel{no}} %DIFAUXCMD
\DIFdel{agent can posses the information processing capacity to possible take account of all salient signals in }\textit{\DIFdel{every}} %DIFAUXCMD
\DIFdel{possible environment, and also have a powerful enough mind to discover and pursue the optimal response to such stimuli.
If no agent }\textit{\DIFdel{can}} %DIFAUXCMD
\DIFdel{in fact adhere to the retirements of the theory in question, the argument goes, then the theory cannot be taken as normatively compelling.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{For this criteria, it is useful to look at the reasons why the three major stochastic model classes were formulated to begin with.
To be sure, all of the stochastic models had a descriptive aim when they were formulated.
Apparent deviations from RPT required at least an econometric method to handle observed data.
But, in justifying the manner in which each class of stochastic model coped with the apparent deviations, these models incorporate aspects that are generally associated with the psychology of agents, and in some cases, these psychological underpinnings help the models to conform to the OIC criterion.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{The TR model attempts to capture noise in data that is attributable to a }%DIFDELCMD < \enquote{tremble}%%%
\DIFdel{, meaning that subjects in experiments would have correctly identified the option that made them the best off but, when committing to a choice, they would mistakenly select a different option with some constant probability.
This motivation for a model doesn't appear to attempt to address the concern from the FFH program about the inability of agents to perform optimization, only the occasional inability of agents to translate this optimization accurately into choice.
The example of Emma in the SMP thought experiment and the models employed by \textcite{Loomes2002} show that in the TR model there is nothing particularly special about the process that evaluates the value of the options, the model operates only on the choice probabilities.
In as much the process that evaluates which option makes agents the best off is not the concern of the TR model, and that agents can }%DIFDELCMD < \enquote{tremble} %%%
\DIFdel{when they attempt to actualize the evaluation process and select some alternative at random, we can say the TR model satisfies the OIC criterion.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{The RE models, however, seem to fare better in this account.
RE models are often called }%DIFDELCMD < \enquote{Fechnerian} %%%
\DIFdel{models after the work of Gustov Fechner }%DIFDELCMD < \parencite{Fechner1966a}%%%
\DIFdel{, a German psycho-physicist and experimental psychologist.
Fechner's work was often concerned with the limits of human perception of physical stimuli, such as the minimally perceptible difference in weight of two hidden objects.
The RE models directly incorporate this concept of }%DIFDELCMD < \enquote{measurement error} %%%
\DIFdel{through the $\lambda$ and $D(\beta,X)$ terms as described in equation (\ref{eq2:RE.2}).
The $\lambda$ term is directly proportional to the standard deviation of a random measurement error of }\textit{\DIFdel{utility}} %DIFAUXCMD
\DIFdel{as opposed to physical stimuli.
This concept of utility being measured with error seems to directly address the criticism put forth against the RPT by the FFH program.
Indeed, for certain distributions of the error, $F(\cdot)$, and/or certain adjusting functions, $D(\beta_n,X)$, the RE models imply that an agent cannot precisely measure her utility in an optimal fashion in }\textit{\DIFdel{any}} %DIFAUXCMD
\DIFdel{decision problem.
The concept that agents measure their utility of an option in a manner analogous to how the same agents would measure the difference in weight of alternative psychical objects seems to entirely satisfy the OIC criterion.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{The RP models, far from incorporating elements that seem plausible for an agent to operationalize, add to the optimization problem associated with RPT the necessity of maintaining a set of preferences that are randomly drawn from for every choice problem.
It must be possible to optimize over each element of this set of preferences.
The process of randomly drawing a preference relation from a set of such relations is not consistent with the OIC criterion.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend \section{Concluding Remarks}

In this chapter we have shown that over the last several decades, stochastic models of economic agents have been given an increasing amount of attention and have discussed three classes of models at length: the \enquote{Tremble} (TR) model, the \enquote{Random Error} (RE) model, and the \enquote{Random Preference} (RP) models.
The primary purpose of introducing these models was to better account for the apparent deviations from \DIFdelbegin \DIFdel{rational preference theory (RPT) }\DIFdelend \DIFaddbegin \DIFadd{EUT }\DIFaddend frequently observed in experimental data.
To further this descriptive purpose, these models introduced aspects with a great deal of attention paid to necessary implications of these models on the choice probabilities of several distinct types of decision problems.
The TR model requires that all deviations from \DIFdelbegin \DIFdel{RPT }\DIFdelend \DIFaddbegin \DIFadd{EUT }\DIFaddend were equally likely;
The SU model requires Strong Stochastic Transitivity;
The RP model requires that violations of FOSD have a zero probability of occurring.

Additionally, these models \DIFdelbegin \DIFdel{were }\DIFdelend \DIFaddbegin \DIFadd{are }\DIFaddend formulated mathematically to be parsimonious and modular, meaning that the stochastic elements of these models effectively never \DIFdelbegin \DIFdel{interfered }\DIFdelend \DIFaddbegin \DIFadd{interfere }\DIFaddend with the elements concerned with utility.
The TR model and most of the RE models only require the estimation of one parameter in addition to whatever model of utility is employed, whereas the common interpretations of the RP model only \DIFdelbegin \DIFdel{required }\DIFdelend \DIFaddbegin \DIFadd{require }\DIFaddend the additional estimation of two parameters.
The modularity of these models also \DIFdelbegin \DIFdel{allowed }\DIFdelend \DIFaddbegin \DIFadd{allows }\DIFaddend for researchers such as \textcite{Loomes2002} to occasionally combine them to address potential descriptive shortfalls from the individual models.

However, the main purpose of this chapter is not to illustrate the descriptive capabilities of these models, but to draw attention to the normative implications and potential justifications of these models.
We propose a simple thought experiment involving a contrived decision problem, the \enquote{Stochastic Money Pump} (SMP), and several hypothetical agents who individually operate differing classes of stochastic models when making choices.
The SMP is structured in such a way as to demonstrate the possibility of an agent entering into a decision problem and leaving with a strictly lower stock of assets, similar to the result of the traditional \enquote{money pump}.
With the SMP in hand, we show that\DIFaddbegin \DIFadd{, }\DIFaddend at least for this decision problem, each of the major classes of stochastic models can be parameterized in such a way that they produce exactly the same descriptive choice probabilities.
This descriptive equality, however, does not in any way imply that the welfare implications of these models are equivalent or even coherent.

We show that for the examples of the models given, the TR and RE models make equivalent implications concerning the welfare of agents, in particular, that agents who have had some of their assets extracted from them are modeled as strictly worse off than if this \DIFdelbegin \DIFdel{has }\DIFdelend \DIFaddbegin \DIFadd{had }\DIFaddend not happened.
The same cannot be said about the RP model or any of its derivatives, such as the proposed \enquote{Random Preference Per Option} \DIFaddbegin \DIFadd{(RPPO) }\DIFaddend model or the RP-TR combination model.
The mathematical descriptions of welfare from these models beg the larger question of how or whether the stochastic models can be normatively justified.

We attend to the discussion of normative coherences by \DIFdelbegin \DIFdel{adopting the framework of instrumental rationality that is often used when discussing RPT and the fast and frugal heuristics (FFH) programs}\DIFdelend \DIFaddbegin \DIFadd{first noting the historical and contemporary emphasis on the ability of an economic theory to make statements about welfare that are useful when discussing policy}\DIFaddend .
We attempt to limit the discussion by focusing on \DIFdelbegin \DIFdel{three }\DIFdelend \DIFaddbegin \DIFadd{two }\DIFaddend prominent criteria used historically and presently when constructing normative justifications: \DIFdelbegin \DIFdel{the }\DIFdelend \enquote{Economic Elimination} (EE) \DIFdelbegin \DIFdel{, }\DIFdelend \DIFaddbegin \DIFadd{and the }\DIFaddend \enquote{Willingness to Correct Choices} (WCC)\DIFdelbegin \DIFdel{, and }%DIFDELCMD < \enquote{Ought Implies Can} %%%
\DIFdel{(OIC) criteria}\DIFdelend .

We argue that the EE criterion requires adherence to a notion that strictly greater stocks of assets are objectively better than smaller stocks of assets, and normative models must require agents to subjectively conform to this valuation.
We conclude that only the RE and TR models make coherent statements with respect to EE; the SMP thought experiment demonstrates how the RP model allows for the implication that agents who have had assets extracted from them are subjectively better off than not having been extracted from.

We argue that to effectively posit the WCC criterion as a condition for normative coherence, the role of the \enquote{confronter} must be relegated to the market.
In this interpretation, the WCC builds on the notion of \enquote{objective betterness} described by EE by stating that having been confronted with the market outcomes of a choice, should the agent face the same decision again, the most likely choice she will make will leave her at least as well off as her previous choice.
We conclude that again the RE and TR models make coherent statements with respect to this criterion, but the RP models do not.

\DIFdelbegin \DIFdel{The final criterion considered, OIC, states that the process implied by the model must be able to be actualized by the agents the model is said to describe.
This criterion has often been proposed by the FFH program as a critique of RPT, but can be discussed with respect to stochastic models as well.
We argue that the RE and TR models present mechanisms which can be said to usefully approximate physical and psychological mechanisms that we might suppose to exist in economic agents; the failure to actualize a decision having already decided which option provides the greatest welfare, and that measurement of utility is prone to error in much the same way as measurement is prone to error in other contexts.
We conclude that the RE and TR models therefore satisfy the OIC criterion, whereas the RP model stipulates further barriers to psychological approximation.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend We find that the motivations of the RP model as a descriptive model of \DIFdelbegin \DIFdel{chocie probabilites }\DIFdelend \DIFaddbegin \DIFadd{choice probabilities }\DIFaddend are relatively sound.
There has been some evidence showing the RP model does statistically fit choice data better than many alternative models, particularly when combined with the TR model.
The RPPO model presents the possibility of even greater statistical fit, particularly since it allows for the violation of FOSD in certain choice scenarios.{\footnotemark}
Whether the RPPO model does in fact perform statistically better than other stochastic models is an empirical question that hasn't been given much attention.

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	The normalized RPPO model doesn't allow an option with a single certain outcome to be chosen over an option with a larger single certain outcome, but the un-normalized RPPO model might, depending on the particular utility functions being utilized and distributions of parameters.
}

We argue that the RPPO model shouldn't be given much attention.
The RP and RPPO models both exist in a territory of economic modeling that concerns itself with statistical fit and predictive quality, which are indeed things \DIFdelbegin \DIFdel{economist }\DIFdelend \DIFaddbegin \DIFadd{economists }\DIFaddend should be concerned about, but cannot be used to make persuasive arguments about how an agent \DIFdelbegin \DIFdel{accumulates }\DIFdelend \DIFaddbegin \DIFadd{maintains }\DIFaddend economic welfare through choices.
It is the latter of these two concerns which constitute the economic, as opposed to the technical, content of the inquiry.
The exercise presented in this chapter helps to inform the econometric question proposed by analysts of \enquote{what is the \enquote{best} stochastic model?} by suggesting that the \enquote{best} model is the one which has the greatest \enquote{fit} among the models \textit{\DIFdelbegin \DIFdel{which }\DIFdelend \DIFaddbegin \DIFadd{that }\DIFaddend make normatively coherent statements about the welfare of the modeled agents.}

We conclude from this experiment that the RP model's failure to provide coherent statements on how the choice mechanism relates to \DIFaddbegin \DIFadd{a useful interpretation }\DIFaddend welfare should disqualify it as \DIFdelbegin \DIFdel{an }\DIFdelend \DIFaddbegin \DIFadd{a }\DIFaddend model for economic agency, regardless of any evidence that suggests it is a better fitting model.
We recognize that rejecting a model that potentially fits choice data from economic experiments better than its alternative seems counter-empiricist, but if estimates from these models are only useful in describing choice probabilities, and not the welfare implications of the choices made, the model is not useful in economic applications and must be discarded.

\newpage

\DIFdelbegin %DIFDELCMD < \printbibliography[segment=2, heading=subbibliography]
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \DIFadd{\onlyinsubfile{
\newpage
\printbibliography[segment=2, heading=subbibliography]
}
}\DIFaddend 



\onehalfspacing
\setcounter{chapter}{2}

\chapter{The Welfare Implications of Stochastic Models\DIFdelbegin \DIFdel{: An Analysis by Simulation}\DIFdelend }

\lltoc % Table of contents only when locally compiled

Given the discussion about how the various stochastic models generally deal with the normative notion of welfare, we would like to reintroduce the question asked earlier \DIFaddbegin \DIFadd{in Chapter 2, section 2.2}\DIFaddend : 
\enquote{What are the likely welfare implications of an economic agent's choices in an incentivized environment given an assumed stochastic model of choice?}
Our conclusion for the \DIFdelbegin \DIFdel{RP }\DIFdelend \DIFaddbegin \DIFadd{Random Preference (RP) }\DIFaddend model and its derivative, the \DIFdelbegin \DIFdel{RPPO }\DIFdelend \DIFaddbegin \DIFadd{Random Preference Per Option (RPPO) }\DIFaddend model, is \enquote{no coherent statements can be made.}
As stated \DIFdelbegin \DIFdel{previously, the RE and TR }\DIFdelend \DIFaddbegin \DIFadd{in the conclusion of Chapter 2, the Random Error (RE) and Tremble (TR) }\DIFaddend models do not suffer from this inadequacy\DIFdelbegin \DIFdel{. 
The answer to the primary question for }\DIFdelend \DIFaddbegin \DIFadd{, and will be referred to as }\enquote{coherent models}\DIFadd{. 
In this chapter, we will continue to contribute to the answer of the primary question by utilizing }\DIFaddend coherent stochastic models, \DIFdelbegin \DIFdel{however, needs to be answered empirically}\DIFdelend \DIFaddbegin \DIFadd{a popular experimental preference elicitation instrument, and simulation methods to derive numerical characterizations of welfare}\DIFaddend .

In the \DIFdelbegin \DIFdel{SMP }\DIFdelend \DIFaddbegin \DIFadd{Stochastic Money Pump (SMP) thought experiment discussed in Chapter 2, section 2.4, }\DIFaddend we were able to discuss the welfare implications of Beth and Cate's choices because we assumed an experimenter had already identified the stochastic specification which completely characterized their choices.
Identifying a stochastic specification \DIFdelbegin \DIFdel{in reality }\DIFdelend typically involves presenting an experimental subject with a series of incentivized choice problems in which the subjects are asked to select an option from a set of alternatives.
The subject's choices in such an experiment are \DIFdelbegin \DIFdel{said }\DIFdelend \DIFaddbegin \DIFadd{assumed }\DIFaddend to reveal their preferences.
But, as we have seen with the SMP example, \DIFaddbegin \DIFadd{even }\DIFaddend coherent stochastic models imply that most choices by an economic agent can be characterized as welfare suboptimal with a probability less than or equal to the probability of the choice being optimal.
This applies to choices which are apparently incompatible with optimality, as well as choices which can be rationalized as optimal.
This property of stochastic models can lead to misidentification of the parameter set $\beta$ which shapes the stochastic specification.
This, in turn, can lead to a mis-characterization of the welfare effects of certain choices.
To understand the consequences of an assumed stochastic model, we will look at another numerical example utilizing the popular Multiple Price List (MPL) utilized by Holt \& Laury (2002) (HL).
First however, we will \DIFdelbegin \DIFdel{describe briefly }\DIFdelend \DIFaddbegin \DIFadd{revisit some notation from Chapter 2, briefly describe }\DIFaddend some econometric methods for identification, and then propose some \DIFdelbegin \DIFdel{more }\DIFdelend \DIFaddbegin \DIFadd{further }\DIFaddend notation to make concepts cleaner.

\DIFdelbegin \DIFdel{As shown previously, the probability of }\DIFdelend %DIF > We consider knowledge of the welfare of individual agents of great importance to economists.
%DIF > It is often the case, however, in the application of economic principals knowledge of the welfare consequences to any given individual matters less than the welfare consequences to groups of individuals.
%DIF > For example, when a government policy compels citizens to make an economic choice, such as the purchase of health insurance or the payment of a penalty, the government or those analyzing the policy may be concerned with the welfare effects of this policy across the entire citizenry, not just the effect of a given citizen.
%DIF > With a policy such as this, many citizens with differing preferences may make exactly the same choice to purchase or not purchase the insurance product, with some citizens mistakenly purchasing or not purchasing the insurance product.
%DIF > A government or policy analyst may want to know the distribution of welfare consequences among those who have or have not purchased the insurance in order to make better policy or policy recommendations with respect to welfare.
\DIFaddbegin 

\section{\DIFadd{Notation and Estimation}} \label{ssec:Notation}

\DIFadd{For any salient lottery $X_j$, and any vector of parameters $\beta_n$, there exists some certain outcome, $\CE_j$, such that subject $n$ is indifferent between the lottery and the certainty equivalent:
}\begin{equation}
	\DIFadd{\label{eq3:CE.indiff}
	X_j \sim^n }{\DIFadd{\CE}}\DIFadd{_j \;\Leftrightarrow\; G(\beta_n,X_j) = G(\beta_n, }{\DIFadd{\CE}}\DIFadd{_j)
}\end{equation}

\noindent \DIFadd{where $G(\cdot)$ is some utility function with all the usual properties.
For our purposes throughout this chapter, we will assume some variation of the Rank Dependent Utility structure defined as follows:
}\begin{equation}
	\DIFadd{\label{eq3:RDU}
	RDU = \sum_{i=1}^{I} \left[ w_i(p) \times u(x_i) \right]
}\end{equation}

\noindent \DIFadd{where $u(\cdot)$ is the CRRA utility function throughout this chapter:
}\begin{equation}
	\DIFadd{\label{eq3:CRRA}
	u(x) = \frac{x^{(1-r)}}{(1-r)}
}\end{equation}

\noindent \DIFadd{and $w_i(p)$ is the decision weight applied to option $i$ defined as follows:
}\begin{equation}
	\DIFadd{\label{eq3:dweight}
	w_i(p) =
	\begin{cases}
		\omega\left(\displaystyle\sum_{j=i}^I p_j\right) - \omega\left(\displaystyle\sum_{k=i+1}^J p_k\right) & \text{for } i<I \\
		\omega(p_i) & \text{for } i = I
	\end{cases}
}\end{equation}

\noindent \DIFadd{where $\omega(\cdot)$ is a probability weighting function.
In cases where $\omega(p_i) = p_i$, the RDU structure is equivalent to Expected Utility Theory (EUT) as the decion weights for each option will equal their objective values.
Many paramterized probability weighting functions allow for this special case to occur.
}

\DIFadd{Combining the Rank Dependent Utility (RDU) structure with a CRRA utility function, we can define the }{\CE} \DIFadd{as follows:
}\begin{align}
	\DIFadd{\label{eq3:CEcalc}
	\begin{split}
		G(\beta_n,X_j) &= \sum_{i=1}^{I} w_i(p) \frac{x_{ij}^{(1-r)}}{(1-r)} = \frac{ {\CE}_j^{(1-r)}}{(1-r)}\\
		{\CE}_j &=  \left( (1-r) \times \sum_{i=1}^{I} w_i(p) \frac{x_{ij}^{1-r}}{(1-r)} \right)^{ \displaystyle\nicefrac{1}{(1-r)} }
	\end{split}
}\end{align}

\noindent \DIFadd{where $i$ indexes the $I$ outcomes of option $j$ in task $t$. 
}


\DIFadd{We continue the notation from Chapter 2 where the value of $j$ also represents each option's ordinal rank among the alternative options in task $t$.
Thus $X_1 \succcurlyeq X_2$ and $X_j \succcurlyeq X_k$, where $k \geq j$.
Similarly, we define the set of unchosen options from the full set of alternatives as $Z = t \,\backslash\, y = \{z \in t \;|\; z \notin y \}$, with the subscript on the elements of $Z$ indicating their ordinal rank in the set of $Z$.
Thus $X_1^Z \succcurlyeq X_2^Z$ and $X_j^Z \succcurlyeq X_k^Z$, where $k \geq j$.
}

\DIFadd{The probability of }\DIFaddend any choice $j$ by some subject $n$, given some vector \DIFaddbegin \DIFadd{of parameters }\DIFaddend $\beta$, being observed for a task $t$, is denoted by $\Pr( y_t = j)$\DIFaddbegin \DIFadd{, where $y_t = j$ is an indicator function that records option $j$ as being chosen in task $t$}\DIFaddend .
To make explicit the dependency of this probability on the option in question, the subject, the task, and the $\beta$ vector, this relationship will be re-framed as follows:
\begin{equation}
	\DIFdelbegin %DIFDELCMD < \label{eq:Pnjt}
%DIFDELCMD < 	%%%
\DIFdelend \DIFaddbegin \label{eq3:Pnjt}
	\DIFaddend P_{njt}(\beta_n) = \Pr(y_i = j)
\end{equation}

The likelihood of observing a series of choices is \DIFdelbegin \DIFdel{simply }\DIFdelend the product of the probability of observing the option chosen for each task across all tasks, $T$ :
\begin{equation}
	\DIFdelbegin %DIFDELCMD < \label{eq:PnT}
%DIFDELCMD < 	%%%
\DIFdelend \DIFaddbegin \label{eq3:PnT}
	\DIFaddend P_{nT}(\beta_n) =  \prod_{t}^{T} P_{njt}(\beta_n)
\end{equation}

\DIFaddbegin \noindent \DIFaddend This is the standard likelihood function applied to choice data.
We could take the log of equation (\DIFdelbegin \DIFdel{\ref{eq:PnT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:PnT}}\DIFaddend ) and conduct standard maximum likelihood estimation (MLE) by searching for the vector $\hat{\beta}_n$ which maximizes the log-likelihood function:
\begin{equation}
	\DIFdelbegin %DIFDELCMD < \label{eq:LPnT}
%DIFDELCMD < 	%%%
\DIFdelend \DIFaddbegin \label{eq3:LPnT}
	\DIFaddend \mathit{LP}_{nT}(\beta_n) = \sum_{t}^{T} \ln \left( P_{nit}(\beta_n) \right)
\end{equation}

\DIFaddbegin \noindent \DIFaddend Thus, the maximum likelihood estimator $\hat{\beta}_n$ for subject $n$ is:
\begin{equation}
	\DIFdelbegin %DIFDELCMD < \label{eq:Bn}
%DIFDELCMD < 	%%%
\DIFdelend \DIFaddbegin \label{eq3:Bn}
	\DIFaddend \hat{\beta}_n = \underset{x}{\operatorname{arg\,max}}\sum_t^T \ln \left( P_{nit}(\beta_n) \right)
\end{equation}

We can utilize this estimator to recover the \DIFdelbegin \DIFdel{CE }\DIFdelend \DIFaddbegin {\CE} \DIFaddend for every option in every task, and then utilize these \CE s to recover our best estimate of the proportion of welfare the subject obtained. 
While conducting welfare analysis given individually estimated parameter vectors is rare in the economics literature,{\footnotemark} the recovery of parameter vectors through MLE is as common as the welfare analysis is rare.
\textcite{Hey1994}, \textcite{Wilcox2015}, and \textcite{Hey2001} provide several prominent examples of parameter estimation.
These particular examples, however, are distinctly different from other uses of MLE in experimental economics, primarily because equation (\DIFdelbegin \DIFdel{\ref{eq:Bn}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:Bn}}\DIFaddend ) is estimated for every subject individually, as opposed to pooling all subject data together and estimating a parameter vector for one, representative agent (RA)\DIFaddbegin \DIFadd{, e.g. \textcite{Camerer1994}}\DIFaddend .

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	An example of this kind of analysis is \DIFdelbegin \DIFdel{\textcite{Harrison2015}
}\DIFdelend \DIFaddbegin \DIFadd{\textcite{Harrison2016}
}\DIFaddend }

There are legitimate methodological (and practical) reasons for modeling choices across subjects as the choices of a single RA.
For instance, the analyst could be primarily concerned with the economic characteristics of the whole sample, rather than with the individuals composing the sample.
As shown in \textcite[142]{Harrison2008a}, it is easy to allow the $\hat{\beta}$ to be determined by a linear combination of observable characteristics of either the subjects or experimental treatments.
For instance, if the race, gender and age of each of the subjects were known, we could estimate:
\begin{equation}
	\DIFdelbegin %DIFDELCMD < \label{eq:BB}
%DIFDELCMD < 	%%%
\DIFdelend \DIFaddbegin \label{eq3:BB}
	\DIFaddend \bm{\hat{\beta}} = \hat{\beta}_0 + \hat{\beta}_1 \times \mathit{race} + \hat{\beta}_2 \times \mathit{gender} + \hat{\beta}_3 \times \mathit{age}
\end{equation}
\noindent where $\hat{\beta}_1$ through $\hat{\beta}_3$ represent the mean marginal effects of race through age respectively on the vector $\bm{\hat{\beta}}$.
\DIFaddbegin 

\DIFaddend Another useful technology \DIFaddbegin \DIFadd{demonstrated by \textcite{Harrison2008a} }\DIFaddend for RA modeling is the use of finite mixture modeling.
This is when a finite mixture of stochastic specifications are estimated jointly on the same data along with mixture parameters.
For instance,
\begin{align}
	\DIFdelbegin %DIFDELCMD < \label{eq:PT_Mix}
%DIFDELCMD < 	%%%
\DIFdelend \DIFaddbegin \label{eq3:PT_Mix}
	\DIFaddend \begin{split}
		\bm{\mathit{P_T}} = \prod_t^T \left[ \sum_m^M \pi_m \times L_T^m(\beta^m) \right]\\ 
		\mathit{st.} \sum_m^M \pi_m = 1
	\end{split}
\end{align}

\noindent where $\pi_m$ is the proportion of model $m$ in the mixture, $\beta$ is the vector of parameters to be estimated in model $m$ and $L_T^m$ is the likelihood of the choice data across the $T$ tasks is explained by model $m$ given the vector $\beta^m$.
Similarly, the log-likelihood for finite mixture models is defined as:
\begin{align}
	\DIFdelbegin %DIFDELCMD < \label{eq:LPT_Mix}
%DIFDELCMD < 	%%%
\DIFdelend \DIFaddbegin \label{eq3:LPT_Mix}
	\DIFaddend \begin{split}
		\bm{\mathit{LP_T}} = \sum_t^T \left[ \ln \left( \sum_m^M \pi_m \times L_T^m(\beta^m) \right) \right]\\ 
		\mathit{st.} \sum_m^M \pi_m = 1
	\end{split}
\end{align}

\DIFaddbegin \noindent \DIFaddend Thus, $M$, $\beta^m$ and $M-1$, $\pi_m$ vectors need to be estimated.
These parameters can additionally be determined by observed characteristics, as in equation (\DIFdelbegin \DIFdel{\ref{eq:BB}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:BB}}\DIFaddend ).
This method can be useful if the analyst wishes to estimate the proportion of a sample which more closely adheres to RDU versus EUT for instance, or if the analyst wants to determine if there is some heterogeneity in the sample that is revealed by choice, but unobservable otherwise.
\textcite[141]{Harrison2008a} use this method to jointly estimate a specification composed of Prospect Theory (PT) and EUT.
They employ a \DIFdelbegin \DIFdel{SU }\DIFdelend \DIFaddbegin \DIFadd{Strong Utility (SU) }\DIFaddend stochastic model to generate the probabilities.
\DIFdelbegin \DIFdel{Though we're not aware of }\DIFdelend \DIFaddbegin \DIFadd{Although there does not appear to be }\DIFaddend any literature doing so, it is possible to estimate a mixture of two differing stochastic models.
For instance, \DIFdelbegin \DIFdel{finding a mixture of subjects }\DIFdelend \DIFaddbegin \DIFadd{an analyst could use a mixture model to determine what proportion of subjects in a dataset are }\DIFaddend better explained by the SU or TR models.{\footnotemark}

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	This process could be used to help with the econometric \DIFdelbegin \DIFdel{failures }\DIFdelend \DIFaddbegin \DIFadd{limitations }\DIFaddend of the pure RP model as those subjects who violate FOSD can be picked up by an alternative model which permitted such violations. 
	This process, of course, doesn't resolve the RP model's normative failures \DIFdelbegin \DIFdel{.
}\DIFdelend \DIFaddbegin \DIFadd{discussed in chapter 2.
}\DIFaddend }

There are also some methodological problems, or at least limitations\DIFaddbegin \DIFadd{, }\DIFaddend when conducting estimation on pooled data.
The estimates represent the means \DIFaddbegin \DIFadd{of }\DIFaddend the relevant parameters in the sample, but often the distributions of these parameters and whether these distributions are correlated provide more important information to analysts.{\footnotemark} 
While the methods described in equations (\DIFdelbegin \DIFdel{\ref{eq:BB}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:BB}}\DIFaddend ) and (\DIFdelbegin \DIFdel{\ref{eq:PT_Mix}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:PT_Mix}}\DIFaddend ) provide some insight into the heterogeneity of a pooled sample, this is mostly limited to estimating average deviations from the mean due to observable heterogeneity.
While it is theoretically possible to have a mixture model with greater than two underlying stochastic specifications, in reality this is computationally demanding and thus the mixture model presented in (\DIFdelbegin \DIFdel{\ref{eq:PT_Mix}) is effectively limited to being able to identify }\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:PT_Mix}) is often only utilized with }\DIFaddend one or two \DIFdelbegin \DIFdel{unobservable characteristics}\DIFdelend \DIFaddbegin \DIFadd{mixtures}\DIFaddend .

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	For an example of why it could be problematic to make inferences about a population from an estimate which represents the mean of a distribution of preferences consider a population that has preferences distributed as $\textit{Logit-Normal} \sim \mathcal{N}(0,5)$. 
	See Figure 2 \DIFdelbegin \DIFdel{, }\DIFdelend \DIFaddbegin \DIFadd{of }\DIFaddend \textcite[83]{Andersen2012}.
	This distribution is highly bi-modal, and the area around the mean of the distribution has very low density. 
	Thus, if a single stochastic specification is estimated on a sample from this population, the estimated parameters representing their distributional means give highly misleading information about the choice behavior we would expect from individual agents sampled from this population. 
	In this case a mixture model of two models could potentially identify the modes, thus providing more, but still limited, information about the population.
	\DIFaddbegin \DIFadd{A similar approach is utilized by \textcite{Conte2011}.
}\DIFaddend }

Estimating parameter vectors for every subject in a sample helps to improve on this limitation.
If every subject has an individually estimated parameter vector, then an analyst can use the \DIFdelbegin \DIFdel{distributions }\DIFdelend \DIFaddbegin \DIFadd{distribution }\DIFaddend of these estimates to approximate the distribution of parameter vectors of the population this sample was drawn from.
This is not perfect however, the individually estimated parameters are still estimates, and thus they all have associated standard errors and positive probabilities of misidentification.
The likelihood of misidentification typically decreases with the number of choice tasks presented to subjects, just as standard errors are typically negatively correlated with sample size.
\textcite{Hey1994} estimate parameters for individual subjects utilizing 100 choice tasks per subject in order minimize the potential for misidentification.
\textcite{Hey2001} utilized 500 choice problems per subject.

\DIFaddbegin \addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	\DIFadd{As discussed in Chapter 2, the primary concern of economic analysis is to provide useful information about the welfare implications of policy or institutional rules.
	By and large, policy is written in a broad way so that it targets populations of individuals, as opposed to singling out individual agents.
	In this respect, knowledge of the distribution of preferences in a population provides useful information about the distribution of welfare effects of policy.
}}

\DIFaddend However, conducting experiments where subjects are required to give responses to a large number of tasks has practical problems which then spill over \DIFdelbegin \DIFdel{into }\DIFdelend \DIFaddbegin \DIFadd{and generates }\DIFaddend theoretical problems.
Subjects can become bored or tired, which may make the tasks less salient or cause them to fail to satisfy the dominance criteria as described by \textcite{Harrison1992}.
Often, experimenters utilize a random lottery incentive mechanism (RLIM) in experiments, selecting one choice by the subject at random for payment.
While in theory this is incentive compatible with EUT, it is not necessarily so with any utility theory that doesn't require the independence axiom (IA), such as RDU \DIFaddbegin \parencite{Harrison2014, Cox2015}\DIFaddend .
Furthermore, each additional choice task presented to the subject dilutes the expected outcomes of the other choice tasks.
This means that the task could fail the dominance criteria unless the outcomes are sufficiently scaled up, even if the outcomes and the payment mechanism are salient.
Thus, when the experimenter implements the RLIM for practical reasons, such as not needing to resolve and then compensate a subject for all of potentially hundreds of choices, he potentially introduces a serious theoretical concern.

These qualifications to estimation of individual parameter vectors should not be considered \DIFdelbegin \DIFdel{lethal to }\DIFdelend \DIFaddbegin \DIFadd{fatal for }\DIFaddend this method, but they should be noted when conducting this kind of estimation.
\textcite{Hey2001} split the 500 choice tasks over 5 days to help mitigate the potential for subjects to become bored.
Other experimenters split the \DIFdelbegin \DIFdel{T }\DIFdelend \DIFaddbegin \DIFadd{$T$ }\DIFaddend lottery tasks into smaller sets of tasks which are split by other, potentially unrelated, tasks.
These kind of \DIFdelbegin \DIFdel{efforts help to mitigate the methodological }\DIFdelend \DIFaddbegin \DIFadd{designs help mitigate the procedural }\DIFaddend problems with this kind of estimation, though sometimes they may introduce other concerns.
While subjects may be less bored by doing subjects over 5 days rather than all on one day, subjects may experience events in between sessions that change their beliefs about the lottery pairs presented during the sessions.
\DIFdelbegin \DIFdel{To a lesser extent, beliefs about lotteries could be changed when lottery tasks are split by other tasks in the lab.
}\DIFdelend 

An alternative method to \DIFdelbegin \DIFdel{recovering }\DIFdelend \DIFaddbegin \DIFadd{recover }\DIFaddend greater information on entire samples of agents is to estimate the distributions of the parameter vectors describing individual preferences directly from pooled data.
Instead of estimating preference parameters, the parameters which shape the distributions of preferences are estimated.
We can call equation (\DIFdelbegin \DIFdel{\ref{eq:Pnjt}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:Pnjt}}\DIFaddend ), which is at the heart of equations (\DIFdelbegin \DIFdel{\ref{eq:PnT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:PnT}}\DIFaddend ) through (\DIFdelbegin \DIFdel{\ref{eq:LPT_Mix}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:LPT_Mix}}\DIFaddend ), a conditional probability, because the probability is conditional on a particular $\beta$ vector.
We can however weight this function by the likelihood of observing the $\beta$ vector from a given distribution.\DIFaddbegin {\footnotemark}
\DIFaddend We call this weighted probability the unconditional probability:
\begin{equation}
	\DIFdelbegin %DIFDELCMD < \label{eq:Pnt}
%DIFDELCMD < 	%%%
\DIFdelend \DIFaddbegin \label{eq3:Pnt}
	\DIFaddend P_{nt}(\theta) = \int P_{nt}(\beta_n) f(\beta | \theta) d\beta	
\end{equation}
\noindent where $f(\beta|\theta)$ is the density function of the $\beta$ vector given some vector of hyper-parameters $\theta$ shaping the distribution of the $\beta$.

\DIFaddbegin \addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	\DIFadd{It is worth noting the relation of these statements to a Bayesian approach.
	Having knowledge of distribution of preferences in a population is akin to holding a prior in a Bayesian approach.
	This prior could then be incorporated with to condition individual level estates and produce an individual level choice probability.
	This Bayesian technique is different from the two approaches discussed here.
	The individual level approach discussed here does not incorporate a distributional prior in its estimation process, while the unconditional approach generates choice probabilities directly from pooled data, not individual data.
	If the unconditional approach discussed here was applied at an individual level, it would be equivalent to the Random Preference stochastic model.
}}

\DIFaddend This unconditional probability can be substituted for the conditional probability used in equations (\DIFdelbegin \DIFdel{\ref{eq:PnT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:PnT}}\DIFaddend ) and (\DIFdelbegin \DIFdel{\ref{eq:LPnT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:LPnT}}\DIFaddend ) to give us the unconditional likelihood equation:
\begin{equation}
	\DIFdelbegin %DIFDELCMD < \label{eq:LnT}
%DIFDELCMD < 	%%%
\DIFdelend \DIFaddbegin \label{eq3:LnT}
	\DIFaddend L_{nT}(\theta) = \prod_t^T P_{nt}(\theta)
\end{equation}

\noindent and its counterpart, the unconditional log-likelihood equation:
\begin{equation}
	\DIFdelbegin %DIFDELCMD < \label{eq:LLnT}
%DIFDELCMD < 	%%%
\DIFdelend \DIFaddbegin \label{eq3:LLnT}
	\DIFaddend \mathit{LL}_{nT}(\theta) = \sum_t^T \ln \left( P_{nt}(\theta) \right)
\end{equation}

Equations (\DIFdelbegin \DIFdel{\ref{eq:Pnt}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:Pnt}}\DIFaddend ) through (\DIFdelbegin \DIFdel{\ref{eq:LLnT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:LLnT}}\DIFaddend ) are computationally impossible to estimate directly due to \DIFdelbegin %DIFDELCMD < \enquote{the inability of computers to perform integration} %%%
\DIFdelend \DIFaddbegin \DIFadd{the general }\enquote{inability of computers to perform integration} \DIFaddend in a closed-form \parencite[2]{Train2002}.
However, equation (\DIFdelbegin \DIFdel{\ref{eq:Pnt}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:Pnt}}\DIFaddend ) can be approximated by simulation as follows:
\begin{equation}
	\DIFdelbegin %DIFDELCMD < \label{eq:SPnt}
%DIFDELCMD < 	%%%
\DIFdelend \DIFaddbegin \label{eq3:SPnt}
	\DIFaddend \mathit{SP}_{nt}(\theta) = \mathlarger{\sum}_h^H \frac{ P_{nt}(\beta^h) }{H}
\end{equation}

\DIFdelbegin \DIFdel{This }\DIFdelend \DIFaddbegin \DIFadd{Equation (\ref{eq3:SPnt}) }\DIFaddend needs some explanation.
The integration involved in equation (\DIFdelbegin \DIFdel{\ref{eq:Pnt}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:Pnt}}\DIFaddend ) is approximated by taking $H$ random draws of $\beta^h$ from the distribution governed by $\theta$, evaluating equation (\DIFdelbegin \DIFdel{\ref{eq:Pnjt}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:Pnjt}}\DIFaddend ) with these randomly drawn $\beta^h$\DIFaddbegin \DIFadd{, }\DIFaddend and taking a simple average across these evaluations.
Only a simple average is needed because if the $\beta^h$ vectors are drawn at random from the distribution governed by $\theta$, then the likelihood of their occurrence is already weighted by the distribution's density.

The use of $H$ as the term characterizing draws from a distribution is not arbitrary.
It indicates that the random draws will be approximated by a Halton sequence of numbers.
The Halton routine is a numerical method to produce a sequence of numbers which approximate random draws from a uniform distribution bounded between 0 and \DIFdelbegin \DIFdel{1.
The Halton sequence however }\DIFdelend \DIFaddbegin \DIFadd{1, and which }\DIFaddend has been shown to provide better coverage of the distribution than other pseudo-random{\footnotemark} number generators.{\footnotemark}

\addtocounter{footnote}{-2}
\stepcounter{footnote}\footnotetext{
	\DIFdelbegin \DIFdel{It is important to recognize that all }\DIFdelend \DIFaddbegin \DIFadd{All }\DIFaddend \enquote{random} numbers generated by computers are in fact \enquote{pseudo-random} numbers produced algorithmically. 
	\textcite[234]{Train2002} describes these numerical routines as follows: 
	\enquote{The intent in \textins{the} design \textins{of pseudo-random routines} is to produce numbers that exhibit the properties of random draws. 
		The extent to which this intent is realized depends, of course, on how one defines the properties of \enquote{random} draws.
		These properties are difficult to define precisely since randomness is a theoretical concept that has no operational counterpart in the real world.} 
	Because of the non-existence of truly \enquote{random} number generators, the term \enquote{random} will be used in place of \enquote{pseudo-random} throughout this text.
}
\stepcounter{footnote}\footnotetext{
	See the remainder of \textcite[Chapter~9]{Train2002} for an in-depth discussion and derivation of why Halton sequences are \DIFaddbegin \DIFadd{widely viewed as being }\DIFaddend superior to other pseudo-random number generators for the purposes of simulating estimators.
}

The \DIFaddbegin \DIFadd{Halton }\DIFaddend sequence of uniformly distributed numbers can be transformed into a sequence of randomly drawn numbers from any invertible, univariate distribution.
That is, if $\mu$ is taken to be a random variable indicating a draw from a uniform distribution, and $F(\epsilon)$ is an invertible, univariate, cumulative distribution, then given $\mu$, draws of $\epsilon$ from this distribution can be obtained by solving $\epsilon = F^{-1}(\mu)$.
\textcite[236]{Train2002} discusses this method for obtaining random draws from invertible, univariate distributions, as well as using Choleski transformations to obtain draws from multivariate normal distributions.

With this simulated unconditional probability, we can obtain the simulated unconditional \DIFdelbegin \DIFdel{log-likelihood }\DIFdelend \DIFaddbegin \DIFadd{likelihood }\DIFaddend by substituting equation (\DIFdelbegin \DIFdel{\ref{eq:SPnt}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:SPnt}}\DIFaddend ) for equation (\DIFdelbegin \DIFdel{\ref{eq:Pnt}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:Pnt}}\DIFaddend ) in equation (\DIFdelbegin \DIFdel{\ref{eq:LnT}):
}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:LnT}):
}\DIFaddend \begin{equation}
	\DIFdelbegin %DIFDELCMD < \label{eq:SLnT}
%DIFDELCMD < 	%%%
\DIFdelend \DIFaddbegin \label{eq3:SLnT}
	\DIFaddend \mathit{SL}_{nT}(\theta) = \prod_t^T \left[ \mathlarger{\sum}_h^H \frac{ P_{nt}(\beta^h) }{H} \right]
\end{equation}

Equation (\DIFdelbegin \DIFdel{\ref{eq:SLnT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:SLnT}}\DIFaddend ) is limited in terms of identifying $\theta$ because\DIFdelbegin \DIFdel{of }\DIFdelend \DIFaddbegin \DIFadd{, as indicated by }\DIFaddend the $n$ subscript, \DIFdelbegin \DIFdel{indicating that }\DIFdelend this metric is \DIFdelbegin \DIFdel{returned }\DIFdelend \DIFaddbegin \DIFadd{defined }\DIFaddend for a single agent.
Since the normatively coherent stochastic models \DIFdelbegin \DIFdel{we've been discussing }\DIFdelend \DIFaddbegin \DIFadd{discussed in Chapter 2 }\DIFaddend have non-random elements composing $\beta_n$, there is no distribution of $\beta_n$ to be estimated from a single agent\DIFaddbegin \DIFadd{'s choices}\DIFaddend .
The real power of this method is realized\DIFaddbegin \DIFadd{, however, }\DIFaddend when sample data is pooled together and the distribution of $\beta_n$ vectors is estimated from this pooled data.
This is an easy extension of equation (\DIFdelbegin \DIFdel{\ref{eq:SLnT}):
}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:SLnT}), which is logged for numerical stability:
}\DIFaddend \begin{equation}
	\DIFdelbegin %DIFDELCMD < \label{eq:SLLNT}
%DIFDELCMD < 	%%%
\DIFdelend \DIFaddbegin \label{eq3:SLLNT}
	\DIFaddend \mathit{SLL}_{NT}(\theta) = \sum_{n=1}^N \left( \sum_t^T \left[ \ln\!\left( \sum_h^H \frac{ P_{nt}(\beta^h) }{H} \right) \right] \right)
\end{equation}

\DIFaddbegin \noindent \DIFaddend We call equation (\DIFdelbegin \DIFdel{\ref{eq:SLLNT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:SLLNT}}\DIFaddend ) the unconditional simulated log-likelihood function, or just the simulated log-likelihood function (SLL).
Maximum simulated likelihood (MSL) methods can be applied to this equation to return the MSL estimator $\hat{\theta}$ which maximizes this function.
The characteristics of simulated estimators are reviewed in depth by \textcite[Chapter~10]{Train2002}, \DIFdelbegin \DIFdel{but importantly, the }\DIFdelend \DIFaddbegin \DIFadd{and the critical insight is that the }\DIFaddend estimator $\hat{\theta}$ derived from equation (\DIFdelbegin \DIFdel{\ref{eq:SLLNT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:SLLNT}}\DIFaddend ) approaches the estimator from equation (\DIFdelbegin \DIFdel{\ref{eq:LLnT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:LLnT}}\DIFaddend ) with a sufficiently large, $H$, number of draws from the distribution governed by $\theta$.

Estimating the distribution of preferences for a sample with MSL improves the analyst's position on multiple accounts.
\DIFdelbegin \DIFdel{For one}\DIFdelend \DIFaddbegin \DIFadd{First}\DIFaddend , the limitation of estimating only the mean preference parameter for pooled data with standard MLE is no longer binding.
Flexible distributions such as the Logit-Normal{\footnotemark} can be employed to estimate higher moments of the distribution such as the variance, skewness and kurtosis.
\DIFdelbegin \DIFdel{Secondly}\DIFdelend \DIFaddbegin \DIFadd{Second}\DIFaddend , the necessity of asking every subject dozens of questions to estimate preference parameters subject-by-subject is eased by being able to pool data across subjects.

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	\textcite[82]{Andersen2012} utilize the Logit-Normal distribution because of its high degree of flexibility and because \enquote{MSL algorithms developed for univariate or multivariate Normal distributions can be applied directly.} 
	The figures they present \parencite*[83]{Andersen2012} display some of the flexible forms this distribution can take.
}

\DIFdelbegin \DIFdel{As an example of statistical power concerns, consider an RDU stochastic specification where $\beta_n =\{r , \lambda , a , b\}$ , where $r$ is the CRRA parameter, $\lambda$ is the precision parameter, and $a$ and $b$ are the probability weighting parameters.
When estimating $\beta_n$ for each subject, a }%DIFDELCMD < \enquote{large} %%%
\DIFdel{number of questions needs to be asked in order to reach sufficient statistical significance given the 4 parameters that need to be jointly estimated.
If we were concerned with making inferences about the population that the sample was drawn from, this estimation must be repeated on many subjects to get good coverage of that distribution.
This could entail the estimation of hundreds of parameters, each with their own standard errors.
In contrast, if MSL is utilized and each element of $\beta_n$ is assumed to be independently distributed as Logit-Normal, $\hat{\theta}$ then consists of only 8 parameters that need to be estimated.
The assumption of independence of the marginal distributions can be relaxed and a covariance matrix of these distribution-shaping parameters could be estimated at the same time.
This would still only increase the number of parameters to be estimated to 12.
}\DIFdelend \DIFaddbegin \section{\DIFadd{The }\texorpdfstring{\textcite{Holt2002}}{Holt and Laury (2002)} \DIFadd{MPL and the Unconditional Assessment of Expected Welfare}}
\DIFaddend 

\DIFdelbegin \subsection{\DIFdel{The }%DIFDELCMD < \texorpdfstring{\textcite{Holt2002}}{Holt and Laury (2002)} %%%
\DIFdel{MPL and the Unconditional Assessment of Expected Welfare}}
%DIFAUXCMD
\addtocounter{subsection}{-1}%DIFAUXCMD
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{The issues }\DIFdelend \DIFaddbegin \DIFadd{Issues }\DIFaddend concerning statistical power and identification will be discussed in more depth \DIFdelbegin \DIFdel{later}\DIFdelend \DIFaddbegin \DIFadd{in Chapter 4}\DIFaddend , but first we revisit the primary question of this chapter given the above discussion on the technologies available to econometricians to make inferences about \DIFdelbegin \DIFdel{preferences of }\DIFdelend \DIFaddbegin \DIFadd{the preferences of individual }\DIFaddend agents.
Recall that it was assumed that the experimenter in the SMP thought experiment had complete knowledge of the stochastic specification utilized by each of the imagined subjects.
This knowledge could have derived from asking each subject a \DIFdelbegin \DIFdel{sufficiently large }\DIFdelend number of questions under \DIFdelbegin \DIFdel{perfect experimental conditions }\DIFdelend \DIFaddbegin \DIFadd{experimental conditions that satisfy the precepts for a valid economic experiment laid out by \textcite{Smith1982}{\footnotemark}}\DIFaddend , and then utilizing MLE and equation (\DIFdelbegin \DIFdel{\ref{eq:PnT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:PnT}}\DIFaddend ) to retrieve highly accurate estimates of each subject's preferences.
Assume that another experimenter asked a sufficiently \enquote{large} sample of subjects a battery of questions and was able to estimate the $\theta$ vector for this sample.
\DIFdelbegin \DIFdel{Can }\DIFdelend \DIFaddbegin \DIFadd{In this section we will demonstrate that }\DIFaddend knowledge of the distribution of preferences \DIFdelbegin \DIFdel{provide knowledge about welfare that was previously obfuscated by individual estimation? 
Potentially, yes}\DIFdelend \DIFaddbegin \DIFadd{in a population can provide estimates of individual agents' welfare that differ meaningfully from estimates of individual agents' welfare that would arise from individual level estimation of preferences}\DIFaddend .

\DIFaddbegin \addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	\DIFadd{\textcite{Smith1982} proposes several precepts as potentially necessary for drawing valid inferences from experimental data. 
	These are }\enquote{Nonsatiation}\DIFadd{, }\enquote{Saliency}\parencite[72]{Smith1982}\DIFadd{, }\enquote{Dominance}\DIFadd{, and }\enquote{Privacy}\parencite[934]{Smith1982}\DIFadd{.
	}\enquote{Nonsatiation} \DIFadd{requires that an agent would prefer to have more of an outcome that she values to less.
	}\enquote{Saliency} \DIFadd{requires that the rules and mechanisms that map an agent's actions to outcomes be understood and actionable by the agent.
	}\enquote{Dominance} \DIFadd{requires that the value of the outcome resulting from one action is sufficiently different to the value of an outcome resulting from another action to the extent that this difference }\textit{\DIFadd{dominates}} \DIFadd{the cost of performing such an action.
	}\enquote{Privacy} \DIFadd{requires that an agent only be given information on the alternative actions and outcomes available to her.
}}

\DIFaddend To make this discussion more concrete, we can utilize one of the HL-MPL instruments alluded to earlier and now displayed in Table (\ref{tb:HL-MPL}).
In the HL experiment, subjects were presented with \DIFdelbegin \DIFdel{the tableabove}\DIFdelend \DIFaddbegin \DIFadd{this table}\DIFaddend , without the \enquote{Expected Payoff Difference} and \enquote{CRRA for Indifference} columns, and asked to select one option from each row.
The \enquote{Option A} column indicates the outcomes and associated probabilities for option A in each of 10 tasks\DIFaddbegin \DIFadd{, }\DIFaddend and similarly for the \enquote{Option B} column.
The \enquote{CRRA for Indifference} column indicates the CRRA value that would make an \DIFaddbegin \DIFadd{EUT }\DIFaddend agent indifferent between option A and option B.
Thus, an agent with a CRRA value of $0.5$ would select option A for rows 1-6, and then \enquote{switch} to selecting option B for the remaining rows.

\begin{table}[ht]
	\centering
	\captionsetup{justification=centering}
	\caption{The Ten Paired Lottery-Choice Decisions with Low Payoffs \newline \textcite[1645]{Holt2002} }
	\label{tb:HL-MPL}
	\begin{adjustbox}{width=1\textwidth}
	\pgfplotstabletypeset[
		col sep=colon,
		every head row/.style={
			after row=\hline
		},
		display columns/0/.style={
			string type,
			column name = {\cnline{Row \#}}
		},
		display columns/1/.style={
			string type,
			column name = {Option A}
		},
		display columns/2/.style={
			string type,
			column name = {Option B}
		},
		display columns/3/.style={
			string type,
			column name = {\cnline{Expected Value\\Difference}}
		},
		display columns/4/.style={
			string type,
			column name = {\cnline{CRRA for\\Indifference}}
		},
	]{tables/HL-MPL.csv} % path/to/file
	\end{adjustbox}
\end{table}

The \DIFdelbegin \DIFdel{HL study is one of the most cited experiments in experimental economics, with 3238 citations as of October 7, 2015, according to Google Scholar.
Its popularity }\DIFdelend \DIFaddbegin \DIFadd{popularity of this approach }\DIFaddend is in part due to it's straightforward logic:
if a subject conforms to a deterministic EUT specification, then she should start off selecting option A, then at some point switch once, and only once, to selecting option B for the remaining rows \DIFaddbegin \DIFadd{or she should select B for every row}\DIFaddend .
The point at which the subject switches reveals an interval in which her preference for risk must lie.

However, this pattern need not necessarily occur given stochastic specifications.
Subjects may, and \DIFdelbegin \DIFdel{often }\DIFdelend \DIFaddbegin \DIFadd{sometimes }\DIFaddend do, switch multiple times between option A and option B as they work their way down the rows.
Some subjects \DIFaddbegin \DIFadd{even }\DIFaddend select option A in row 10 even though it is dominated by option B.
The first of these observed choice behaviors is often referred to as multiple switching behavior (MSB), while the second is a form of FOSD where there is no risk involved.
\DIFdelbegin \DIFdel{MSB is frequently observed in economic experiments: For instance, }\DIFdelend \textcite[1647]{Holt2002} observe that 28 of their 212 subjects exhibited MSB.
Rather than discussing all of the potential reasons why a subject would exhibit MSB, we will assume a normatively coherent stochastic model and discuss the implications of MSB within it.

The HL-MPL is a useful instrument to discuss the welfare implications of stochastic models not only because it is popular, but because the \DIFdelbegin \DIFdel{frequently }\DIFdelend observed MSB is an apparent violation to EUT that easy to notice visually without estimation.
There is no deterministic EUT utility function which allows either the switching back and forth from option A to option B or the selection of a guaranteed, lower outcome over a guaranteed, higher outcome.
Thus, any observance of MSB by an agent suggests that, at least under an EUT framework, maximal welfare has not been obtained.

An important and often overlooked reality of stochastic models is that even if a subject doesn't display MSB, the subject may still not be realizing their optimal welfare.
This may not seem obvious at first, as any non-MSB choice pattern can be rationalized by some preference relation.
\DIFdelbegin \DIFdel{But as }\DIFdelend \DIFaddbegin \DIFadd{Cases such as these arrise when a subject makes a choice error with respect to the utility function they operate, but this choice error results in a choice pattern that is still rationalizable, or }\enquote{consistent}\DIFadd{.
As }\DIFaddend soon as we incorporate knowledge of a sample's distribution of preferences governed by $\theta$, it becomes clear that many observed, apparently \enquote{consistent} choice patterns contain more choice errors and are often more costly in terms of foregone welfare than apparently \enquote{inconsistent} choice patterns.
This will be made clear in the immediate discussion, but first we must define some notation.

Utilizing notation from the \DIFdelbegin \DIFdel{previous chapter}\DIFdelend \DIFaddbegin \DIFadd{beginning of Section \ref{ssec:Notation}}\DIFaddend , an option in a set of alternatives $t$ is represented as $X_{jt}$, where $j$ indicates the option's ordinal rank among the set of alternatives given the agent's \DIFaddbegin \DIFadd{utility parameter vector, }\DIFaddend $\beta_n$\DIFdelbegin \DIFdel{.
Therefore, we }\DIFdelend \DIFaddbegin \DIFadd{, and $y_t = j$ indicates that option $j$ was chosen by the agent in task $t$.
We }\DIFaddend can define a \enquote{choice error} as any choice where \DIFaddbegin \DIFadd{the option chosen didn't provide the greatest utility.
Therefore a choice error in task $t$ is when }\DIFaddend $y_t \neq 1$\DIFdelbegin \DIFdel{:
}\DIFdelend \DIFaddbegin \DIFadd{, and an indicator function for choice errors given some vector of assumed utility parameters $\beta_n$ is given by:
}\DIFaddend \begin{equation}
	\DIFdelbegin \DIFdel{I_{nt}}\DIFdelend \DIFaddbegin \label{eq3:Itb}
	\DIFadd{K_{t}}\DIFaddend (\beta_n) = 
	\begin{cases}
		 1 & y_t \neq 1\\
		 0 & y_t = 1
	\end{cases}
\end{equation}

\noindent The frequency of choice errors by agent $n$ in the choice pattern $y_t \times T$ is:
\begin{equation}
	\DIFdelbegin %DIFDELCMD < \label{eq:MBn}
%DIFDELCMD < 	%%%
\DIFdelend \DIFaddbegin \label{eq3:MTBn}
	\DIFaddend M\DIFaddbegin \DIFadd{_T}\DIFaddend (\beta_n) = \sum_t^T \DIFdelbegin \DIFdel{I}\DIFdelend \DIFaddbegin \DIFadd{K}\DIFaddend (\beta_n)
\end{equation}

Given the distribution parameter vector $\theta$, we can define the expected frequency of choice errors in the choice pattern $y_t \times T$ as:
\begin{equation}
	\DIFdelbegin %DIFDELCMD < \label{eq:EMt}
%DIFDELCMD < 	%%%
\DIFdelend \DIFaddbegin \label{eq3:EMt}
	\DIFaddend \E(M | \theta) = \int M(\beta_n) f(\beta | \theta) d\beta
\end{equation}

\noindent where, just as in equation (\DIFdelbegin \DIFdel{\ref{eq:Pnt}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:Pnt}}\DIFaddend ), $f(\beta|\theta)$ is the density function of the $\beta$ vector given the vector of hyper-parameters $\theta$ shaping the distribution of the $\beta$.
Equation (\DIFdelbegin \DIFdel{\ref{eq:EMt}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EMt}}\DIFaddend ) is just the mean of the discrete distribution of choice errors in in the choice pattern $y_t \times T$ , given the distribution parameter vector $\theta$.
Because the distribution of choice errors is discrete, $M(\beta_n) \in [0,T] \subset \mathbb{N}^0$, \DIFdelbegin %DIFDELCMD < {\footnotemark} %%%
\DIFdelend we can define the probability mass function of choice errors as follows\DIFdelbegin \DIFdel{:
}\DIFdelend \DIFaddbegin {\footnotemark}\DIFadd{:
}\DIFaddend \begin{equation}
	\DIFdelbegin %DIFDELCMD < \label{eq:PE}
%DIFDELCMD < 	%%%
\DIFdelend \DIFaddbegin \label{eq3:PE}
	\DIFaddend P_E(e | \theta) = \int N[M(\beta),e] f(\beta|\theta) d \beta
\end{equation}

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	$\mathbb{N}^0$ indicates the set of natural numbers, inclusive of $0$. $\mathbb{N}^1$ or $\mathbb{N}^{+}$ would indicate the set of natural numbers not inclusive of 0.
}

\noindent where:
\begin{equation}
	\DIFdelbegin %DIFDELCMD < \label{eq:NMB}
%DIFDELCMD < 	%%%
\DIFdelend \DIFaddbegin \label{eq3:NMB}
	\DIFaddend N[M(\beta), e] = 
	\begin{cases}
		1 & M(\beta) = e\\
		0 & M(\beta) \neq e
	\end{cases}
\end{equation}

\noindent and $e$ indicates the number of choice errors for the given choice pattern and $\theta$ vector.
Equation (\DIFdelbegin \DIFdel{\ref{eq:PE}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:PE}}\DIFaddend ) provides useful information about whether an observed pattern deviates from a deterministic choice model, but is limited in the case that it assigns equal weight to errors which are very costly in terms of welfare and errors that are not so costly.

We can incorporate \DIFaddbegin \DIFadd{two of }\DIFaddend the metrics developed \DIFdelbegin \DIFdel{previously }\DIFdelend \DIFaddbegin \DIFadd{in Chapter 2 }\DIFaddend for welfare assessment into this sample framework\DIFdelbegin \DIFdel{to gather more useful information and determine the expected welfare surplus and the expected ratio of obtained }\DIFdelend \DIFaddbegin \DIFadd{.
The first metric, calculated for a choice pattern $y_t \times T$, is equivalent to a standard consumer surplus calculation:
}\begin{equation}
	\DIFadd{\label{eq3:WST}
	\Delta W_{nT} = \sum_{t=1}^T \left( }{\DIFadd{\CE}}\DIFadd{_{nyt} - }{\DIFadd{\CE}}\DIFadd{_{n1t}^Z \right)
}\end{equation}

\noindent \DIFadd{where ${\CE}_{nyt}$ is the }\DIFaddend {\CE} \DIFdelbegin \DIFdel{to maximum }\DIFdelend \DIFaddbegin \DIFadd{of the option chosen, indicated by the subscript $y$, by agent $n$ in task $t$, and ${\CE}_{n1t}^Z$ is the }\DIFaddend {\CE} \DIFdelbegin \DIFdel{for the }\DIFdelend \DIFaddbegin \DIFadd{of the option that provides the greatest utility among the set of unchosen options, $Z$, in task $t$.
Throughout this chapter, we will refer to the metric in equation (\ref{eq3:WST}) as the }\enquote{welfare surplus} \DIFadd{metric.
The second metric we propose to characterize the welfare implications of choices is similar to the concept of auction }\enquote{efficiency} \DIFadd{utilized by \textcite{Plott1978}:
}

\begin{equation}
	\DIFadd{\label{eq3:WET}
	\%W_{nT} = \frac{\displaystyle\sum_{t=1}^{T} {\CE}_{nyt} }{\displaystyle\sum_{t=1}^{T} {\CE}_{n1t}}
}\end{equation}

\noindent \DIFadd{In the metric defined in equation (\ref{eq3:WET}), the }{\CE}\DIFadd{'s of the options chosen by the agent across all tasks $T$ are summed, and then divided by the }{\CE}\DIFadd{'s of the options that would have provided the greatest utility across all the tasks.
Therefore, should an agent never make a choice error, this metric would take on the value of $1$, and should the agent make at least one choice error, it would take on a value between $0$ and $1$.}{\footnotemark}
\DIFadd{Throughout this chapter, we will refer to the metric in equation (\ref{eq3:WET}) as the }\enquote{welfare efficiency} \DIFadd{metric.
}

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	\DIFadd{There are a few mathematical peculiarities with this metric.
	This metric can lose its $(0,1)$ bounds if any of the $T$ tasks has a mixed frame, that is, a task has both positive and negative outcomes.
	This would occur if the }{\CE} \DIFadd{of a chosen option has a different sign than the }{\CE} \DIFadd{of the highest ranked option.
	Also, this metric becomes undefined if the }{\CE} \DIFadd{of the highest ranked alternative is $0$.
	These general issues will not be of concern in this chapter as all examples of lotteries have outcomes in the strictly positive domain.
}}

\DIFadd{The welfare surplus and welfare efficiency metrics from equations (\ref{eq3:WST}) and (\ref{eq3:WET}) can be used in place of equation (\ref{eq3:MTBn}) in equation (\ref{eq3:EMt}) to gather useful information for a }\DIFaddend given choice pattern and $\theta$ vector:
\begin{align}
	E( \Delta W_T | \theta) &= \int \Delta W_T(\beta) f(\beta | \theta) d \beta \DIFdelbegin %DIFDELCMD < \label{eq:EDWT}%%%
\DIFdelend \DIFaddbegin \label{eq3:EWST}\DIFaddend \\
	E( \% W_T | \theta) &= \int \% W_T(\beta) f(\beta | \theta) d \beta \DIFdelbegin %DIFDELCMD < \label{eq:EPWT}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \label{eq3:EWET}
\DIFaddend \end{align}

Given equation (\DIFdelbegin \DIFdel{\ref{eq:NMB}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:NMB}}\DIFaddend ), we can denote the expected welfare surplus and the expected \DIFdelbegin \DIFdel{proportion of welfare }\DIFdelend \DIFaddbegin \DIFadd{welfare efficiency }\DIFaddend obtained by agents who have committed $e \in [0,T]$ errors by making choices $y_t \times T$ as follows:
\begin{align}
	E( \Delta W_T | \theta, e) &= \int \bigr( \Delta W_T(\beta) \times N[M(\beta),e] \bigr) f(\beta | \theta) d \beta \DIFdelbegin %DIFDELCMD < \label{eq:EDWTe}%%%
\DIFdelend \DIFaddbegin \label{eq3:EDWTe}\DIFaddend \\
	E( \% W_T | \theta, e) &= \int \bigl( \% W_T(\beta) \times N[M(\beta),e] \bigr) f(\beta | \theta) d \beta \DIFdelbegin %DIFDELCMD < \label{eq:EPWTe}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \label{eq3:EPWTe}
\DIFaddend \end{align}

The same limitation mentioned about MSL concerning a computer's inability to perform closed-form integration \DIFaddbegin \DIFadd{in general }\DIFaddend applies to equations (\DIFdelbegin \DIFdel{\ref{eq:EMt}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EMt}}\DIFaddend ), (\DIFdelbegin \DIFdel{\ref{eq:PE}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:PE}}\DIFaddend ), and (\DIFdelbegin \DIFdel{\ref{eq:EDWT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EWST}}\DIFaddend ) through (\DIFdelbegin \DIFdel{\ref{eq:EPWTe}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EWET}}\DIFaddend ).
However, these equations can be approximated in the manner described for MSL in equation (\DIFdelbegin \DIFdel{\ref{eq:SPnt}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:SPnt}}\DIFaddend ): the terms in these equations between the integrand and the density function will be evaluated with $\beta$ vectors randomly drawn $H$ times from the distribution governed by $\theta$, and then averaged.
As $H$ gets sufficiently large, the simulated statistics approach the true statistics.

\DIFdelbegin \DIFdel{We can construct similar notation for welfare metrics utilizing equations (17) and (18), as well as calculating variances for every expectation metric proposed above, but these steps will just complicate the meat of the welfare analysis unnecessarily.
For now, we can simply begin to analyze the HL-MPL given these metrics}\DIFdelend \DIFaddbegin \subsection{\DIFadd{Sample Level Analysis with an EUT Population}}

\DIFadd{The simulation methods described here and for the remainder of this chapter characterize an individual agent as having a single $\beta_n$ vector representing her preferences, and making choices in an economic environment that satisfies the \textcite{Smith1982} precepts for valid economic experiments.
An individual agent $n$ generates a }\textit{\DIFadd{observed}} \DIFadd{choice pattern $y_t \times T$ by resolving the stochastic process defined by her preferences.
In Chapter 2, we described normatively coherent stochastic models as those models that characterize agents as having non-random preferences, thus an agent's preferences do not change from choice to choice.}{\footnotemark}
\DIFadd{Individual $\beta_n$ parameter vectors are themselves drawn from a population of $\beta$ vectors.
This distribution of $\beta$ vectors in the population is characterized by the parameter vector $\theta$.
Throughout the following discussion, we will refer to a choice pattern's likelihood of being }\textit{\DIFadd{observed}}\DIFadd{, by which we mean the choice pattern's simulated likelihood as calculated in equation (\ref{eq3:SLnT}).
This is the probability of a randomly drawn agent from the population defined by $\theta$ producing the choice pattern, thus the pattern's likelihood of being observed.
Likewise, when we discuss the expected welfare implications of a choice pattern for a given population, we are discussing the expected welfare implications for an agent from that population who generated that choice pattern}\DIFaddend .

\DIFdelbegin \subsubsection{\DIFdel{Sample Level Analysis with an EUT Population}}
%DIFAUXCMD
\addtocounter{subsubsection}{-1}%DIFAUXCMD
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{To make this numerical exampleexplicit }\DIFdelend \DIFaddbegin \DIFadd{To make an explicit numerical example, }\DIFaddend we will first define \DIFdelbegin \DIFdel{a sample population .
For simplicity sake }\DIFdelend \DIFaddbegin \DIFadd{the models characterizing an individual agent's choice probabilities, and then the marginal distributions of the elements of $\beta$ which together define the population characterized by $\theta$.
For the sake of simplicity}\DIFaddend , we will first consider a \DIFdelbegin \DIFdel{sample }\DIFdelend \DIFaddbegin \DIFadd{population }\DIFaddend entirely composed of agents \DIFdelbegin \DIFdel{with }\DIFdelend \DIFaddbegin \DIFadd{conforming to }\DIFaddend an EUT utility \DIFdelbegin \DIFdel{structure and a CU stochastic model.
The functional form for EUT will be the CRRA function.
}\DIFdelend \DIFaddbegin \DIFadd{model with a Contextual Utility (CU) stochastic model }\parencite{Wilcox2008}\DIFadd{.
Thus, choice probabilities for an individual agent are defined as follows:
}

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	\DIFadd{Not only are we assuming that agents do not have random preferences, we're also assuming that an agent's preferences are static across choices generally.
	We could, as \textcite{Hey2001} does, model some or all of the parameters in an agent's utility function as being partly determined by the number of choices that the agent has encountered.
	Because preferences modeled in this way change from choice to choice in a non-random manner, the welfare analysis discussed in this chapter could be extended in a normatively coherent manner to incorporate this }\enquote{learning}\DIFadd{, potentially with interesting implications.
	This would involve specifying additional marginal distributions which characterize the parameters defining the }\enquote{learning} \DIFadd{process.
}}

\begin{align}
	\DIFadd{\label{eq3:RE}
	\begin{split}
	P_{njt}(\beta_n) &= {\Prob}\left(  \epsilon_t \geq \frac{1}{D(\beta_n,X_t) \lambda_n} \left[ G(\beta_n,X_{kt}) - G(\beta_n,X_{jt}) \right] \right)\\
	&= 1 - F\left( \dfrac{G(\beta_n,X_{kt}) - G(\beta_n,X_{jt})}{D(\beta_n,X_t)\lambda_n }  \right)\\
	&= {\Prob}(y_t = j)
	\end{split}
}\end{align}

\noindent \DIFadd{where $\epsilon_t$ defines the random error associated with the measurement of utility, the functional form the utility function, $G(\cdot)$, is the CRRA function of the form $u(x) = \frac{x^{1-r}}{(1-r)}$, $F(\cdot)$ is the logistic cumulative distribution function (cdf), and the adjusting function $D(\cdot)$ is as follows:
}

\begin{align}
	\DIFadd{\label{eq3:CU}
	\begin{split}
		&D(\beta_n,X_t) = \mathit{max}[u(x_{it})] - \mathit{min}[u(x_{it})]\\
		&\mathit{st.}\; w_i(x_{it}) \neq 0
	\end{split}
}\end{align}

\noindent \DIFaddend Thus the $\beta_n$ vector for each agent is said to consist of only two parameters, $r$ and $\lambda$.
\DIFaddbegin \DIFadd{The joint distribution of these two parameters characterizes the population of agents and is defined by the parameter vector $\theta$.
}\DIFaddend We will consider \DIFdelbegin \DIFdel{these }\DIFdelend \DIFaddbegin \DIFadd{the marginal distributions of the $r$ and $\lambda$ }\DIFaddend parameters to be \DIFaddbegin \DIFadd{independent and }\DIFaddend uncorrelated in the \DIFdelbegin \DIFdel{sample.}\DIFdelend \DIFaddbegin \DIFadd{population.}{\footnotemark}
\DIFaddend The $r$ parameter can conceivably take any value, but to make the bulk of the density lie in the \DIFdelbegin \DIFdel{relevant }\DIFdelend \DIFaddbegin \DIFadd{familiar }\DIFaddend range of the HL-MPL, we will consider it as distributed \DIFdelbegin \DIFdel{normally}\DIFdelend \DIFaddbegin \DIFadd{normal}\DIFaddend , with mean of $0.65$ and a standard deviation of $0.3$, thus $r \sim \mathcal{N}(0.65 , 0.3^2 )$.
The $\lambda$ parameter must be strictly positive, so it will be assumed to be distributed as gamma with a mean of $0.35$ and a standard deviation of $0.3$.
This is equivalent to a gamma distribution with a shape parameter of $k \approx 1.36$ and a scale parameter of $t\approx0.26$, thus $\lambda \sim \Gamma(1.36 , 0.26)$.
Together these 4 parameters make the joint distribution-shaping parameter $\theta=\{0.65 ,0.3^2, 1.36 , 0.26\}$.
\DIFaddbegin \DIFadd{Because the marginal distributions are uncorrelated, we don't need to define elements of a covariance matrix.
}\DIFaddend 

The metrics described in equations (\DIFdelbegin \DIFdel{\ref{eq:SLnT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:SLnT}}\DIFaddend ) and (\DIFdelbegin \DIFdel{\ref{eq:MBn}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:MTBn}}\DIFaddend ) through (\DIFdelbegin \DIFdel{\ref{eq:EPWTe}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EPWTe}}\DIFaddend ) rely on a given choice pattern, $y_t \times T$.
In the HL-MPL there are a total of $2^{10}=1024$ choice patterns that can be described.
To begin the discussion of the welfare implications of stochastic choice models, we calculate the values for equations (\DIFdelbegin \DIFdel{\ref{eq:SLnT})and (\ref{eq:MBn}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:SLnT}), and (\ref{eq3:MTBn}}\DIFaddend ) through (\DIFdelbegin \DIFdel{\ref{eq:EPWTe}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EPWTe}}\DIFaddend ) for all $\mathit{TT} =1024$ choice patterns and all $e \in[0,T]$ for the given $\theta$, with $H=2.5 \times 10^6$.{\footnotemark} 
\DIFdelbegin \DIFdel{While this large a value for $H$ is not necessary to gather sufficiently unbiased estimates for }\DIFdelend \DIFaddbegin 

\addtocounter{footnote}{-3}
\stepcounter{footnote}\footnotetext{
	\DIFadd{This is done for convenience; adding correlation among the marginal distributions would require the definition of a covariance matrix.
	In samples of real populations, we might expect there to be correlation among these marginal distributions, and this analysis can be easily extended to accommodate it.
	This additional step is not difficult, but introduces more parameters to keep track of and doesn't significantly add to the narrative.
}}
\stepcounter{footnote}\footnotetext{
	\DIFadd{The calculations were performed using the R statistical software. 
	The large number of calculations was facilitated by authoring a new package, }\enquote{ctools}\DIFadd{, which primarily acts as a wrapper for the }\enquote{parallel} \DIFadd{and }\enquote{Rhpc} \DIFadd{packages.
	The use of parallel computing is common in various statistical software, but R does parallel computation in a particularly useful way.
	All code used is available on request.
}}
\stepcounter{footnote}\footnotetext{
	\DIFadd{As noted earlier, instead of a built-in random number generator, we transform Halton sequences into the required distributions. 
	The normal distribution was created by inverting a Halton sequence constructed with a prime base of $3$, and the gamma distribution was created by inverting a Halton sequence constructed with a prime base of $7$.
	The first 30 elements of each sequence were dropped and the next 2.5 million elements were used. 
}}

\DIFadd{To make clear how the result of these equations are arrived at, we can work through the calculations step by step.
First, we select a choice pattern from one of the $1024$ choice patterns possible with the HL-MPL, for example, the choice of option A for the first five rows and option B for rows $6$ through $10$.
Next, a $\beta_n$ vector is drawn from the joint distribution defined by }\DIFaddend $\theta$\DIFdelbegin \DIFdel{utilizing MSL, it does allow us to make very accurate estimates at the tails of the distribution.
}\DIFdelend \DIFaddbegin \DIFadd{.
As an example, we will assume $\beta_n = \lbrace r = 0.65, \lambda = .35\rbrace$ was drawn; recall that we are also assuming EUT with a CU stochastic model.
Utilizing this $\beta_n$ and choice pattern, we can evaluate the various metrics proposed.
First, we evaluate equation (\ref{eq3:PnT}), the likelihood that agent $n$ would produce this choice pattern, utilizing equation (\ref{eq3:RE}) to calculate choice probabilities for the individual tasks:
}\begin{align}
	\DIFadd{\label{eq3:example_PnT}
	\begin{split}
		P_{n,j,1}  = Pr(y_1 = A    \,|\, \beta_n)    &= 0.82 \\
		P_{n,j,2}  = Pr(y_2 = A    \,|\, \beta_n)    &= 0.78 \\
		P_{n,j,3}  = Pr(y_3 = A    \,|\, \beta_n)    &= 0.74 \\
		P_{n,j,4}  = Pr(y_4 = A    \,|\, \beta_n)    &= 0.68 \\
		P_{n,j,5}  = Pr(y_5 = A    \,|\, \beta_n)    &= 0.62 \\
		P_{n,j,6}  = Pr(y_6 = B    \,|\, \beta_n)    &= 0.44 \\
		P_{n,j,7}  = Pr(y_7 = B    \,|\, \beta_n)    &= 0.51 \\
		P_{n,j,8}  = Pr(y_8 = B    \,|\, \beta_n)    &= 0.57 \\
		P_{n,j,9}  = Pr(y_9 = B    \,|\, \beta_n)    &= 0.63 \\
		P_{n,j,10} = Pr(y_{10} = B \,|\, \beta_n)    &= 0.95 \\
		P_{nT}     = \prod_{t = 1}^{T = 10} P_{njt}(\beta_n)  &= 0.0154
	\end{split}
}\end{align}

\noindent \DIFadd{Note that $P_{n,j,6} < 0.50$.
With the CU stochastic model, the option with the highest utility, expected or otherwise, will always have the highest probability of being chosen.
Since there are only two alternatives in task $6$, it must be the case that option $B$ in this task had a lower expected utility than option $A$, and therefore the choice of $B$ in task $6$ is a choice error.
Using the notation defined in Section \ref{ssec:Notation}, $y_6 = 2$, and for all $t \in \lbrace T \,\backslash\, 6 \rbrace$, $y_t = 1$.
This information allows us to evaluate equation (\ref{eq3:MTBn}), the frequency of choice errors in a given choice pattern, utilizing equation (\ref{eq3:Itb}):
}

\begin{align}
	\DIFadd{\label{eq3:example_MTBn}
	\begin{split}
		P_{n,j,1}  = Pr(y_1 = A    \,|\, \beta_n) = 0.82 ~ \Rightarrow ~ K_{1}(\beta_n)  &= 0 \\
		P_{n,j,2}  = Pr(y_2 = A    \,|\, \beta_n) = 0.78 ~ \Rightarrow ~ K_{2}(\beta_n)  &= 0 \\
		P_{n,j,3}  = Pr(y_3 = A    \,|\, \beta_n) = 0.74 ~ \Rightarrow ~ K_{3}(\beta_n)  &= 0 \\
		P_{n,j,4}  = Pr(y_4 = A    \,|\, \beta_n) = 0.68 ~ \Rightarrow ~ K_{4}(\beta_n)  &= 0 \\
		P_{n,j,5}  = Pr(y_5 = A    \,|\, \beta_n) = 0.62 ~ \Rightarrow ~ K_{5}(\beta_n)  &= 0 \\
		P_{n,j,6}  = Pr(y_6 = B    \,|\, \beta_n) = 0.44 ~ \Rightarrow ~ K_{6}(\beta_n)  &= 1 \\
		P_{n,j,7}  = Pr(y_7 = B    \,|\, \beta_n) = 0.51 ~ \Rightarrow ~ K_{7}(\beta_n)  &= 0 \\
		P_{n,j,8}  = Pr(y_8 = B    \,|\, \beta_n) = 0.57 ~ \Rightarrow ~ K_{8}(\beta_n)  &= 0 \\
		P_{n,j,9}  = Pr(y_9 = B    \,|\, \beta_n) = 0.63 ~ \Rightarrow ~ K_{9}(\beta_n)  &= 0 \\
		P_{n,j,10} = Pr(y_{10} = B \,|\, \beta_n) = 0.95 ~ \Rightarrow ~ K_{10}(\beta_n) &= 0 \\
		                                M(\beta_n) = \sum_{t = 1}^{T = 10}{K_t(\beta_n)} &= 1
	\end{split}
}\end{align}

\noindent \DIFadd{Thus our subject $n$ has committed one choice error across the $T$ tasks.
This result allows us to calculate equation (\ref{eq3:NMB}) for values of $e \in [ 0, T ]$ which indicates if there have been $e$ number of errors in this choice pattern:
}

\begin{align}
	\DIFadd{\label{eq3:example_NMB}
	\begin{split}
		N( M_T(\beta_n) = 1, e = 0 )  &= 0 \\
		N( M_T(\beta_n) = 1, e = 1 )  &= 1 \\
		N( M_T(\beta_n) = 1, e = 2 )  &= 0 \\
		N( M_T(\beta_n) = 1, e = 3 )  &= 0 \\
		N( M_T(\beta_n) = 1, e = 4 )  &= 0 \\
		N( M_T(\beta_n) = 1, e = 5 )  &= 0 \\
		N( M_T(\beta_n) = 1, e = 6 )  &= 0 \\
		N( M_T(\beta_n) = 1, e = 7 )  &= 0 \\
		N( M_T(\beta_n) = 1, e = 8 )  &= 0 \\
		N( M_T(\beta_n) = 1, e = 9 )  &= 0 \\
		N( M_T(\beta_n) = 1, e = 10 ) &= 0 \\
	\end{split}
}\end{align}

\noindent \DIFadd{Next we can calculate the two welfare metrics from equations equations (\ref{eq3:WST}) and (\ref{eq3:WET}), indicating welfare surplus and welfare efficiency respectively.
First we calculate the }\DIFaddend {\DIFaddbegin \CE} \DIFadd{of option $A$ and option $B$ for all $T = 10$ tasks using equation (\ref{eq3:CEcalc}). 
We note the }{\CE} \DIFadd{of the chosen and unchosen options for the given choice pattern, the difference between the two, and the greatest }{\CE} \DIFadd{for each task:
}

\begin{table}[ht]
	\centering
	\setlength{\tabcolsep}{1pt}
	\caption{ \DIFaddFL{Example }{\CE}\DIFaddFL{'s of EUT Agent with HL-MPL}}
	\label{tb:example_CE}
	\begin{adjustbox}{width=1\textwidth}
	\pgfplotstabletypeset[
		col sep=comma,
		every head row/.style={
			after row=\hline
		},
		every last row/.style={
			after row=\hline
		},
		display columns/0/.style={
			column type={c},
			column name = {Task}
		},
		display columns/1/.style={
			precision = 2,
			zerofill,
			column name = { \cnline{ {\CE} of A} }
		},
		display columns/2/.style={
			precision = 2,
			zerofill,
			column name = { \cnline{ {\CE} of B } }
		},
		display columns/3/.style={
			precision = 2,
			zerofill,
			column name = { \cnline{ {\CE} of Chosen\\Option } }
		},
		display columns/4/.style={
			precision = 2,
			zerofill,
			column name = { \cnline{ {\CE} of Unchosen\\Option} }
		},
		display columns/5/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = { \cnline{ {\CE} of Chosen -\\{\CE} of Unchosen} }
		},
		display columns/6/.style={
			precision = 2,
			zerofill,
			column name = { \cnline{Greatest \\{\CE}}}
		}
	]{tables/Example_CE.csv} %DIF >  path/to/file
	\end{adjustbox}
\end{table}

\DIFadd{With the }{\CE}\DIFadd{'s calculated, we can substitute them in to equations (\ref{eq3:WST}) and (\ref{eq3:WET}).
For equation equation (\ref{eq3:WST}), we take the sum of column $6$ in Table \ref{tb:example_CE}:
}

\begin{equation}
	\DIFadd{\label{eq3:example_WST}
	\Delta W_{nT} = \sum_{t=1}^T \left( }{\DIFadd{\CE}}\DIFadd{_{nyt} - }{\DIFadd{\CE}}\DIFadd{_{n1t}^Z \right) = 8.92
}\end{equation}

\noindent \DIFadd{and for equation (\ref{eq3:WET}), we take the sum of column $4$ and divide it by the sum of column $7$:
}

\begin{equation}
	\DIFadd{\label{eq3:example_WET}
	\%W_{nT} = \frac{\displaystyle\sum_{t=1}^{T} {\CE}_{nyt} }{\displaystyle\sum_{t=1}^{T} {\CE}_{n1t}} = \frac{21.37}{21.74} = .983
}\end{equation}

\noindent \DIFadd{Finally, we multiply the welfare metrics derived in equations (\ref{eq3:example_WST}) and (\ref{eq3:example_WET}) by the indicator functions derived for $e \in [0,T]$ in equation (\ref{eq3:NMB}):
}

\begin{align}
	\DIFadd{\label{eq3:example_NMBWST}
	\begin{split}
		N( M_T(\beta_n) = 1, e = 1 )  \times \Delta W_{nT} &= 1 \times 8.92 = 8.92\\
		N( M_T(\beta_n) = 1, e \neq 1 )  \times \Delta W_{nT} &= 0 \times 8.92 = 0
	\end{split}
}\end{align}

\begin{align}
	\DIFadd{\label{eq3:example_NMBWET}
	\begin{split}
		N( M_T(\beta_n) = 1, e = 1 )  \times \%W_{nT} &= 1 \times .983 = .983\\
		N( M_T(\beta_n) = 1, e \neq 1 )  \times \%W_{nT} &= 0 \times .983 = 0
	\end{split}
}\end{align}

\noindent \DIFadd{The indicator functions in equation (\ref{eq3:example_NMB}) are mutually exclusive, therefore the product of the indicator functions and the welfare metrics will be $0$ for all but one value of $e$, and equal to the metrics for the remaining $e$, in this example, for $e = 1$. 
}

%DIF > Thus, the derivation of the results in equations (\ref{eq3:example_PnT}) through (\ref{eq3:example_WET}) constitutes the core of the computational exercise that results in population level expectations.
\DIFadd{Having derived the results of these equations for one given choice pattern, we iterate through the remaining $1023$ choice patterns for this particular agent, repeating the numerical exercise described above for each choice pattern.
With metrics defined for this particular agent across all $TT = 1024$ possible choice patterns, a new $\beta_n$ vector is drawn from $\theta$, and the entire process repeated.
For the calculations described below, we repeat the process of drawing a $\beta_n$ from $\theta$ and calculating the results of these metrics for all choice patterns $H = 2.5 \times 10^6$ times.}{\DIFaddend \footnotemark}
\DIFdelbegin \DIFdel{The }\DIFdelend \DIFaddbegin \DIFadd{This process results in a $3$ dimensional array with $(\mathit{\#\ of\ metrics} \times \mathit{\#\ of\ choice\ patterns} \times H) = 33 \times 1024 \times (2.5 \times 10^6) = 8.448 \times 10^{10}$ elements.
}

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	\DIFadd{Since each of these repetitions are effectively independent of each other, this kind of task is termed an }\enquote{embarrassingly parallel} \DIFadd{problem.
	The }\enquote{ctools} \DIFadd{package written for this project makes the calculation of these kinds of problems across multiple CPUs particularly easy.
}}

\DIFadd{To arrive at the population level metrics, we take the average of each metric defined in equations (\ref{eq3:example_PnT}) through (\ref{eq3:example_NMBWET}) across all $H$ simulated agents for each choice pattern.
Since each $\beta_n$ was drawn randomly from the distribution governed by $\theta$, only a simple average is needed.
This averaging leaves us with a dataset that has $33 \times 1024 = 33,792$ elements.
}

\DIFadd{This }\DIFaddend resulting dataset, however, is too large to be displayed in full, so for now we restrict attention to the 10 choice patterns \DIFdelbegin \DIFdel{which are the }\DIFdelend most likely to be observed, and discuss the metrics calculated in equations (\DIFdelbegin \DIFdel{\ref{eq:EMt}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EMt}}\DIFaddend ), (\DIFdelbegin \DIFdel{\ref{eq:EDWT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EWST}}\DIFaddend ), (\DIFdelbegin \DIFdel{\ref{eq:EPWT})and (\ref{eq:PE}) with $e \in (0,1)$}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EWET}), and (\ref{eq3:PE}) with $e = (0,1)$}\DIFaddend .
The results of these equations for the 10 most likely choice patterns are as follows:

\DIFdelbegin %DIFDELCMD < \addtocounter{footnote}{-2}
%DIFDELCMD < \stepcounter{footnote}%%%
\footnotetext{\DIFdel{The calculations were performed using the R statistical software. 
	The large number of calculations was greatly sped up by using the }%DIFDELCMD < \enquote{parallel} %%%
\DIFdel{package provided with R which allowed the use of multiple processors for many of the computations. 
	All code used is available on request.
}}
%DIFAUXCMD
%DIFDELCMD < \stepcounter{footnote}%%%
\footnotetext{\DIFdel{As noted earlier, instead of a built-in random number generator, one transforms Halton sequences into the required distributions. 
	The normal distribution was created by inverting a Halton sequence constructed with a prime base of $3$, and the gamma distribution was created by inverting a Halton sequence constructed with a prime base of $7$.
	The first 30 elements of each sequence were dropped and the next 2.5 million elements were used. 
	An added benefit of the Halton sequence is its reproducibility. 
	The results described can be replicated exactly.
}}
%DIFAUXCMD
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend \break

\begin{table}[ht]
	\DIFaddbeginFL \setlength{\tabcolsep}{2pt}
	\DIFaddendFL \centering
	\caption{HL-MPL Welfare and Error Expectations for Top Ten \DIFaddbeginFL \DIFaddFL{Most Likely }\DIFaddendFL Choice Patterns, EUT}
	\label{tb:TopTenEUT}
	\begin{adjustbox}{width=1\textwidth}
	\DIFdelbeginFL %DIFDELCMD < \pgfplotstabletypeset[
%DIFDELCMD < 		col sep=comma,
%DIFDELCMD < 		every head row/.style={
%DIFDELCMD < 			before row={
%DIFDELCMD < 				\multicolumn{10}{c}{Choice in Row} &
%DIFDELCMD < 				\cnline{Simulated\\Likelihood} &
%DIFDELCMD < 				\cnline{Expected\\Errors} &
%DIFDELCMD < 				\cnline{Welfare\\Proportion} &
%DIFDELCMD < 				\cnline{Welfare\\Surplus} &
%DIFDELCMD < 				$P_E(e=0)$ &
%DIFDELCMD < 				$P_E(e=1)$\\
%DIFDELCMD < 			},
%DIFDELCMD < 			after row=\hline
%DIFDELCMD < 		},
%DIFDELCMD < 		every last row/.style={
%DIFDELCMD < 			after row=\hline
%DIFDELCMD < 		},
%DIFDELCMD < 		display columns/0/.style={
%DIFDELCMD < 			column name = {1},
%DIFDELCMD < 			column type={p{.2cm}}
%DIFDELCMD < 		},
%DIFDELCMD < 		display columns/9/.style={
%DIFDELCMD < 			column name = {10},
%DIFDELCMD < 			column type={p{.3cm}|}
%DIFDELCMD < 		},
%DIFDELCMD < 		display columns/10/.style={
%DIFDELCMD < 			precision = 2,
%DIFDELCMD < 			sci precision = 3,
%DIFDELCMD < 			column name = {}
%DIFDELCMD < 		},
%DIFDELCMD < 		display columns/11/.style={
%DIFDELCMD < 			precision = 3,
%DIFDELCMD < 			sci precision = 3,
%DIFDELCMD < 			column name = {}
%DIFDELCMD < 		},
%DIFDELCMD < 		display columns/12/.style={
%DIFDELCMD < 			precision = 4,
%DIFDELCMD < 			sci precision = 3,
%DIFDELCMD < 			column name = {}
%DIFDELCMD < 		},
%DIFDELCMD < 		display columns/13/.style={
%DIFDELCMD < 			precision = 4,
%DIFDELCMD < 			sci precision = 3,
%DIFDELCMD < 			column name = {}
%DIFDELCMD < 		},
%DIFDELCMD < 		display columns/14/.style={
%DIFDELCMD < 			precision = 4,
%DIFDELCMD < 			sci precision = 3,
%DIFDELCMD < 			column name = {}
%DIFDELCMD < 		},
%DIFDELCMD < 		display columns/15/.style={
%DIFDELCMD < 			precision = 4,
%DIFDELCMD < 			sci precision = 3,
%DIFDELCMD < 			column name = {}
%DIFDELCMD < 		}
%DIFDELCMD < 	]{tables/TopTenEUT.csv} %%%
\DIFdelendFL \DIFaddbeginFL \pgfplotstabletypeset[
		col sep=comma,
		every head row/.style={
			before row={
				\multicolumn{1}{c}{} &
				\multicolumn{10}{c}{Choice in Row} &
				\cnline{Simulated\\Likelihood} &
				\cnline{Expected\\Errors} &
				\cnline{Welfare\\Efficiency} &
				\cnline{Welfare\\Surplus} &
				$P_E(e=0)$ &
				$P_E(e=1)$\\
			},
			after row=\hline
		},
		every last row/.style={
			after row=\hline
		},
		display columns/0/.style={
			column name = {Rank},
			column type={c}
		},
		display columns/1/.style={
			column name = {1},
			column type={|p{.3cm}}
		},
		display columns/2/.style={
			column name = {2},
			column type={p{.3cm}}
		},
		display columns/3/.style={
			column name = {3},
			column type={p{.3cm}}
		},
		display columns/4/.style={
			column name = {4},
			column type={p{.3cm}}
		},
		display columns/5/.style={
			column name = {5},
			column type={p{.3cm}}
		},
		display columns/6/.style={
			column name = {6},
			column type={p{.3cm}}
		},
		display columns/7/.style={
			column name = {7},
			column type={p{.3cm}}
		},
		display columns/8/.style={
			column name = {8},
			column type={p{.3cm}}
		},
		display columns/9/.style={
			column name = {9},
			column type={p{.3cm}}
		},
		display columns/10/.style={
			column name = {10},
			column type={p{.4cm}|}
		},
		display columns/11/.style={
			precision = 4,
			fixed,
			%sci precision = 2,
			zerofill,
			column name = {}
		},
		display columns/12/.style={
			precision = 3,
			zerofill,
			sci precision = 3,
			column name = {}
		},
		display columns/13/.style={
			precision = 4,
			sci precision = 3,
			zerofill,
			column name = {}
		},
		display columns/14/.style={
			precision = 2,
			sci precision = 3,
			zerofill,
			column name = {}
		},
		display columns/15/.style={
			precision = 3,
			sci precision = 3,
			column name = {}
		},
		display columns/16/.style={
			precision = 3,
			sci precision = 3,
			zerofill,
			column name = {}
		}
	]{tables/TopTenEUT.csv} \DIFaddendFL % path/to/file
	\end{adjustbox}
\end{table}

For the \enquote{Choice in Row} column in Table (\ref{tb:TopTenEUT}), $0$ indicates a choice of A for the row, and $1$ indicates a choice of B.
Note that the choice pattern that is mostly likely to be observed from a sample drawn from the specified population\DIFdelbegin \DIFdel{is }\DIFdelend \DIFaddbegin \DIFadd{, shown in the first row where }\textit{\DIFadd{Rank}} \DIFadd{is $1$, is }\DIFaddend the choice pattern we would observe from an agent described by a deterministic choice process with preferences at the mean of the distribution of $r$.
The next two most likely choice patterns\DIFaddbegin \DIFadd{, where }\textit{\DIFadd{Rank}} \DIFadd{is $2$ and $3$, }\DIFaddend correspond to the choice pattern we would observe from agents described by a deterministic choice process with preferences one standard deviation either side of the mean of the distribution of $r$.
\DIFaddbegin 

\DIFaddend Interestingly, for each of \DIFdelbegin \DIFdel{these three }\DIFdelend \DIFaddbegin \DIFadd{the three most likely }\DIFaddend choice patterns, it is far more likely than not that an agent displaying these choice patterns made at least one choice error, and thus did not obtain maximal welfare from her choices.
\DIFaddbegin \DIFadd{This is shown by the values in column $P_E(e=0)$, which reference equation (\ref{eq3:PE}), all being less than $0.50$.
}\DIFaddend Note that only \DIFdelbegin \DIFdel{$32.15\%$ }\DIFdelend \DIFaddbegin \DIFadd{$32.2\%$ }\DIFaddend of agents who display the most likely choice pattern \DIFaddbegin \DIFadd{in row $1$ }\DIFaddend are expected to \DIFaddbegin \DIFadd{have not made any choice errors and }\DIFaddend obtain maximal welfare.
This is despite the fact that any of these choice patterns can be rationalized by some set of preferences \DIFaddbegin \DIFadd{for our assumed model}\DIFaddend .
These patterns do, however, produce \DIFdelbegin \DIFdel{a relatively high proportion of expected welfare }\DIFdelend \DIFaddbegin \DIFadd{relatively high expected welfare efficiency and surplus}\DIFaddend .
The welfare surplus metric is less informative in this comparison\DIFdelbegin \DIFdel{, }\DIFdelend \DIFaddbegin \DIFadd{: }\DIFaddend it is more useful in making absolute rather than relative statements about welfare.

The \DIFdelbegin \DIFdel{large value of $P_E(e >0)$ is due largely }\DIFdelend \DIFaddbegin \DIFadd{relatively large values of $ 1 - P_E(e = 0)$, which imply that most choice patterns contain at least $1$ choice error, is mainly due }\DIFaddend to the shape and location of the distribution of $r$.
The mean of $0.65$ lies just next to the indifference boundary between rows 6 and 7 of the HL-MPL, as indicated in \DIFdelbegin \DIFdel{Table (1}\DIFdelend \DIFaddbegin \DIFadd{the column }\enquote{CRRA for Indifference} \DIFadd{of Table (\ref{tb:HL-MPL}}\DIFaddend ).
That means that the bulk of the $r$ values drawn from this distribution define utility values that indicate near indifference between the A and B lotteries in row 7 of the HL-MPL.
All RE models increase the probability of a choice error the closer an agent is to being indifferent between 2 options, so it should not be a surprise that with this particular choice of distribution for $r$ we have a large proportion of choice errors.

The fourth and fifth most likely choice patterns \DIFaddbegin \DIFadd{in Table (\ref{tb:TopTenEUT}), where }\textit{\DIFadd{Rank}} \DIFadd{is $4$ and $5$}\DIFaddend , \DIFdelbegin \DIFdel{however, }\DIFdelend are not consistent with any deterministic EUT preferences.
These patterns display what we will call \enquote{Light MSB}: not including the choice made in row 10, the agent has \enquote{switched} between choosing A and B three times.{\footnotemark}
Because MSB is not consistent with any deterministic EUT preferences, $P_E(e=0)=0$ for these patterns.
In fact, the only choice patterns in which $P_E(e=0)>0$ will be those which are \enquote{Consistent}: displaying a choice pattern that can be rationalized by some EUT \DIFdelbegin \DIFdel{function.
What is interesting about }\DIFdelend \DIFaddbegin \DIFadd{preferences.
}

\DIFadd{Despite }\DIFaddend the patterns in rows 4 and 5 of Table (\ref{tb:TopTenEUT}) \DIFdelbegin \DIFdel{is that, despite the fact that they are }\DIFdelend \DIFaddbegin \DIFadd{being }\DIFaddend obviously inconsistent with a deterministic EUT process, they both are more likely to be observed \DIFdelbegin \DIFdel{and obtain a greater proportion of welfare }\DIFdelend \DIFaddbegin \DIFadd{from agents drawn from a population defined by $\theta$, and obtain greater welfare surplus }\DIFaddend than the sixth most likely choice pattern which is \enquote{Consistent.}
\DIFdelbegin \DIFdel{In fact, }\DIFdelend \DIFaddbegin \DIFadd{The likelihood of the }\enquote{Light MSB} \DIFadd{choice patterns in rows 4 and 5, displayed in the }\enquote{Simulated Likelihood} \DIFadd{column, are greater than the likelihood of the choice pattern in row 6, which is consistent.
The welfare efficiency metric for row 5, displayed in the }\enquote{Welfare Efficiency} \DIFadd{column, is greater than that of row 6, and the welfare surplus metrics for both rows 4 and 5 are greater than for row 6.
Since metrics for all $TT = 1024$ choice patterns were calculated, we will see in the immediate discussion that }\DIFaddend these two Light MSB patterns are both more likely to be observed and be less costly \DIFdelbegin \DIFdel{than 7 }\DIFdelend \DIFaddbegin \DIFadd{in terms of welfare surplus than 6 }\DIFaddend out of 10 \enquote{Consistent} patterns.

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	The reason that row 10 is not included in this definition is because we are making a distinction between patterns which do and do not include a choice of A in row 10 later.
}

Another interesting aspect of this analysis is the correlation of welfare and the likelihood of observing a choice pattern.
The correlation between \DIFdelbegin \DIFdel{likelihood and the ratio of obtained to maximal welfare is $0.55$ }\DIFdelend \DIFaddbegin \DIFadd{the simulated likelihood of the choice patterns and their expected welfare efficiency is $0.62$ }\DIFaddend across the whole dataset, \DIFdelbegin \DIFdel{which is }\DIFdelend \DIFaddbegin \DIFadd{while the simulated likelihood and expect welfare surplus has a correlation of $0.68$.
These are }\DIFaddend positive but far from 1.
That is, as the \DIFdelbegin \DIFdel{probability }\DIFdelend \DIFaddbegin \DIFadd{likelihood }\DIFaddend of observing a \DIFaddbegin \DIFadd{choice }\DIFaddend pattern increases, the \DIFdelbegin \DIFdel{ratio of obtained welfare to maximal welfare }\DIFdelend \DIFaddbegin \DIFadd{expected welfare efficiency and surplus of the choice pattern }\DIFaddend generally increases as well, but not always.
This is apparent in rows 8 and 9 of Table \DIFdelbegin \DIFdel{(\ref{tb:TopTenEUT})}\DIFdelend \DIFaddbegin \DIFadd{\ref{tb:TopTenEUT}}\DIFaddend .
The choice pattern described in row 8 is more likely to be observed than the pattern in row 9, but the pattern in row 9 has a higher expected welfare \DIFdelbegin \DIFdel{ratio }\DIFdelend \DIFaddbegin \DIFadd{efficiency }\DIFaddend than row 8.
The very large $H$ employed in these calculations rules out the possibility that this is a statistical fluke \DIFdelbegin \DIFdel{from }\DIFdelend \DIFaddbegin \DIFadd{caused by }\DIFaddend the random way these statistics were calculated.
\DIFdelbegin \DIFdel{Instead, this }\DIFdelend \DIFaddbegin 

\DIFadd{This }\DIFaddend example illustrates how stochastic models are not \enquote{welfare ranking} models but instead incorporate aspects of the choice process that are robust to the incentivized environment that the agents exist in.
The example of row 8 and 9 only depicts the most common occurrence where the expected welfare \DIFaddbegin \DIFadd{efficiency }\DIFaddend of a pattern and its \DIFdelbegin \DIFdel{probability }\DIFdelend \DIFaddbegin \DIFadd{likelihood }\DIFaddend diverge in this hypothetical population.
The most drastic divergence occurs between the patterns which have violated FOSD by selecting option A in row 10, and those that have not.

To make this distinction clear, Figure \ref{fig:ConFOSD} plots the log of the SL (SLL) against the expected welfare \DIFdelbegin \DIFdel{proportion }\DIFdelend \DIFaddbegin \DIFadd{efficiency }\DIFaddend of the choice patterns that\DIFdelbegin \DIFdel{are}\DIFdelend :
\begin{itemize}
 \setlength\itemsep{-.5em}
	\item \DIFdelbegin \DIFdel{consistent}\DIFdelend \DIFaddbegin \DIFadd{are Consistent with determinisitic EUT}\DIFaddend ,
	\item are \DIFdelbegin \DIFdel{consistent }\DIFdelend \DIFaddbegin \DIFadd{Consistent }\DIFaddend other than the choice of A in row 10 (FOSD Only),
	\item display Light MSB\DIFaddbegin \DIFadd{, the agent has }\enquote{switched} \DIFadd{between choosing A and B three times, }\DIFaddend with a choice of B in row 10\DIFdelbegin \DIFdel{(Light MSB)}\DIFdelend ,
	\item \DIFdelbegin \DIFdel{and }\DIFdelend display Light MSB with a choice of A in row 10 (Light MSB + FOSD)
\end{itemize}

\begin{figure}[h!]
	\caption{Consistent and Light MSB, With and Without Row 10 Error}
	\includegraphics[width=\linewidth]{figures/SamPlots/EUT-ConFOSD.jpg}
	\label{fig:ConFOSD}
\end{figure}

In Figure \ref{fig:ConFOSD}, each point represents a unique choice pattern.
For any given point plotted, any other point to the Southeast of that point indicates a pattern that is both more likely to be \DIFdelbegin \DIFdel{observed and is expected to provides less welfare }\DIFdelend \DIFaddbegin \DIFadd{produced by an agent drawn randomly from this population and provides lower expected welfare efficiency}\DIFaddend .
For instance, any point in the shaded region of Figure \ref{fig:ConFOSD} represents a choice pattern that is both more likely to be observed and have a lower expected welfare \DIFdelbegin \DIFdel{ratio }\DIFdelend \DIFaddbegin \DIFadd{efficiency }\DIFaddend than pattern Y.

Figure \ref{fig:ConFOSD} shows that the choice of A in row 10 greatly decreases the SLL of the pattern, but barely decreases the expected ratio of obtained welfare to maximal welfare, all else equal.
For example, the most likely consistent choice pattern is the top right-most red dot in Figure \ref{fig:ConFOSD}, labeled \enquote{X}, which corresponds to row 1 of Table 2 and has a welfare \DIFdelbegin \DIFdel{ratio }\DIFdelend \DIFaddbegin \DIFadd{efficiency }\DIFaddend of 0.986 and a SL of 0.036.
The most likely choice pattern with a choice of A in row 10 is the top right-most green dot, labeled \enquote{Y}.
This pattern is identical to the \enquote{X} pattern other than the selection of A in row 10 and has a welfare \DIFdelbegin \DIFdel{proportion }\DIFdelend \DIFaddbegin \DIFadd{efficiency }\DIFaddend of 0.938 and a SL of 0.00246.
The ratio of welfare obtained to maximum differs only by 0.0483, but pattern X is about 14.65 times more likely to be observed than pattern Y.
The seventh most likely consistent pattern, not displayed in Table 1, but can be seen as the red dot in Figure \ref{fig:ConFOSD} labeled \enquote{Z}, is about 1.55 times more likely to be observed than pattern Y, and has an expected welfare \DIFdelbegin \DIFdel{ratio }\DIFdelend \DIFaddbegin \DIFadd{efficiency }\DIFaddend that is about 0.065 \textit{lower} than pattern Y.

The general result of this exercise is to make clear that stochastic models do not perfectly link the likelihood of a choice pattern with its realized welfare \DIFaddbegin \DIFadd{as consumer surplus or efficiency}\DIFaddend .
This is due to the way in which heteroscedastic RE models disproportionately \enquote{punish} FOSD by assigning occurrences of it a very low likelihood.
The choice of A in row 10 is punished even more by the fact that there is no risk involved.
\DIFaddbegin 


\DIFaddend Empirically, experimental economists rarely observe behavior such as the choice of A in row 10 because the agents they study are in environments that incentivize them to reject dominated offers.
There is, by definition, no extra benefit to actively choosing a dominated offer.
But just because there is no extra benefit to be had, it shouldn't be inferred that the agent doesn't value the dominated option positively.
Any agent who selected option A in row 10 still receives a \$2 benefit from having had the choice problem presented to her if that choice is selected for payment.
It makes a great deal of sense to model choice in this fashion: that there is somewhat of a disconnect between greater realized welfare and greater likelihood of choice helps to illustrate the complex nature of economic agency.

\DIFdelbegin \subsubsection{\DIFdel{Sample Level Analysis with a Mixed EUT-RDU Population}}
%DIFAUXCMD
\addtocounter{subsubsection}{-1}%DIFAUXCMD
\DIFdelend \DIFaddbegin \subsection{\DIFadd{Sample Level Analysis with a Mixed EUT-RDU Population}}
\DIFaddend 

The above discussion focuses on a population that is entirely composed of EUT conforming agents.
Individual level estimates from \textcite{Hey1994} and the mixture model estimates from \textcite{Harrison2008a} show that many populations are likely not composed entirely of EUT agents.
We can extend the example above, defining the population as being made of some mixture of EUT agents and RDU agents.
By mixture, we mean that there will be two subpopulations of a grand population, but agents from these subpopulations carry no observable characteristics to distinguish themselves as belonging to one subpopulation or another.

Before beginning the analysis of this mixture population, we can extend the metrics utilized in equations (\DIFdelbegin \DIFdel{\ref{eq:SLnT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:SLnT}}\DIFaddend ) and (\DIFdelbegin \DIFdel{\ref{eq:MBn}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:MTBn}}\DIFaddend ) through (\DIFdelbegin \DIFdel{\ref{eq:EPWTe}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EPWTe}}\DIFaddend ) to be defined for mixed populations.
This is \DIFdelbegin \DIFdel{done }\DIFdelend \DIFaddbegin \DIFadd{implemented }\DIFaddend much the same way as mixture models were defined in equation (\DIFdelbegin \DIFdel{\ref{eq:PT_Mix}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:PT_Mix}}\DIFaddend ); each metric, $Q_m$, for subpopulation $m$ is weighted by the proportion of the subpopulation in the grand population, $M$.
\begin{align}
	\DIFdelbegin %DIFDELCMD < \label{eq:Metric_Mix}
%DIFDELCMD < 	%%%
\DIFdelend \DIFaddbegin \label{eq3:Metric_Mix}
	\DIFaddend \begin{split}
		\bm{\mathit{Q^M}} = \sum_m^M \pi_m \times Q^m \\ 
		\mathit{st.} \sum_m^M \pi_m = 1
	\end{split}
\end{align}

\noindent where $\pi_m$ is the proportion of subpopulation $m$ in the grand population.
For example, the probability of observing any given choice pattern $y \times T$ for a grand population made of M subpopulations is:
\begin{align}
	\DIFdelbegin %DIFDELCMD < \label{eq:LnT_Mix}
%DIFDELCMD < 	%%%
\DIFdelend \DIFaddbegin \label{eq3:LnT_Mix}
	\DIFaddend \begin{split}
		\bm{L_{nT}^M} = \sum_m^M \pi_m \times L_{nT}^m(\theta^m) \\ 
		\mathit{st.} \sum_m^M \pi_m = 1
	\end{split}
\end{align}

\noindent where $L_{nT}^m$ is as described in equation (\DIFdelbegin \DIFdel{\ref{eq:LnT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:LnT}}\DIFaddend ) for some subpopulation $m$ defined by $\theta^m$.

A final metric before we begin the example of the mixed population is the probability that any given choice pattern was produced by population $m$.
Utilizing equation (\DIFdelbegin \DIFdel{\ref{eq:LnT_Mix}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:LnT_Mix}}\DIFaddend ) we define the probability that a pattern was produced by population $m$ as the ratio of the weighted simulated likelihood of observing the pattern from subpopulation $m$ to the likelihood of observing the pattern in the grand population:

\begin{equation}
	\DIFdelbegin %DIFDELCMD < \label{eq:Propm}
%DIFDELCMD < 	%%%
\DIFdelend \DIFaddbegin \label{eq3:Propm}
	\DIFaddend \mathit{Prop^m_{T}} = \frac{\pi_m \times L_{nT}^m(\theta^m) }{\bm{L_{nT}^M}}
\end{equation}

With this mixing framework in mind, we can define our grand population.
We assume that $70\%$ of agents in the grand population conform to EUT, while the remaining $30\%$ conform to RDU.
Given that the previous example thoroughly examined an EUT population, rather than duplicate analysis, we assume that the EUT subpopulation is the same as the previous EUT-only example.
Thus, the EUT subpopulation is defined as using a CU stochastic model and CRRA function with the $r$ parameter normally distributed $r \sim \mathcal{N}(0.65 , 0.3^2 )$, and the $\lambda$ parameter following a gamma distribution $\lambda \sim \Gamma(1.36 , 0.26)$.
This results in $\theta^{EUT} = \lbrace 0.65 ,0.3^2, 1.36 , 0.26\rbrace$.

For the RDU \DIFdelbegin \DIFdel{population, we will again use a CU stochastic model and a CRRA utility function, and additionally use the }\DIFdelend \DIFaddbegin \DIFadd{subpopulation, we employ the the }\DIFaddend flexible 2 parameter decision weighting function defined by \textcite{Prelec1998} \DIFdelbegin \DIFdel{.
}\DIFdelend \DIFaddbegin \DIFadd{as the probability weighting funciton to be substiuted into equation (\ref{eq3:dweight}):
}\begin{equation}
	\DIFadd{\label{eq3:pw:pre}
	\omega(p_i)=\exp(-\beta(-\ln(p_i))^\alpha)
}\end{equation}
\noindent \DIFadd{where $\alpha > 0$ and $\beta > 0$.
We continue to use the CRRA utility function and CU stochastic model for the RDU subpopulation.
}

\DIFaddend The $r$ parameter is be distributed identically to the $r$ parameter in the EUT population $r \sim \mathcal{N}(0.65 , 0.3^2 )$, and the $\lambda$ parameter still uses the gamma distribution, but is distributed $\lambda \sim \Gamma(0.563 , 0.26)$, which results in the mean of the $\lambda$ distribution at $0.15$ and a standard deviation of $0.2$.{\footnotemark}
Both the $\alpha$ and $\beta$ parameters for the decision weight function must be greater than $0$, so they will also be distributed with a gamma distribution, $\alpha \sim \Gamma(169 , 7.69 \times 10^{-3})$ and $\beta \sim \Gamma(144 , 8.33 \times 10^{-3})$.
Thus the mean of $\alpha$ is $\approx 1.3$ and its standard deviation is $\approx 0.1$, and the mean of $\beta$ is $\approx 1.2$ and its standard deviation is $\approx 0.1$.
This results in $\theta^{RDU} = \lbrace  0.65 ,0.3^2,  0.563 , 0.26 , 169 , 7.69 \times 10^{-3} , 144 , 8.33 \times 10^{-3} \rbrace$.

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	With the mass of the $\lambda$ distribution closer to $0$, \textit{a priori} we should expect fewer choice errors among the RDU population than the EUT population.
}

Once again, we will employ an $H = 2.5 \times 10^6$ and calculate the values for equations (\DIFdelbegin \DIFdel{\ref{eq:SLnT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:SLnT}}\DIFaddend ) and (\DIFdelbegin \DIFdel{\ref{eq:MBn}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:MTBn}}\DIFaddend ) through (\DIFdelbegin \DIFdel{\ref{eq:EPWTe}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EPWTe}}\DIFaddend ) for all $\mathit{TT} =1024$ choice patterns and all $e \in[0,T]$ for the RDU subpopulation.
With the results of the calculations for the EUT subpopulation calculated previously, and the results of the same calculations for the RDU population, we can mix each of these metrics as described in equation (\DIFdelbegin \DIFdel{\ref{eq:Metric_Mix}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:Metric_Mix}}\DIFaddend ) with $\pi_{EUT} = 0.7$ and $\pi_{RDU} = 0.3$.
Again, it is impractical to display the results of all metrics for all $1024$ choice patterns, so first, we recreate Table (\ref{tb:TopTenEUT}) with the results of the RDU metrics.

\begin{table}[ht]
	\centering
	\caption{HL-MPL Welfare and Error Expectations for\\Top Ten Choice Patterns, RDU}
	\label{tb:TopTenRDU}
	\begin{adjustbox}{width=1\textwidth}
	\pgfplotstabletypeset[
		col sep=comma,
		every head row/.style={
			before row={
				\multicolumn{10}{c}{Choice in Row} &
				\cnline{Simulated\\Likelihood} &
				\cnline{Expected\\Errors} &
				\cnline{Welfare\\Proportion} &
				\cnline{Welfare\\Surplus} &
				$P_E(e=0)$ &
				$P_E(e=1)$\\
			},
			after row=\hline
		},
		every last row/.style={
			after row=\hline
		},
		display columns/0/.style={
			column name = {1},
			column type={p{.2cm}}
		},
		display columns/9/.style={
			column name = {10},
			column type={p{.3cm}|}
		},
		display columns/10/.style={
			precision = 4,
			sci precision = 3,
			column name = {}
		},
		display columns/11/.style={
			precision = 3,
			sci precision = 3,
			column name = {}
		},
		display columns/12/.style={
			precision = 4,
			sci precision = 3,
			column name = {}
		},
		display columns/13/.style={
			precision = 4,
			sci precision = 3,
			column name = {}
		},
		display columns/14/.style={
			precision = 4,
			sci precision = 3,
			column name = {}
		},
		display columns/15/.style={
			precision = 4,
			sci precision = 3,
			column name = {}
		}
	]{tables/TopTenRDU.csv} % path/to/file
	\end{adjustbox}
\end{table}

There is a great deal of similarity between Table \DIFdelbegin \DIFdel{(\ref{tb:TopTenRDU} ) and Table (\ref{tb:TopTenEUT})}\DIFdelend \DIFaddbegin \DIFadd{\ref{tb:TopTenRDU} and Table \ref{tb:TopTenEUT}}\DIFaddend .
In particular, the two subpopulations share the same $3$ most likely choice patterns, though with different simulated likelihood, welfare, and error metrics.
Again we note that the choice patterns which display Light MSB have $0$ probability of containing $0$ choice errors, and that several Light MSB choice patterns are expected to contain fewer choice errors and be less costly in \DIFdelbegin \DIFdel{tems }\DIFdelend \DIFaddbegin \DIFadd{terms }\DIFaddend of welfare than some Consistent choice patterns.
There appears to be less of a disconnect between welfare and likelihood in the RDU subpopulation than in the EUT subpopulation. 
In Table \DIFdelbegin \DIFdel{(\ref{tb:TopTenRDU} ) }\DIFdelend \DIFaddbegin \DIFadd{\ref{tb:TopTenRDU} }\DIFaddend we observe that going from row 6 to 7 the Simulated Likelihood decreases, but the Welfare Proportion metric increases.
However, the Welfare Surplus metric decreases with the Simulated Likelihood of the choice pattern for all patterns in Table (\ref{tb:TopTenRDU}).

A major difference between the two subpopulations is that the RDU subpopulation's most likely choice pattern has a much greater likelihood than the EUT subpopulation's most likely choice pattern.
Much of this is due to the greater mass of the $\lambda$ \DIFdelbegin \DIFdel{distrubtion }\DIFdelend \DIFaddbegin \DIFadd{distribution }\DIFaddend close to $0$ in the RDU subpopulation compared to the EUT subpopulation, but it is also because the distributions chosen for the decision weighting parameters imply greater risk aversion.
This means that although the CRRA coefficients lie near the \DIFdelbegin \DIFdel{boundry }\DIFdelend \DIFaddbegin \DIFadd{boundary }\DIFaddend of row 6 and 7 of the HL-MPL, the way the RDU subpopulation weights probabilities makes them more risk averse, and therefore more likely to switch at row 7 than if they did not weight probabilities.
These differences are important when we look at the grand population metrics.

\begin{table}[ht]
	\centering
	\caption{HL-MPL Welfare and Error Expectations for\\Top Ten Choice Patterns, EUT-RDU Mixture}
	\label{tb:TopTenMIX}
	\begin{adjustbox}{width=1\textwidth}
	\pgfplotstabletypeset[
		col sep=comma,
		every head row/.style={
			before row={
				\multicolumn{10}{c}{Choice in Row}&
				\cnline{Proportion\\EUT}&
				\cnline{Simulated\\Likelihood}&
				\cnline{Expected\\Errors}&
				\cnline{Welfare\\Proportion}&
				\cnline{Welfare\\Surplus}&
				$P_E(e=0)$\\
			},
			after row=\hline
		},
		every last row/.style={
			after row=\hline
		},
		display columns/0/.style={
			column name = {1},
			column type={p{.2cm}}
		},
		display columns/9/.style={
			column name = {10},
			column type={p{.3cm}|}
		},
		display columns/10/.style={
			precision = 2,
			sci precision = 3,
			column name = {}
		},
		display columns/11/.style={
			precision = 4,
			sci precision = 3,
			column name = {}
		},
		display columns/12/.style={
			precision = 3,
			sci precision = 3,
			column name = {}
		},
		display columns/13/.style={
			precision = 4,
			sci precision = 3,
			column name = {}
		},
		display columns/14/.style={
			precision = 4,
			sci precision = 3,
			column name = {}
		},
		display columns/15/.style={
			precision = 4,
			sci precision = 3,
			column name = {}
		}
	]{tables/TopTenMIX.csv} % path/to/file
	\end{adjustbox}
\end{table}

The grand population metrics displayed in Table (\ref{tb:TopTenMIX}) are barely noteworthy by themselves.
They easily could have been generated by a population composed entirely of EUT agents with a distribution of $\lambda$ somewhat closer to $0$ than the EUT subpopulation that actually composes $70\%$ of the agents in this population.
Many of the same features of the two subpopulations are apparent in the mixed grand population;
choice patterns displaying any form of MSB have $0$ likelihood of $0$ choice errors, and there are some disconnects between simulated likelihood and welfare as observed in rows $5$-$6$, and $7$-$8$ for the welfare \DIFdelbegin \DIFdel{proportion }\DIFdelend \DIFaddbegin \DIFadd{efficiency }\DIFaddend metric and rows $9$-$10$ for the welfare surplus metric.

Of greater interest is the \enquote{Proportion EUT} metric, defined in equation (\DIFdelbegin \DIFdel{\ref{eq:Propm}).
}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:Propm}).
This meteric calculates the unconditional likelihood that a subject displaying a particular choice pattern belongs to the EUT subpopulation we defined.
}\DIFaddend For every choice pattern in the top ten most likely to be observed choice patterns, we expect that the proportion of the agents belonging to the EUT subpopulation that generated the choice pattern is smaller than the proportion of EUT agents in the grand population.
For the top 3 choice patterns, the difference between the proportion of EUT agents in the total population and the proportion of EUT agents that generated the choice pattern is greater than $20\%$.
In fact, it is more likely than not that these choice patterns are generaed by the RDU subpopulation.
This is despite the fact that the EUT subpopulation makes up $70\%$ of the grand population, and that the top three most likely to be observed choice patterns in the grand popualtion all correspond to the same top three choice patterns in the EUT subpopulation.

The above discussion of the three populations helps to illuminate the concept that knowledge of the distribution of preferences in a sample allows an analyst to have a better interpretation of observed patterns of choice.
Table 2 demonstrates that for many choice patterns which can be described as \enquote{consistent} with EUT, the EUT function which \DIFdelbegin \DIFdel{would best fit the }\DIFdelend \DIFaddbegin \DIFadd{rationalizes }\DIFaddend individual agent's data actually misrepresents the agent's \enquote{true} preferences.
Similar conclusions can be drawn for a population comprised entirely of RDU agents.
The consequence of this misrepresentation is that an agent is assumed to have made choices that maximize her subjective welfare when this is not the case.
In our particular choice of example EUT and RDU population parameters, for every agent who displays a \enquote{consistent} choice pattern it is more likely than not that their \enquote{true} underlying preferences are best characterized by a utility function which does not rationalize their observed choice behavior.
This general result is just as applicable to choice patterns described by RDU as it is to patterns described by EUT as well as for other coherent stochastic models, not just CU.

It should also be clear from Table 2 and Figure \ref{fig:ConFOSD} that not all choice patterns that are consistent with EUT should be judged as superior to choice patterns which are apparently inconsistent with EUT from the perspective of welfare realization \DIFaddbegin \DIFadd{as consumer surplus or welfare efficiency}\DIFaddend .
Figure \ref{fig:ConFOSD} demonstrates that stochastic models can make normative sense of occurrences of FOSD, while making the descriptively accurate claim that violations of dominance are unlikely to occur, a claim backed by the empirical literature described in the previous chapter.

\DIFdelbegin \subsection{\DIFdel{Individual vs. Sample Level Identification}}
%DIFAUXCMD
\addtocounter{subsection}{-1}%DIFAUXCMD
\DIFdelend %DIF > \section{Individual vs. Sample Level Identification}
%DIF > 
%DIF > Having made the case that sample level assessment of welfare provides information that is lacking in individual level assessment, it is important to ask the question \enquote{How much more information?} or \enquote{Why/When should we (economists) care?} 
%DIF > The welfare metric described in equation (\ref{eq3:EWET}) provides a useful benchmark to describe the difference between the welfare evaluation done on the individual level versus welfare evaluation done on the sample level.
%DIF > This distinction can be made clearer by examining \enquote{consistent} choice patterns, that is, patterns which can be described as conforming to deterministic utility theory.
%DIF > These patterns, along with the same associated metrics calculated in Table (\ref{tb:TopTenEUT}) for the EUT population are presented below, ranked in order of their likelihood of being observed:
%DIF > 
%DIF > \begin{table}[ht]
%DIF > 	\centering
%DIF > 	\caption{Consistent Choice Patterns and Associated Metrics\\EUT Population}
%DIF > 	\label{tb:ConPat}
%DIF > 	\begin{adjustbox}{width=1\textwidth}
%DIF > 	\pgfplotstabletypeset[
%DIF > 		col sep=tab,
%DIF > 		every head row/.style={
%DIF > 		% as in the previous example, this patches the first row:
%DIF > 			before row={
%DIF > 				\multicolumn{10}{c}{Choice in Row} &
%DIF > 				\cnline{Simulated\\Likelihood} & 
%DIF > 				\cnline{Expected\\Errors} & 
%DIF > 				\cnline{Welfare\\Proportion} & 
%DIF > 				\cnline{Welfare\\Surplus} &
%DIF > 				$P_E(e=0)$ & 
%DIF > 				\cnline{CRRA\\Boundary}\\
%DIF > 			},
%DIF > 			after row=\hline,
%DIF > 		},
%DIF > 		every last row/.style={
%DIF > 		after row=\hline},
%DIF > 		display columns/0/.style={
%DIF > 			column name = {1},
%DIF > 			column type={p{.2cm}}
%DIF > 		},
%DIF > 		display columns/9/.style={
%DIF > 			column name = {10},
%DIF > 			column type={p{.3cm}}
%DIF > 		},
%DIF > 		display columns/10/.style={
%DIF > 			precision = 2,
%DIF > 			sci precision = 3,
%DIF > 			column name = {}
%DIF > 		},
%DIF > 		display columns/11/.style={
%DIF > 			precision = 3,
%DIF > 			sci precision = 3,
%DIF > 			column name = {}
%DIF > 		},
%DIF > 		display columns/12/.style={
%DIF > 			precision = 4,
%DIF > 			sci precision = 3,
%DIF > 			column name = {}
%DIF > 		},
%DIF > 		display columns/13/.style={
%DIF > 			precision = 4,
%DIF > 			sci precision = 3,
%DIF > 			column name = {}
%DIF > 		},
%DIF > 		display columns/14/.style={
%DIF > 			precision = 4,
%DIF > 			sci precision = 2,
%DIF > 			column name = {}
%DIF > 		},
%DIF > 		display columns/15/.style={
%DIF > 			string type,
%DIF > 			column name = {}
%DIF > 		}
%DIF > 	]{tables/ConsistentEUT.csv} % path/to/file
%DIF > 	\end{adjustbox}
%DIF > \end{table}
%DIF > 
%DIF > 
%DIF > We begin this discussion by noting that because each of the patterns listed in Table (\ref{tb:ConPat}) are \enquote{consistent}, should an estimation routine be applied to any of them individually, the preference parameter returned will lie somewhere in the indifference band described under the \enquote{CRRA Boundary} column.{\footnotemark} 
%DIF > Also, because each of these patterns is \enquote{consistent}, the welfare efficiency will be 1 for each of these estimates.
%DIF > That is to say, because these patterns can be perfectly explained by a CRRA utility function with a parameter value within the interval described in the \enquote{CRRA Boundary} column, agents who have generated these choice patterns have made 0 apparent choice errors, thus, they have not apparently forgone any welfare.
%DIF > 
%DIF > \addtocounter{footnote}{-1}
%DIF > \stepcounter{footnote}\footnotetext{
%DIF > 	Note that for the choice pattern in row 10 of Table (\ref{tb:ConPat}) estimation is impossible because of the lack of variation in the data. 
%DIF > 	For the remaining 9 choice patterns, there is little room to estimate both the CRRA parameter and a stochastic error parameter. 
%DIF > 	The CRRA boundary, however, still describes the range of parameter values that explain this choice pattern given a deterministic EUT choice process.
%DIF > }
%DIF > 
%DIF > What is clear from the sample level analyses however is that this is not the case in reality.
%DIF > In this particular population, every observed \enquote{consistent} choice pattern is more likely to be the result of one or more choice errors made by the agent than to be an accurate representation of the agent's \enquote{true} preferences.
%DIF > For choice patterns that have a low likelihood of being observed given the population, there is effectively a $0\%$ probability that the choice pattern accurately represents the \enquote{true} preference of the agent that generated it.
%DIF > 
%DIF > While Table (\ref{tb:ConPat}) is constructed based on an EUT-only population, a similar table could be constructed for the EUT/RDU Mixture population described in Table (\ref{tb:TopTenMIX}).
%DIF > As before, there would not be much difference in the presented metrics, but the presence of an RDU subpopulation presents further potential problems for individual level estimation.
%DIF > The top three choice patterns described in Tables (\ref{tb:ConPat}) and (\ref{tb:TopTenMIX}) can all be perfectly explained by an EUT model. 
%DIF > But, as is seen by the \enquote{EUT Proportion} metric in Table (\ref{tb:TopTenMIX}), the majority of agents displaying these patterns in our example mixed population actually conform to RDU, not EUT.
%DIF > Thus, unlike the potential for misidentification of a population composed entirely of EUT agents as displayed in Table (\ref{tb:ConPat}), the most likely choice patterns to be observed are also among the most likely to lead to misidentification.
%DIF > 
%DIF > In general, however, it appears that the less likely it is to observe a choice pattern from a given population, the more likely it is that individual level estimation applied to these choice patterns will misidentify the preferences of the agent that generated it.
%DIF > In addition, the cost of this misidentification, in terms of a mischaracterization of the agent's welfare, also increases as the likelihood of observing the choice pattern decreases.
%DIF > We can readily see this by observing how far the welfare efficiency in Table (\ref{tb:ConPat}) are from 1.
%DIF > While this difference is low for the most common choice patterns, it is not insignificant.
%DIF > For instance, the choice pattern in row 5, which is only about a third as likely to be observed as the most likely choice pattern, is more than 0.07 away from 1.
%DIF > 
%DIF > To end this discussion, it should be made clear that we recognize that, to an extent, the comparison of individual level estimation against sample level estimation using the HL instrument defined is somewhat of a straw-man argument.
%DIF > Estimation at the individual level is often done using instruments that have greater than 40 choice problems presented to subjects, and with lottery pairs constructed specifically to aid in the correct identification of RDU agents.
%DIF > These considerations likely lead to greater statistical power than the 10-choice HL-MPL in the example given.
%DIF > Larger numbers of choice problems presented to subjects leads to lower likelihoods of observing the kind of choice error patterns that we discuss.
%DIF > In addition, it is not possible to retrieve estimates from most choice patterns in the HL-MPL because of the low number of choice problems.
%DIF > Thus we are not able to directly compare estimates of welfare at the individual level with estimates done on the sample level for the majority of choice patterns using the HL-MPL.
%DIF > 
%DIF > However, having a larger number of choice problems does not rule out the potential for serious mischaracterization of preferences, and by extension the characterization of welfare.
%DIF > The potential for such problems depends in large part due to the idiosyncratic aspects of the experimental instrument along with the particular distributions of parameters in the population the sample was drawn from.
%DIF > In particular, it seems that individual level estimation will lead to mischaracterization of the tails of the distribution of preferences in a sample.
%DIF > We believe that this exercise demonstrates some potential pitfalls of conducting individual level estimation.

\DIFdelbegin \DIFdel{Having made the case that sample level assessment of welfare provides information that is lacking in individual level assessment, it is important to ask the question }%DIFDELCMD < \enquote{How much more information?} %%%
\DIFdel{or }%DIFDELCMD < \enquote{Why/When should we (economists) care?} 
%DIFDELCMD < %%%
\DIFdel{The welfare metric described in equation (\ref{eq:EPWT}) provides a useful benchmark to describe the difference between the welfare evaluation done on the individual level versus welfare evaluation done on the sample level.
This distinction can be made clearer by examining }%DIFDELCMD < \enquote{consistent} %%%
\DIFdel{choice patterns, that is, patterns which can be described as conforming to deterministic utility theory.
These patterns, along with the same associated metrics calculated in Table (\ref{tb:TopTenEUT}) for the EUT population are presented below, ranked in order of their likelihood of being observed:
}\DIFdelend \DIFaddbegin \section{\DIFadd{Population Level Analysis of Welfare: Preferences, Noise, and the Instrument}}
\DIFaddend 

\DIFdelbegin %DIFDELCMD < \begin{table}[ht]
%DIFDELCMD < 	\centering
%DIFDELCMD < 	%%%
%DIFDELCMD < \caption{%
{%DIFAUXCMD
\DIFdelFL{Consistent Choice Patterns and Associated Metrics}%DIFDELCMD < \\%%%
\DIFdelFL{EUT Population}}
	%DIFAUXCMD
%DIFDELCMD < \label{tb:ConPat}
%DIFDELCMD < 	\begin{adjustbox}{width=1\textwidth}
%DIFDELCMD < 	\pgfplotstabletypeset[
%DIFDELCMD < 		col sep=tab,
%DIFDELCMD < 		every head row/.style={
%DIFDELCMD < 		% as in the previous example, this patches the first row:
%DIFDELCMD < 			before row={
%DIFDELCMD < 				\multicolumn{10}{c}{Choice in Row} &
%DIFDELCMD < 				\cnline{Simulated\\Likelihood} & 
%DIFDELCMD < 				\cnline{Expected\\Errors} & 
%DIFDELCMD < 				\cnline{Welfare\\Proportion} & 
%DIFDELCMD < 				\cnline{Welfare\\Surplus} &
%DIFDELCMD < 				$P_E(e=0)$ & 
%DIFDELCMD < 				\cnline{CRRA\\Boundary}\\
%DIFDELCMD < 			},
%DIFDELCMD < 			after row=\hline,
%DIFDELCMD < 		},
%DIFDELCMD < 		every last row/.style={
%DIFDELCMD < 		after row=\hline},
%DIFDELCMD < 		display columns/0/.style={
%DIFDELCMD < 			column name = {1},
%DIFDELCMD < 			column type={p{.2cm}}
%DIFDELCMD < 		},
%DIFDELCMD < 		display columns/9/.style={
%DIFDELCMD < 			column name = {10},
%DIFDELCMD < 			column type={p{.3cm}}
%DIFDELCMD < 		},
%DIFDELCMD < 		display columns/10/.style={
%DIFDELCMD < 			precision = 2,
%DIFDELCMD < 			sci precision = 3,
%DIFDELCMD < 			column name = {}
%DIFDELCMD < 		},
%DIFDELCMD < 		display columns/11/.style={
%DIFDELCMD < 			precision = 3,
%DIFDELCMD < 			sci precision = 3,
%DIFDELCMD < 			column name = {}
%DIFDELCMD < 		},
%DIFDELCMD < 		display columns/12/.style={
%DIFDELCMD < 			precision = 4,
%DIFDELCMD < 			sci precision = 3,
%DIFDELCMD < 			column name = {}
%DIFDELCMD < 		},
%DIFDELCMD < 		display columns/13/.style={
%DIFDELCMD < 			precision = 4,
%DIFDELCMD < 			sci precision = 3,
%DIFDELCMD < 			column name = {}
%DIFDELCMD < 		},
%DIFDELCMD < 		display columns/14/.style={
%DIFDELCMD < 			precision = 4,
%DIFDELCMD < 			sci precision = 2,
%DIFDELCMD < 			column name = {}
%DIFDELCMD < 		},
%DIFDELCMD < 		display columns/15/.style={
%DIFDELCMD < 			string type,
%DIFDELCMD < 			column name = {}
%DIFDELCMD < 		}
%DIFDELCMD < 	]{tables/ConsistentEUT.csv} %%%
%DIF <  path/to/file
	%DIFDELCMD < \end{adjustbox}
%DIFDELCMD < \end{table}
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{We begin this discussion by noting that because each of the patterns listed in Table (\ref{tb:ConPat}) are }%DIFDELCMD < \enquote{consistent}%%%
\DIFdel{, should an estimation routine be applied to any of them individually, the preference parameter returned will lie somewhere in the indifference band described under the }%DIFDELCMD < \enquote{CRRA Boundary} %%%
\DIFdel{column.}%DIFDELCMD < {\footnotemark} 
%DIFDELCMD < %%%
\DIFdel{Also, because each of these patterns is }%DIFDELCMD < \enquote{consistent}%%%
\DIFdel{, the welfare ratio will be 1 for each of these estimates.
That is to say, because these patterns can be perfectly explained by a CRRA utility function with a parameter value within the interval described in the }%DIFDELCMD < \enquote{CRRA Boundary} %%%
\DIFdel{column, agents who have generated these choice patterns have made 0 apparent choice errors, thus, they have not apparently forgone any welfare.
}%DIFDELCMD < 

%DIFDELCMD < \addtocounter{footnote}{-1}
%DIFDELCMD < \stepcounter{footnote}%%%
\footnotetext{\DIFdel{Note that for the choice pattern in row 10 of Table (\ref{tb:ConPat}) estimation is impossible because of the lack of variation in the data. 
	For the remaining 9 choice patterns, there is little room to estimate both the CRRA parameter and a stochastic error parameter. 
	The CRRA boundary, however, still describes the range of parameter values that explain this choice pattern given a deterministic EUT choice process.
}}
%DIFAUXCMD
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{What is clear from the sample level analyses however is that this is not the case in reality.
In this particular population, every observed }%DIFDELCMD < \enquote{consistent} %%%
\DIFdel{choice pattern is more likely to be the result of one or more choice errors made by the agent than to be an accurate representation of the agent's }%DIFDELCMD < \enquote{true} %%%
\DIFdel{preferences.
For choice patterns that have a low likelihood of being observed given the population, there is effectively a $0\%$ probability that the choice pattern accurately represents the }%DIFDELCMD < \enquote{true} %%%
\DIFdel{preference of the agent that generated it.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{While Table (\ref{tb:ConPat}) is constructed based on an EUT-only population, a similar table could be constructed for the EUT/RDU Mixture population described in Table (\ref{tb:TopTenMIX}).
As before, there would not be much difference in the presented metrics, but the presence of an RDU subpopulation presents further potential problems for individual level estimation.
The top three choice patterns described in Tables (\ref{tb:ConPat}) and (\ref{tb:TopTenMIX}) can all be perfectly explained by an EUT model. 
But, as is seen by the }%DIFDELCMD < \enquote{EUT Proportion} %%%
\DIFdel{metric in Table (\ref{tb:TopTenMIX}), the majority of agents displaying these patterns in our example mixed population actually conform to RDU, not EUT.
Thus, unlike the potential for misidentification of a population composed entirely of EUT agents as displayed in Table (\ref{tb:ConPat}), the most likely choice patterns to be observed are also among the most likely to lead to misidentification.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{In general, however, it appears that the less likely it is to observe a choice pattern from a given population, the more likely it is that individual level estimation applied to these choice patterns will misidentify the preferences of the agent that generated it.
In addition, the cost of this misidentification, in terms of a mischaracterization of the agent's welfare, also increases as the likelihood of observing the choice pattern decreases.
We can readily see this by observing how far the welfare ratios in Table (\ref{tb:ConPat}) are from 1.
While this difference is low for the most common choice patterns, it is not insignificant.
For instance, the choice pattern in row 5, which is only about a third as likely to be observed as the most likely choice pattern, is more than 0.07 away from 1.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{To end this discussion, it should be made clear that we recognize that, to an extent, the comparison of individual level estimation against sample level estimation using the HL instrument defined is somewhat of a straw-man argument.
Estimation at the individual level is often done using instruments that have greater than 40 choice problems presented to subjects, and with lottery pairs constructed specifically to aid in the correct identification of RDU agents.
These considerations likely lead to greater statistical power than the 10-choice HL-MPL in the example given.
Larger numbers of choice problems presented to subjects leads to lower likelihoods of observing the kind of choice error patterns that we discuss.
In addition, it is not possible to retrieve estimates from most choice patterns in the HL-MPL because of the low number of choice problems.
Thus we are not able to directly compare estimates of welfare at the individual level with estimates done on the sample level for the majority of choice patterns using the HL-MPL.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{However, having a larger number of choice problems does not rule out the potential for serious mischaracterization of preferences, and by extension the characterization of welfare.
The potential for such problems depends in large part due to the idiosyncratic aspects of the experimental instrument along with the particular distributions of parameters in the population the sample was drawn from.
In particular, it seems that individual level estimation will lead to mischaracterization of the tails of the distribution of preferences in a sample.
We believe that this exercise demonstrates some potential pitfalls of conducting individual level estimation.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\subsection{\DIFdel{Population Level Analysis of Welfare: Preferences, Noise, and the Instrument}}
%DIFAUXCMD
\addtocounter{subsection}{-1}%DIFAUXCMD
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend The proposed characterizations of the welfare of a sample, including the degree to which certain consistent choice patterns are expected to be more costly than inconsistent choice patterns, are ultimately determined by the distribution of preferences and stochastic parameters in the sample.
To analyze how the welfare characterizations change as the distribution of preferences change in the sample, we could repeat the computational exercise that \DIFdelbegin \DIFdel{lead }\DIFdelend \DIFaddbegin \DIFadd{led }\DIFaddend to Table (\ref{tb:TopTenEUT}) for a few different distributions and discuss implications pattern by pattern.
This \DIFaddbegin \DIFadd{exercise}\DIFaddend , however, \DIFdelbegin \DIFdel{would be tedious}\DIFdelend \DIFaddbegin \DIFadd{will produce data only for the populations chosen, and will be less informative about how expectations of welfare change as the population changes}\DIFaddend .
Instead, it will be useful to define a few \DIFdelbegin \DIFdel{sample-level metrics instead}\DIFdelend \DIFaddbegin \DIFadd{population-level metrics that look at the data at the aggregate level}\DIFaddend .
For instance, for each $y \times T$ choice pattern, we can weigh the expected welfare \DIFdelbegin \DIFdel{proportion }\DIFdelend \DIFaddbegin \DIFadd{efficiency }\DIFaddend resulting from equation (\DIFdelbegin \DIFdel{\ref{eq:EPWT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EWET}}\DIFaddend ) by the simulated likelihood resulting from equation (\DIFdelbegin \DIFdel{\ref{eq:SLnT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:SLnT}}\DIFaddend ) and then sum across all TT choice patterns to retrieve the sample expected welfare \DIFdelbegin \DIFdel{proportion}\DIFdelend \DIFaddbegin \DIFadd{efficiency}\DIFaddend :

\begin{equation}
	\DIFdelbegin %DIFDELCMD < \label{eq:EPWTT}
%DIFDELCMD < 	%%%
\DIFdelend \DIFaddbegin \label{eq3:EPWTT}
	\DIFaddend \E(\%W_T(\theta)) = \sum_{tt=1}^{TT} \mathit{SL}_{Ntt}(\theta) \times \E(\%W_{tt} | \theta)
\end{equation}

Similar expectations can be derived for any of the per-choice pattern statistics defined previously, but we will be paying particular interest to the statistics derived from equations (\DIFdelbegin \DIFdel{\ref{eq:EMt}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EMt}}\DIFaddend ), and (\DIFdelbegin \DIFdel{\ref{eq:PE}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:PE}}\DIFaddend ) where $e=0$.
We are not limited to looking at expectations however, we can utilize equation (\DIFdelbegin \DIFdel{\ref{eq:EPWTT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EPWTT}}\DIFaddend ) to derive higher moments of these statistics, such as the variance:

\begin{equation}
	\DIFdelbegin %DIFDELCMD < \label{eq:VPWTT}
%DIFDELCMD < 	%%%
\DIFdelend \DIFaddbegin \label{eq3:VPWTT}
	\DIFaddend \Var(\%W_T(\theta)) = \sum_{tt=1}^{TT} \mathit{SL}_{Ntt}(\theta) \times \left[ \E(\%W_{tt} | \theta) - \E(\%W_T | \theta) \right]^2
\end{equation}

Having the means and variances of the statistics described allows us to make high-level inferences about the welfare implications of an instrument like the HL-MPL on different populations for a given stochastic model.
That is, we can contribute to the answer of our primary question of \enquote{what are the welfare implications of stochastic models} by solving equations (\DIFdelbegin \DIFdel{\ref{eq:EPWTT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EPWTT}}\DIFaddend ) and (\DIFdelbegin \DIFdel{\ref{eq:VPWTT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:VPWTT}}\DIFaddend ) for various values of $\theta$ and relating the elements of $\theta$ to these results.
We can substitute any  $y \times T$ statistic from derived from equations (\DIFdelbegin \DIFdel{\ref{eq:EMt}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EMt}}\DIFaddend ), (\DIFdelbegin \DIFdel{\ref{eq:PE}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:PE}}\DIFaddend ), (\DIFdelbegin \DIFdel{\ref{eq:EPWT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EWET}}\DIFaddend ), and (\DIFdelbegin \DIFdel{\ref{eq:EPWTe}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EPWTe}}\DIFaddend ) in place of $\%W_T$ in equations (\DIFdelbegin \DIFdel{\ref{eq:EPWTT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EPWTT}}\DIFaddend ) and (\DIFdelbegin \DIFdel{\ref{eq:VPWTT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:VPWTT}}\DIFaddend ) to describe these statistics on a population by population basis.

While equations (\DIFdelbegin \DIFdel{\ref{eq:EPWTT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EPWTT}}\DIFaddend ) and (\DIFdelbegin \DIFdel{\ref{eq:VPWTT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:VPWTT}}\DIFaddend ) may in fact have analytical solutions to determine these relationships, meaning we could attempt to solve for the partial derivative of equations (\DIFdelbegin \DIFdel{\ref{eq:EPWTT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EPWTT}}\DIFaddend ) and (\DIFdelbegin \DIFdel{\ref{eq:VPWTT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:VPWTT}}\DIFaddend ) with respect to each element of $\theta$, any analytical solution will be unique with respect to so many idiosyncratic factors that this becomes unfeasible, and potentially uninformative.
These factors include:
\begin{itemize}
 \setlength\itemsep{-.25em}
	\item The stochastic model
	\item The utility model
	\item The location, dispersion and shape of the joint distribution governing the complete stochastic specification
	\item The number of $H$ draws used to simulate the probabilities
	\item The base prime number used for the Halton sequences
	\item The specific tasks faced by the sample population
\end{itemize}

Given these limitations, instead we will examine the relationship of the parameters making up the stochastic specification\DIFaddbegin \DIFadd{, i.e. the elements of $\theta$, }\DIFaddend with the associated results of equations (\DIFdelbegin \DIFdel{\ref{eq:EPWTT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EPWTT}}\DIFaddend ) and (\DIFdelbegin \DIFdel{\ref{eq:VPWTT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:VPWTT}}\DIFaddend ) visually and with the use of locally weighted polynomial regression (LOESS) as originally developed by Cleveland, Grosse, Shyu, Chambers \& Hastie (1992).
We will examine two types of populations, both entirely composed of EUT agents.
The first type has preference parameters that are Normally distributed, while the second type will have Logit-Normal distributed preferences.
For each population type, we generate 500,000 unique population parameter sets, $\theta_i$, the elements of which are assumed to be uncorrelated, and solve equations (\DIFdelbegin \DIFdel{\ref{eq:EPWTT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EPWTT}}\DIFaddend ) and (\DIFdelbegin \DIFdel{\ref{eq:VPWTT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:VPWTT}}\DIFaddend ) for the statistics derived in equations (\DIFdelbegin \DIFdel{\ref{eq:EMt}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EMt}}\DIFaddend ), (\DIFdelbegin \DIFdel{\ref{eq:PE}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:PE}}\DIFaddend ) and (\DIFdelbegin \DIFdel{\ref{eq:EPWT}}\DIFdelend \DIFaddbegin \DIFadd{\ref{eq3:EWET}}\DIFaddend ) with $e=0$ and with each equation solved with $H=10,000$.

\DIFdelbegin \subsubsection{\DIFdel{EUT Populations with Normally Distributed Preferences}}
%DIFAUXCMD
\addtocounter{subsubsection}{-1}%DIFAUXCMD
\DIFdelend \DIFaddbegin \subsection{\DIFadd{EUT Populations with Normally Distributed Preferences}}
\DIFaddend 

We begin our discussion with an example utilizing normally distributed preferences and gamma distributed stochastic errors.
Thus, each $\theta_i$ is comprised of 4 elements: the mean of the CRRA parameter and the Lambda term, $\mu_r$ and $\mu_\lambda$, and standard deviation of the CRRA parameter and the Lambda term, $\sigma_r$ and $\sigma_\lambda$. Each of the candidate $\theta_i$ vectors was randomly drawn from a joint uniform distribution of these elements.
The bounds of the marginal distributions of these elements are as follows: $\mu_r \in [-1.9 , 1.55 ]$ , $\sigma_r \in [0 , 1]$ , $\mu_\lambda \in [.05 , 2.25]$ , $\sigma_\lambda \in [.01 , .75]$. 
These bounds are almost arbitrary; the bounds for $\mu_r$ were chosen to be just outside the indifference bounds of the HL instrument, but the remaining marginal distributions were chosen to be broad enough to provide some interesting patterns.

This exercise results in 8 statistics for each $\theta_i$: the means and variances of the expected proportion of welfare to the maximum attainable welfare, the expected welfare surplus, the expected number of choice errors, and the expected proportion of agents who make no errors.
Each statistic will be plotted against the 4 elements of $\theta_i$.
The result is 32 plots of the raw data and 32 charts of the LOESS lines associated with the raw data plots.
All LOESS lines are plotted along with 95\% confidence intervals in shaded gray.

Each plot and chart also attempts to give information about another parameter not plotted on the $x$ or $y$ axes by color coding the plotted data with respect to different values of this \enquote{z} parameter.
For $\mu_r$ this \enquote{z} parameter is $\sigma_r$, for $\sigma_r$ it is $\mu_r$, for $\mu_\lambda$ it is $\sigma_\lambda$ and for $\sigma_\lambda$ it is $\mu_\lambda$.
For all of the charts, the \enquote{z} parameter is split into quartiles and for the LOESS line charts, LOESS lines are calculated for the \enquote{x} and \enquote{y} parameter values that belong to each quartile.
Additionally, in the raw data plots, each point has been given a large degree of transparency.
This means that the density of points in the plot is represented by the density of color in the plot.

We will examine the LOESS line charts of these data with the raw data plots included in Appendix A.
First we will discuss the effect on welfare expectations of the parameters governing the stochastic model, and then discuss the parameters governing the utility model.
Thus, we will first be looking at Figures (\ref{fig:S-Wel-um}), (\ref{fig:S-Err-um}), (\ref{fig:S-Wel-us}) and (\ref{fig:S-Err-us}).
Figures (\ref{fig:S-Wel-um}) and (\ref{fig:S-Err-um}) demonstrate the effect of the mean of the distribution of the lambda term on welfare and the error frequencies, while Figures (\ref{fig:S-Wel-us}) and (\ref{fig:S-Err-us}) demonstrate the effect of the standard deviation of the lambda term on the same statistics.

The results of the plots of stochastic model parameters are mostly intuitive and unsurprising.
Looking at Figures (\ref{fig:S-Wel-um}) and (\ref{fig:S-Err-um}), as the mean of the distribution increases, the expected welfare and expected proportion of 0 error choice patterns monotonically decreases, while the expected number of choice errors monotonically increases.
Because lambda is distributed with a gamma distribution, for any given mean, a higher standard deviation implies that the mass of the distribution shifts closer towards $0$.
Thus, it is unsurprising that those populations with high standard deviations of lambda tend to exhibit choice patterns with lower expected choice errors and greater expected proportions of no error choice patterns.
This is because for any given choice problem, a lower value of lambda implies a lower probability of committing a choice error.{\footnotemark}
This directly translates into greater expected welfare than those populations with lower standard deviations holding the mean constant.

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	Since $\lambda$ is in the denominator of each exponential transformation, as $\lambda \to 0$, ${\Prob}(y_t = j) \to 1$ for $j = 1$ and ${\Prob}(y_t = j) \to 0$ for $j\neq1$ regardless of the other parameters.
}

Looking at Figures (\ref{fig:S-Wel-us}) and (\ref{fig:S-Err-us}), we can see that $\sigma_\lambda$ is far less influential than the effect of $\mu_\lambda$.
In the (A) and (C) charts of Figure (\ref{fig:S-Wel-us}), the slopes of the LOESS lines are slightly positive, but mostly flat other than the line for the lowest quartile of $\mu_\lambda$.
In the (A) and (C) charts of Figure (\ref{fig:S-Err-us}), we see much of the same, mostly flat lines indicating very little variation across the parameter space.
Again the exception is the line for the lowest quartile of $\mu_\lambda$.
This should not be surprising given that the populations were generated with a CU stochastic model.
The third quartile of $\mu_\lambda$ begins at $1.15$, which means that majority of the mass of the distribution of lambda in any population will lie above 1 for any value of $\sigma_\lambda$ in the range explored.
At these high levels of lambda, most choice probabilities will converge to something close to $\Pr( y_t = j) \to 0.5$.
This leaves little room for variation in expected welfare or expected choice errors.

In contrast to the monotonic relations of the lambda distribution, the effect of the CRRA parameters on the expected welfare and expected error statistics displays influences of the idiosyncratic aspects of the HL instrument.
This is most apparent in the plots of $\mu_r$.
In interpreting these plots, it is important to keep in mind that the CRRA parameters used in each population are Normally distributed.
Thus, the mean of the distribution always represents the point of the distribution with the greatest density, with smaller standard deviations leading to greater concentration of the mass of the distribution around the mean and larger standard deviations leading to the reverse.

In Figures (\ref{fig:S-Wel-rm}) and (\ref{fig:S-Err-rm}), each tick mark on the x-axis represent the values of the CRRA parameter at which an agent would be indifferent between lotteries for some row of the HL instrument.
From left to right, the first tick mark corresponds to the value of the CRRA parameter that would make an agent indifferent between the lotteries in the first row of the instrument, the second tick mark corresponds the second row of the instrument, and so on.
There are only 9 ticks because the there does not exist any CRRA parameter which would set an agent to be indifferent between the lotteries in row 10 of the instrument.

We will begin by first discussing the effect of $\mu_r$ on choice errors as displayed in Figure (\ref{fig:S-Err-rm}).
Something that is immediately apparent is that the orange LOESS line, depicting populations with low standard deviations of CRRA parameters, is much more volatile than the other quartile lines.
Interestingly, the orange line dips downward in plots (B),(C) and (D) and peaks upward in plot (A) at the values of $\mu_r$ that correspond to the indifference values described previously.
From plots (A) and (C), we draw the conclusion that as the mass of the distribution of preferences grows around parameter values which correspond to values which imply indifference in a choice scenario, we will see an increase in the number of choice errors in the population.

In the case of the quartile described by the orange line, the idiosyncratic relationship between $\mu_r$ and the points that represent indifference also holds for the variance of expected choice errors, as depicted in plots (B) and (D) of Figure (\ref{fig:S-Err-rm}).
That is, the increase in the average number of expected errors at these points is largely driven by a sharp reduction in the probability of observing a choice pattern with few expected errors relative to the probability of observing a choice pattern with a large number of errors.{\footnotemark}

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	Because $\Pr(y_t=j) = \Pr(y_t=k) \forall j,k$ as $\lambda \to \infty$, the maximum expected number of errors that can ever be observed in a population is $\sum_{t=1}^T \frac{J_t -1}{J_t}$. 
	That is, since every option is given equal probability in the limit, and only one option is not an error, the sum of ratio of choice errors to options across all tasks is the maximum expected number of choice errors in the limit.
	The maximum in the case of the HL instrument where $J_t = 2 \ \forall t$ and $T=10$ is therefore 5.
}

The remainder of the quartiles however do not follow this general pattern of heightened influence around the indifference points.
Instead, for plots (B),(C) and (D) of Figure (\ref{fig:S-Err-rm}), the lines generally decrease until $\mu_r = 0.15$ and plot (A) increases until just about the same point.
This less volatile pattern is because the 3 highest quartiles all indicate populations with high standard deviations.
Consider the 3 upper quartile lines around $\mu_r = 0.15$.
The distances between this point and the two closest indifference points are $0.26$ and $0.29$.
The second lowest quartile's lower bound of $\sigma_r$ is $0.26$, which means that the density of the preference relation distribution at these points of indifference is much larger than for the lowest quartile, relatively.
It should be apparent from observing the lowest quartile line that as the density of the preference distribution increases around these points of indifference, the frequency of errors will increase.
We can attempt to see this more formally by creating a metric that characterizes how much the distribution of preferences \enquote{sits} on these points of indifference:
\begin{equation}
	\DIFdelbegin %DIFDELCMD < \label{eq:Dstat}
%DIFDELCMD < 	%%%
\DIFdelend \DIFaddbegin \label{eq3:Dstat}
	\DIFaddend D_j = \sum_r^R \frac{f_j(r)}{\max f_j(x)}
\end{equation}

\noindent where $f_j(r)$ is the density of the distribution of CRRA parameters for population $j$ at point $r$ and $R$ is the set of values for the CRRA parameters at which an economic agent would be indifferent between the two options in each choice problem.
The denominator of the ratio is the maximum density of the distribution $f(\cdot)$ for population $j$.
Since the CRRA parameters were distributed Normally, this value is always equivalent to the density at the mean, $\mu_r$.
The set of $R$ in for the HL instrument is:
\begin{equation}
	R \equiv \{-1.71, -0.95, -0.49, -0.14, 0.15, 0.41, 0.68, 0.97, 1.37\}
\end{equation}

We evaluate the metric from equation (73) against the 8 statistics utilized in Figures (\ref{fig:S-Wel-rm}) through (\ref{fig:S-Err-us}).
The raw plots of this data are provided in the Appendix, and the LOESS Figures will be discussed presently.
Since it can be seen in Figures (\ref{fig:S-Wel-um}) and (\ref{fig:S-Err-um}) that the effect of the $\mu_\lambda$ term asymptotes rapidly as $\mu_\lambda > 1$, we restrict our plots to populations for which $\mu_\lambda < 1$.
This leaves us with about 150k observations.
These 150k observations are first split into deciles of $\mu_\lambda$ and then the LOESS lines are calculated for each decile.
This splitting of the data helps to make clear the large effect of the stochastic elements on the statistics explored and also the large amount of heterogeneity in the effect of preference parameters caused by the stochastic parameters.

The metric developed in equation (73) is not perfect, we should expect to see clumping of data points around 0 and 1 where populations will be wholly sitting on one point or wholly between points, but it does provide a generally good description of the phenomenon we are concerned with.
Looking at Figure (\ref{fig:D-Wel-smooth}), plots (A) and (C), we can confirm what was suspected to be driving the shape of the plots in Figure (\ref{fig:S-Err-rm}).
As $D$ increases, and more of the density of the CRRA distribution is shifted onto the points describing indifference, the greater the expected number of errors we should observe.

This effect is remarkably monotonic across every decile of $\mu_\lambda$, though the effect is strongest for lower deciles.
What should be no surprise is that the highest 3 deciles of $\mu_\lambda$ effectively expect $0\%$ of the populations considered to produce choice patterns with no choice errors, as can be seen in plot (C).
The variance statistics in plots (B) and (D) are generally monotonic, but not universally so.
In general, the variance in the number of expected errors across populations tends to decrease as $D$ increases.
This is in line with the populations becoming increasingly error prone.

In Figure (\ref{fig:D-Err-smooth}) we see the story of Figure (\ref{fig:D-Wel-smooth}) interpreted into welfare, but with an interesting and important difference: the expected welfare metrics in plots (A) and (C) are effectively equal around $D=0$ and $D=1$.
There doesn't exist an equality in the error metrics around these values of $D$ in Figure (\ref{fig:D-Wel-smooth}), nor should there be.
$D=0$ corresponds to populations which have a $\mu_r$ and $\sigma_r$ such that the entire population sits between the indifference points in $R$.
$D=1$ will generally{\footnotemark} represent the opposite; such a population will have a $\mu_r$ and $\sigma_r$ such that the entire population sits on top of one of the indifference points in $R$.
If the entire population sits far from an indifference point, holding the stochastic element constant, we expect there to be fewer errors compared to a population that sits on top of an indifference point because the average agent will not be close to indifference for the lottery pair in question.
But, this is also precisely why the welfare metrics are close to equivalent: if a population sits on an indifference point, it means that agents are mostly indifferent between the options in the lottery pair, and therefore any errors made for this lottery pair will be relatively un-costly in terms of welfare.

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	Generally because there are multiple ways to get $D=1$. A population with $\mu_r$ close to one and a $\sigma_r$ such that there is some density on $r_j \in R \ \mathit{s.t.} \ i \neq j$ can potentially make $D \to 1$.
	However, $\mu_r \to r_j \in R$ and $\sigma_r \to 0$ is the most frequent scenario.
}

Other than the particular case where $D=0$ and $D=1$, in Figure (\ref{fig:D-Err-smooth}) we see the general trend that we might expect from looking at Figure (\ref{fig:D-Wel-smooth}): as the $D$ metric increases and the relative density of the CRRA distribution increases around points of indifference, expected welfare decreases monotonically.
This is because other than the case of $D=1$, where errors should be relatively frequent but not costly, an increasing $D$ not only means that a greater proportion of agents lie on the indifference points, but also around it.
It is this greater proportion of agents lying sufficiently near an indifference point to make an error relatively likely, but sufficiently far to make it relatively costly which drives down expected welfare.
Similar to what was seen in Figure (\ref{fig:D-Wel-smooth}), in Figure (\ref{fig:D-Err-smooth}) we see that the effect of $D$ is stronger with populations with $\mu_\lambda$ in the lower deciles and weakest with populations with $\mu_\lambda$ in the higher deciles.

What is also clear from Figures (\ref{fig:D-Wel-smooth}) and (\ref{fig:D-Err-smooth}) is that the preference aspect of the utility model, represented by $D$, contributes far less to expected choice errors and, more importantly, to expected welfare than is contributed by the stochastic aspects of the model.
Looking at the lowest decile lines in Figures (\ref{fig:D-Wel-smooth}) and (\ref{fig:D-Err-smooth}), we can see that a relatively large increase in $D$ is needed to cause the same effect as moving to the next lowest decile.
Comparing the lowest decile with the highest decile reveals tremendous changes in expected errors and expected welfare while holding $D$ constant for the populations analyzed.

\DIFdelbegin \subsubsection{\DIFdel{EUT Populations with Logit-Normal Distributed Preferences}}
%DIFAUXCMD
\addtocounter{subsubsection}{-1}%DIFAUXCMD
\DIFdelend %DIF > \subsection{EUT Populations with Logit-Normal Distributed Preferences}
%DIF > 
%DIF > In the previous subsection, we discussed the expected welfare outcomes of populations with normally distributed preferences and gamma distributed stochastic errors faced with the HL-MPL.
%DIF > We now turn our attention to populations with Logit-Normal distributed preferences.
%DIF > However, rather than redo Figures (\ref{fig:S-Wel-rm}) through (\ref{fig:S-Err-us}) with the new populations, we will restrict this analysis to re-examining the D statistic of equation (\ref{eq3:Dstat}) and Figures (\ref{fig:D-Wel-smooth}) and (\ref{fig:D-Err-smooth}).
%DIF > 
%DIF > The Logit-Normal distribution is defined as a Logit transformation of a Normal distribution.
%DIF > \begin{align}
%DIF > 	\begin{split}
%DIF > 		X \sim \mathcal{N}(\mu,\sigma)\\
%DIF > 		Y = \frac{\exp(X)}{1 + \exp(X)}
%DIF > 	\end{split}
%DIF > \end{align}
%DIF > 
%DIF > \noindent where $Y$ is distributed Logit-Normally.
%DIF > One of the benefits of this distribution is no extra parameters are needed in comparison to a standard normal distribution.
%DIF > A minor drawback of this distribution is that it is bounded between $[0,1]$, but this is easily rectified by \enquote{scaling} and \enquote{shifting} the distribution.
%DIF > For our analysis, we will scale every distribution by a fixed constant of $3.45$ and every the distribution by a fixed constant of $-1.9$.
%DIF > This will result in every distribution being bounded between $[-1.9,1.55]$, just outside of the lower and upper indifference boundaries of the HL-MPL.
%DIF > A somewhat 

\DIFdelbegin \DIFdel{In the previous subsection, we discussed the expected welfare outcomes of populations with normally distributed preferences and gamma distributed stochastic errors faced with the HL-MPL.
We now turn our attention to populations with Logit-Normal distributed preferences.
However, rather than redo Figures (\ref{fig:S-Wel-rm}) through (\ref{fig:S-Err-us}) with the new populations, we will restrict this analysis to re-examining the D statistic of equation (\ref{eq:Dstat}) and Figures (\ref{fig:D-Wel-smooth}) and (\ref{fig:D-Err-smooth}).
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{The Logit-Normal distribution is defined as a Logit transformation of a Normal distribution.
}\begin{align*}
	\DIFdel{\begin{split}
		X \sim \mathcal{N}(\mu,\sigma)\\
		Y = \frac{\exp(X)}{1 + \exp(X)}
	\end{split}
}\end{align*}
%DIFAUXCMD
%DIFDELCMD < 

%DIFDELCMD < \noindent %%%
\DIFdel{where $Y$ is distributed Logit-Normally.
One of the benefits of this distribution is no extra parameters are needed in comparison to a standard normal distribution.
A minor drawback of this distribution is that it is bounded between $[0,1]$, but this is easily rectified by }%DIFDELCMD < \enquote{scaling} %%%
\DIFdel{and }%DIFDELCMD < \enquote{shifting} %%%
\DIFdel{the distribution.
For our analysis, we will scale every distribution by a fixed constant of $3.45$ and every the distribution by a fixed constant of $-1.9$.
This will result in every distribution being bounded between $[-1.9,1.55]$, just outside of the lower and upper indifference boundaries of the HL-MPL.
A somewhat 
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend The general analysis of the population level data reveals several somewhat expected results, and several somewhat unexpected results.
Firstly it is clear, and unsurprising, that the means of both the CRRA and Lambda distributions individually drive a great deal of the variation in the number of expected choice errors and the expected welfare of a population.
Specifically that the effect of the mean of Lambda on the expected number of choice errors was large should have been obvious \textit{a priori}.
The \DIFdelbegin \DIFdel{Lambda }\DIFdelend \DIFaddbegin \DIFadd{$\lambda$ }\DIFaddend parameter directly influences choice probabilities regardless of the underlying instrument.
Similarly, that populations with CRRA parameters tightly distributed around a point of indifference would have greater expected number of choice errors was intuitive.
That larger numbers of expected choice errors generally lead to lower welfare was already clear from previous analyses.

Somewhat more surprising is just how dominant the stochastic elements of utility functions are over the preference aspects when deriving expectations around welfare.
Figures (\ref{fig:D-Wel-smooth}) and (\ref{fig:D-Err-smooth}) make clear, despite the potential flaws with the $D$ metric, that the way the preference parameters interact with the idiosyncratic aspects of the instrument matter a great deal, but the stochastic parameters unambiguously matter more.
This result should be important to economists and policy makers concerned with estimating the potential welfare implications of new policy instruments.

\DIFdelbegin \subsection{\DIFdel{Summary of Analyses}}
%DIFAUXCMD
\addtocounter{subsection}{-1}%DIFAUXCMD
\DIFdelend \DIFaddbegin \section{\DIFadd{Summary of Analyses}}
\DIFaddend 

We describe the current econometric toolkit used to estimate parameters of utility models given choice data and, by extension of a normatively coherent stochastic model, the welfare implications of these parameters.
The only methods considered involved the structural estimation of a utility function through maximum likelihood estimation.
This toolkit progressed from utilizing pooled data across an entire sample to estimate parameters for a single representative agent, to controlling for observable heterogeneity within the sample, and, with the use of mixture models, a limited amount of unobservable heterogeneity.
These methods, however, still pool data and produce estimates that are effectively estimates of means of the distributions of parameters that characterize a sample of agents, and provide little to no information about the shapes of these distributions.
By extension, little could be said about the welfare of any given agent from within the sample.

To improve the potential for making accurate individual level welfare assessments, economists estimated the same stochastic models on \enquote{large} amounts of data collected from individual agents.
As was shown in the SMP thought experiment in the previous chapter, there is nothing normatively incorrect about estimating models at the individual level, and with a sufficient number of observations per subject, such estimation can be statistically very powerful.
\DIFdelbegin \DIFdel{Individual level estimates of utility functions however have rarely been utilized to conduct welfare evaluation.
}\DIFdelend \DIFaddbegin \DIFadd{\textcite{Harrison2016} uses individual-level estimation to estimate the welfare surplus of a decision to purchase an insurance product.
}\DIFaddend 

\DIFdelbegin \DIFdel{This method is not without drawbacks.
Often, economists who estimate individual level parameters compile the individual estimates to describe the sample distribution of parameters.
Each of these individual estimates, however, has a standard error associated with it which makes it difficult to aggregate these estimates into distributional data.
A more practical concern is that occasionally estimation of a utility model on individual level data is made impossible by the particular choices made by the subjects.
Choice patterns that deviate significantly from deterministic theories of utility become cause maximum likelihood routines to fail to converge on parameter sets.
}\DIFdelend %DIF > This method is not without drawbacks.
%DIF > Often, economists who estimate individual level parameters compile the individual estimates to describe the sample distribution of parameters.
%DIF > Each of these individual estimates, however, has a standard error associated with it which makes it difficult to aggregate these estimates into distributional data.
%DIF > A more practical concern is that occasionally estimation of a utility model on individual level data is made impossible by the particular choices made by the subjects.
%DIF > Choice patterns that deviate significantly from deterministic theories of utility become cause maximum likelihood routines to fail to converge on parameter sets.

A concern we raise about this method is the drawback of discarding sample level information.
This concern is heightened by the stochastic component of choice.
We show that certain choices made by subjects are better characterized as \enquote{choice errors} which describe the subject as failing to accumulate a certain amount of welfare.
Every stochastic model puts a positive probability on such choice errors.
The risk this poses to individual level estimation is that one or more choice errors will be made by an individual in such a way as to cause a misidentification of the utility model.
This poses a potential problem for economists and policy makers hoping to understand the welfare implications of institutional instruments.

%DIF > To address this concern, we propose estimation of utility functions through maximum simulated likelihood methods (MSL) to recover estimates of the distribution of preferences across the whole sample, as opposed to recovering just the mean with other pooled estimation techniques and discarding sample level information with individual estimation.
To address this concern, we propose \DIFdelbegin \DIFdel{estimation of utility functions through maximum simulated likelihood methods (MSL) to recover }\DIFdelend \DIFaddbegin \DIFadd{that }\DIFaddend estimates of the distribution of preferences across the whole sample \DIFdelbegin \DIFdel{, as opposed to recovering just the mean with other pooled estimation techniques and discarding sample level information with individual estimation}\DIFdelend \DIFaddbegin \DIFadd{should be recovered, potentially with maximum simulated likelihood (MSL), and utilized in welfare surplus calculations}\DIFaddend .
With the distributional characteristics of the utility model in hand, \DIFdelbegin \DIFdel{the }\DIFdelend \DIFaddbegin \DIFadd{unconditional }\DIFaddend welfare implications of any given choice pattern \DIFdelbegin \DIFdel{made by an individual }\DIFdelend can be analyzed.

We test this methodology through simulation methods by first specifying a hypothetical population of agents characterized by a joint distribution of utility and stochastic parameters, and then simulating choice data for this population utilizing the instrument used in the popular Holt \& Laury (2002) (HL) experiment.
\DIFdelbegin \DIFdel{For the particular population explored, }\DIFdelend \DIFaddbegin \DIFadd{Our methodology allows us to calculate the unconditional likelihood of any given choice pattern, how many choice errors we expect to exist in the pattern, and }\DIFaddend the \DIFdelbegin \DIFdel{results of this analysis confirmed concerns about individual level estimation.
For particular populations, there is a great risk of misidentifying individual subject's utility functions, and thus mis-characterizing the welfare implications of those subject's choices}\DIFdelend \DIFaddbegin \DIFadd{welfare consequences thereof}\DIFaddend .
We see \DIFdelbegin \DIFdel{this demonstrated in Table (\ref{tb:TopTenEUT} ) and Figure (\ref{fig:ConFOSD} ).
The choice patternswith lower expected likelihood of being observed are the most likely to misidentify the preferences of the subjects that produced them, and this misidentification leads to a large mischaracterization of the welfare implications of these }\DIFdelend \DIFaddbegin \DIFadd{in Table \ref{tb:TopTenEUT} and Figure \ref{fig:ConFOSD} that many choices that are consistent with EUT provide less welfare surplus than apparently inconsistent choice patterns.
In these cases, knowledge of the distribution of preferences in a population a subject is sampled from provides us with insight about the subject's possible welfare surplus that may have been lost if the }\DIFaddend subject's choices \DIFdelbegin \DIFdel{.
The most common misidentification however will occur from choice patterns that are most likely to be observed, but the welfare implications of this misidentification are relatively small.
}\DIFdelend \DIFaddbegin \DIFadd{were viewed in isolation.
}\DIFaddend 

%DIF > For the particular population explored, the results of this analysis confirmed concerns about individual level estimation.
%DIF > For particular populations, there is a great risk of misidentifying individual subject's utility functions, and thus mis-characterizing the welfare implications of those subject's choices.
%DIF > The choice patterns with lower expected likelihood of being observed are the most likely to misidentify the preferences of the subjects that produced them, and this misidentification leads to a large mischaracterization of the welfare implications of these subject's choices.
%DIF > The most common misidentification however will occur from choice patterns that are most likely to be observed, but the welfare implications of this misidentification are relatively small.
\DIFaddbegin 

\DIFaddend The analysis of the individual population we chose left open the question of how much do population level characteristics matter when it comes to describing the welfare of the population, given an instrument.
To explore this question 350k populations were simulated and several metrics describing welfare and choice errors were calculated for each population.
Each parameter that defined the populations was then plotted against these metrics and a visual analyses of the data was conducted.
We discovered, unsurprisingly, that the means of the marginal distributions that made up each population's joint distribution were of greatest importance in describing the welfare of populations.
Also, having controlled for the entire marginal distribution of the preference parameter and the idiosyncratic aspects of the instrument, we discovered that the stochastic aspect of the utility model is the dominant driver of expected welfare.
This result was somewhat surprising, though not entirely unintuitive.

\DIFdelbegin \subsection{\DIFdel{Concluding Remarks}}
%DIFAUXCMD
\addtocounter{subsection}{-1}%DIFAUXCMD
\DIFdelend %DIF > \section{Concluding Remarks}

\DIFdelbegin \DIFdel{The analyses conducted in this chapter provide several useful results for econometricians, experimenters, and policy makers.
Firstly, there exist stochastic models of choice which arguably describe choice probabilities well, but which are unable to provide useful statements about the accumulation of economic welfare, and thus should not be considered when conducting analyses of experimental choice data.
Secondly, experimental instruments intended to produce choice data for estimating individual level preference may provide data that leads to the misidentification of these preference on the individual level by not adequately incorporating sample level information.
}\DIFdelend %DIF > The analyses conducted in this chapter provide several useful results for econometricians, experimenters, and policy makers.
%DIF > We demonstrate a method for calculating the unconditional welfare consequences of discrete economic choices made by individual agents.
%DIF > We show that these unconditional metrics lead to the somewhat unintuitive conclusion that choice patterns that are apparently inconsistent with either EUT or RDU can in fact result in greater welfare surplus for an individual than apparently inconsistent choice patterns.

\DIFdelbegin \DIFdel{It is almost certainty the case that these same data can be analyzed at the sample level using the MSL methodology described in this chapter to produce potentially more accurate descriptions of the economic welfare of the subjects.
Thus, the large existing body of experimental data can likely be reexamined using the MSL method discussed in this chapter.
What appears likely, however, is that there may need to be a shift in economic experiments away from presenting subjects with ever more choice problems in the hope of gaining more accurate individual level estimates of utility parameters, and towards presenting subjects with smaller instruments and collecting data from larger samples.
What constitutes a sufficiently powerful instrument and what is the smallest sufficiently large sample to make accurate characterizations of expected individual welfare are open questions at this point.
It does however seem plausible that these questions can in large part be answered through simulating choice data based on prior expectations of the distributions of utility function parameters and conducting power analyses on these data.
Power analyses of this kind are ever more feasible with modern computing power and statistical software, and yet are rarely performed either }\textit{\DIFdel{a priori}} %DIFAUXCMD
\DIFdel{or }\textit{\DIFdel{ex ante}}%DIFAUXCMD
\DIFdel{.
}\DIFdelend %DIF > Finally, given the strong effect of the stochastic elements of choice on the probability and magnitude of misidentifying utility structures and by extension welfare characterizations, this chapter reinforces the statement made more than 20 years ago by Hey \& Orme (1994 p.1322):
%DIF > \enquote{Perhaps we should now spend some time on thinking about the noise, rather than about even more alternatives to EU?}

\DIFdelbegin \DIFdel{Finally, given the strong effect of the stochastic elements of choice on the probability and magnitude of misidentifying utility structures and by extension welfare characterizations, this chapter reinforces the statement made more than 20 years ago by Hey \& Orme (1994 p.1322):
}%DIFDELCMD < \enquote{Perhaps we should now spend some time on thinking about the noise, rather than about even more alternatives to EU?}
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend \newpage

\DIFdelbegin \subsection{\DIFdel{Figures}}
%DIFAUXCMD
\addtocounter{subsection}{-1}%DIFAUXCMD
\DIFdelend \DIFaddbegin \section{\DIFadd{Figures}}
\DIFaddend 

\begin{figure}[hp!]
	\center
	\caption{Mean of CRRA against Welfare}
	\includegraphics[height=.28\paperheight]{figures/AggPlots/S-Wel-rm.jpg}
	\label{fig:S-Wel-rm}
\end{figure}

\begin{figure}[hp!]
	\center
	\caption{Mean of CRRA against Errors}
	\includegraphics[height=.29\paperheight]{figures/AggPlots/S-Err-rm.jpg}
	\label{fig:S-Err-rm}
\end{figure}

\begin{figure}[hp!]
	\center
	\caption{Standard Deviation of CRRA against Welfare}
	\includegraphics[height=.3\paperheight]{figures/AggPlots/S-Wel-rs.jpg}
	\label{fig:S-Wel-rs}
\end{figure}

\begin{figure}[hp!]
	\center
	\caption{Standard Deviation of CRRA against Errors}
	\includegraphics[height=.3\paperheight]{figures/AggPlots/S-Err-rs.jpg}
	\label{fig:S-Err-rs}
\end{figure}

\begin{figure}[hp!]
	\center
	\caption{Mean of Lambda against Welfare}
	\includegraphics[height=.3\paperheight]{figures/AggPlots/S-Wel-um.jpg}
	\label{fig:S-Wel-um}
\end{figure}

\begin{figure}[hp!]
	\center
	\caption{Mean of Lambda against Errors}
	\includegraphics[height=.3\paperheight]{figures/AggPlots/S-Err-um.jpg}
	\label{fig:S-Err-um}
\end{figure}

\begin{figure}[hp!]
	\center
	\caption{Standard Deviation of Lambda against Welfare}
	\includegraphics[height=.3\paperheight]{figures/AggPlots/S-Wel-us.jpg}
	\label{fig:S-Wel-us}
\end{figure}

\begin{figure}[hp!]
	\center
	\caption{Standard Deviation of Lambda against Errors}
	\includegraphics[height=.3\paperheight]{figures/AggPlots/S-Err-us.jpg}
	\label{fig:S-Err-us}
\end{figure}

\begin{figure}[hp!]
	\center
	\caption{D Statistic against Welfare}
	\includegraphics[height=.3\paperheight]{figures/AggPlots/S-Wel-D.jpg}
	\label{fig:D-Wel-smooth}
\end{figure}

\begin{figure}[hp!]
	\center
	\caption{D Statistic against Errors}
	\includegraphics[height=.3\paperheight]{figures/AggPlots/S-Err-D.jpg}
	\label{fig:D-Err-smooth}
\end{figure}

\newpage

\DIFdelbegin %DIFDELCMD < \printbibliography
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \DIFadd{\onlyinsubfile{
\newpage
\printbibliography[segment=3, heading=subbibliography]
}
}\DIFaddend 




\onehalfspacing
\setcounter{chapter}{3}

\chapter{Welfare From Experimental Instruments}

\lltoc % Table of contents only when locally compiled

In the previous chapter we proposed a method for assessing the welfare implications of choices made by subjects in incentivized environments.
This method differs from other proposed methods of welfare calculation in that rather than requiring an assumed set of utility parameters for the individual in question, it is necessary to assume some distribution of utility parameter sets from which the individual has been randomly sampled.
We suggested that failure to incorporate the distributional information of these utility parameter sets into the evaluation of welfare may result in a mischaracterization of welfare for some individuals.
This is because some individuals may make mistakes, or \enquote{choice errors}, when faced with a choice problem and select a choice which is not welfare maximal.
These errors may occur often enough and in such a manner that they result in a choice pattern that fits some utility function statistically better than the \enquote{true} utility function that the subject actually operates, and would likely reveal over a longer observation of choice patterns or with larger instruments.
Should fitted function and the \enquote{true} function differ enough in their utility parameters, the welfare characterizations resulting from the fitted function could be meaningfully different than the welfare characterizations that would result from the \enquote{true} function.

In this chapter, we will analyze two experimental instruments' ability to accurately recover the utility functions of agents faced with the instruments.
The analysis will focus firstly on the ability of the instrument to correctly classify an agent operating one of four different utility models, as is done in \textcite{Harrison2016}, and secondly on the welfare consequences of this characterization.
To begin this analysis, we will describe and replicate the classification and welfare calculation exercises of \textcite{Harrison2016}.
Next we will conduct a simulation analysis on the lottery instrument used in \textcite{Harrison2016} to determine the frequency of misclassification for each of the four models in question, and the welfare consequences thereof.
This analysis will then be repeated using the lottery instrument described in \textcite{Hey1994}.
For each instrument, a hypothetical population will be used to derive the conditional likelihood that an agent declared as operating a particular utility function actually operates the declared function.

\section{Estimating a Benchmark using \texorpdfstring{\textcite{Harrison2016}}{Harrison and Ng (2015)}}

\textcite{Harrison2016} report the results of an experiment intended to evaluate the welfare consequences of individuals' decisions to purchase insurance.
This is in part a response to the large literature cited by \textcite[1]{Harrison2016} which evaluates insurance on the basis of \enquote{take-up}: the rate at which individuals purchase insurance.
They argue that although a take-up metric can be transparent and easy to measure, it doesn't allow for statements about whether an individual \textit{should} have taken up the insurance product.
These are, however, precisely the kind of normative welfare statements that economists should be making about the economic choices of agents.
They are also the kind of normative welfare statements that can be made from estimating the utility functions of individuals and evaluating their choices with respect to these functions.


\textcite{Harrison2016} engage the problem of evaluating the welfare consequences of the decision to purchase insurance or not by conducting a 2 part experiment.
In the first part, each subject is presented with a battery of 80 lottery pairs and asked to select one lottery from each pair that will be played out for payment.
This part will be referred to as the \enquote{lottery task} throughout.
The responses of each subject to the lottery task are used to estimate utility functions for that individual.
In the second part, each subject is endowed with \money{20} and presented with 24 choices where they are asked to choose between a lottery which will result in a loss of \money{15} with some probability $p$ or no loss of the initial endowment with probability $(1-p)$, and a certain amount of money between \money{15.20} and \money{19.80}.
The choice of the certain amount of money is framed as the purchase of insurance against the risk of loss in the lottery option.
This part will be referred to as the \enquote{insurance task} throughout.
Both of these instruments are detailed in full in the Appendix.

For each individual, \textcite{Harrison2016} use the data recovered in the lottery task to estimate four models which can be described in the framework of Rank Dependent Utility (RDU) as first proposed by \textcite{Quiggin1982}:
\begin{equation}
	\label{eq4:RDU}
	RDU = \sum_{i=1}^{I} \left[ w_i(p) \times u(x_i) \right]
\end{equation}
\noindent where $i$ indexes the outcomes, $x_i$, from $\{1,\ldots,I\}$ with $i=1$ being the smallest outcome in the lottery and $i=I$ being the greatest outcome in the lottery, $u(\cdot)$ returns the utility of its argument, $w_i(\cdot)$ returns the decision weight applied to outcome $i$ given the distribution of probabilities in the lottery ranked by outcome, $p$.
The decision weight function, $w_i(\cdot)$, takes the form:
\begin{equation}
	\label{eq4:dweight}
	w_i(p) =
	\begin{cases}
		\omega\left(\displaystyle\sum_{j=i}^I p_j\right) - \omega\left(\displaystyle\sum_{k=i+1}^I p_k\right) & \text{for } i<I \\
		\omega(p_i) & \text{for } i = I
	\end{cases}
\end{equation}
\noindent where the probability weighting function, $\omega(\cdot)$, can take a variety of parametric or non-parametric forms.
\textcite{Harrison2016} estimate the four following probability weighting functions. The linear function:
\begin{equation}
	\label{eq4:pw:eut}
	\omega(p_i) = p_i
\end{equation}

\noindent The power function ($\mathit{RDU_{Pow}}$) used by \textcite{Quiggin1982}:
\begin{equation}
	\label{eq4:pw:pow}
	\omega(p_i)=p_i^\gamma
\end{equation}

\noindent where $\gamma > 0$. The \enquote{Inverse-S} shaped function ($\mathit{RDU_{Invs}}$) popularized by \textcite{Tversky1992}:
\begin{equation}
	\label{eq4:pw:inv}
	\omega(p_i) = \frac{p_i^\gamma}{\biggl(p_i^\gamma + {(1-p_i)}^\gamma\biggr)^{ \frac{1}{\gamma} } }
\end{equation}

\noindent where $\gamma > 0$. And the flexible function proposed by \textcite{Prelec1998} ($\mathit{RDU_{Prelec}}$):
\begin{equation}
	\label{eq4:pw:pre}
	\omega(p_i)=\exp(-\beta(-\ln(p_i))^\alpha)
\end{equation}
\noindent where $\alpha > 0$ and $\beta > 0$.

Note that the functional form of an RDU model with the linear probability weighting function in equation (\ref{eq4:pw:eut}) is equivalent to Expected Utility Theory (EUT), and will be referred to as EUT throughout the remainder of this text.
In all the remaining probability weighting functions, there exist values for the probability weighting parameters which allow $w_i(p) = p_i$, the special case of EUT.

For all four models, \textcite{Harrison2016} use the CRRA utility function defined below:
\begin{equation}
	\label{eq4:CRRA}
	u(x) = \frac{x^{(1-r)}}{(1-r)}
\end{equation}
\noindent where $r$ is the coefficient of relative risk aversion \parencite{Pratt1964}.

We will continue the notation used in chapters 2 and 3 to describe a choice scenario by a subject, but limit it to a binary choice between two options, $j$ and $k$.
In this framework a choice of option $j$ in task $t$ is indicated by the function $y_t = j$, where $y_t = 1 \geq^n y_t = 2$.
The values of $j$ and $k$ do not indicate the order or frame the options in task $t$ were presented to the subject, but rather the ordinal rank the subject's utility function assigns to the options, with 1 always being the option of greatest utility.
This notation is useful when describing the welfare consequences of choices, as will be seen below.

\textcite{Harrison2016} also use Contextual Utility (CU), as defined by \textcite{Wilcox2008}, as the stochastic model.
Thus for the models utilized, the probability that option $j$ is chosen is given by:
\begin{align}
	\label{eq4:RE.2}
	\begin{split}
		{\Prob}(y_t = j) &= {\Prob}\left(  \epsilon_t \geq \frac{1}{\lambda_n} \left[ G(\beta_n,X_{kt}) - G(\beta_n,X_{jt}) \right] \right)\\
		&= 1 - F\left( \dfrac{G(\beta_n,X_{kt}) - G(\beta_n,X_{jt})}{D(\beta_n,X_t)\lambda_n }  \right)
	\end{split}
\end{align}

\noindent where $\epsilon_t$ is a mean 0 error term, $F$ is a symmetric cumulative distribution function (cdf), meaning $1 - F(x)  = F(-x)$, $G(\cdot)$ is the RDU utility model that takes the parameters $\beta_n$ to calculate the utility of lottery $j$ or $k$ in task $t$ comprised of outcomes and probabilities $X_{jt}$, and $\lambda_n$ is a precision parameter.
The function $D(\cdot)$ separates contextual utility from a Strong Utility model:
\begin{align}
	\label{eq4:W.cu}
	\begin{split}
		&D(\beta_n,X_t) = \mathit{max}[u(x_{it})] - \mathit{min}[u(x_{it})]\\
		&\mathit{st.}\; w_i(x_{it}) \neq 0
	\end{split}
\end{align}

Usually, the Normal or Logistic cdf is chosen for $F$, and we will be employing the Logistic cdf for all calculations throughout this chapter.
Given that each choice considered in this chapter only involves two lottery options, we can define the probability of choosing option $j$ given a particular model, parameter set $\beta_n$, precision parameter $\lambda_n$, and outcomes and probabilities of option $j$, $X_{jt}$, as follows:
\begin{equation}
	\label{eq4:RE.f}
	{\Prob}(y_t=j) =\dfrac{\exp\!\left( \dfrac{ G(\beta_n,X_{jt}) }{ D(\beta_n,X_{t})\lambda_n }  \right)}{  \exp\!\left( \dfrac{ G(\beta_n,X_{jt}) }{ D(\beta_n,X_{t})\lambda_n }  \right) + \exp\!\left( \dfrac{ G(\beta_n,X_{kt}) }{ D(\beta_n,X_{t})\lambda_n }  \right)    }
\end{equation}

These choice probabilities in turn are logged and summed to produce a log-likelihood function for each of the four different models:
\begin{equation}
	\label{eq4:ll}
	\ensuremath{\mathit{LL_n}} = \sum_{t}^T \ln \left[ {\Prob}(y_t) \right]
\end{equation}

As a metric of welfare, \textcite{Harrison2016} primarily use the consumer surplus (CS) of each choice.
The CS of each choice is defined as the difference between the certainty equivalent ({\CE}) of the chosen option and the certainty equivalent of the unchosen option.
Since the CRRA utility function defined in equation (\ref{eq4:CRRA}) is used for all models discussed, we can define the {\CE} as follows:

\begin{align}
	\label{eq4:CEcalc}
	\begin{split}
		&\sum_{i=0}^{I-1} w_i(p) \frac{x_{ij}^{(1-r)}}{(1-r)} = \frac{ {\CE}_j^{(1-r)}}{(1-r)}\\
		&{\CE}_j =  \left( (1-r) \times \sum_{i=0}^{I-1} w_i(p) \frac{x_{ij}^{1-r}}{(1-r)} \right)^{ \displaystyle\nicefrac{1}{(1-r)} }
	\end{split}
\end{align}

\noindent and the welfare surplus metric derived from this {\CE} for any choice as:

\begin{equation}
	\label{eq4:wsurplus}
	\Delta W_{nt} =  {\CE}_{nyt} - {\CE}_{n1t}^Z
\end{equation}

\noindent and the accumulated welfare surplus as:

\begin{equation}
	\label{eq4:wsurplusT}
	\Delta W_{nT} = \sum_{t=1}^T \left( {\CE}_{nyt} - {\CE}_{n1t}^Z \right)
\end{equation}

\noindent where the $y$ subscript indicates the option chosen (either 1 or 2 in the binary scenario we consider here), and the $Z$ superscript indicates the remaining, unchosen options, of which the {\CE} with the greatest value, designated by the subscript 1, is considered the forgone opportunity.

\textcite[106]{Harrison2016} consider an additional metric of forgone welfare surplus as the difference between the maximal {\CE} for every choice and the {\CE} of the option actually chosen by the subject:
\begin{equation}
	\label{eq4:wforgone}
	\Delta F_{nt} = -1 \times \left( {\CE}_{n1t} - {\CE}_{nyt} \right)
\end{equation}

\noindent and the accumulated forgone welfare surplus:

\begin{equation}
	\label{eq4:wforgoneT}
	\Delta F_{nT} = \sum_{t=1}^T  -1 \times \left( {\CE}_{n1t} - {\CE}_{nyt} \right)
\end{equation}

\noindent With these metrics, the best possible value for any subject is 0, which would indicate that all choices made were optimal, whereas any positive value indicates the amount of welfare surplus forgone by the subject due to choice errors.
These metrics line up easily with the metrics defined in equations (\ref{eq4:wsurplus}) and (\ref{eq4:wsurplusT}), as should $y_t \neq 1$, ${\CE}_{n1t}^Z = {\CE}_{n1t}$.

\textcite{Harrison2016} estimate values of the CRRA utility parameter, $r$, the probability weighting parameters, $\gamma, \alpha, \beta$, and the stochastic parameter $\lambda$, for each of the models presented above via maximum likelihood estimation (MLE) using the choices made by the subjects in the lottery task.
\textcite[107,110]{Harrison2016} calculate the welfare consequences of the chocies made by each subject by using only the point estimates from the MLE, as well as a bootstrap method which incorporates the covariance matrix of the standard errors.

For the bootstrap method, a multivariate normal distribution of parameter sets is bootstrapped from the estimates using the point estimates of these parameters as the means of the marginal distributions, and the covariance matrix of standard errors used as the covariance matrix of standard deviations.
For each subject's parameter estimates 500 draws of parameter sets were taken, the welfare metrics calculated for each set of parameters, and then the values of the metrics averaged across the 500 draws.
Since the covariance matrix used in the bootstrap method draws parameters from the joint distribution with respect to their density in the joint distribution, only a simple average is needed.

The experimental subjects consisted of 111 undergraduate students enrolled in several different colleges at Georgia State University, USA.
All experimental sessions were conducted in 2014 at the ExCEN experimental lab of Georgia State University. 
Every subject recieved, and expected to recieve, a guarenteed \money{5} show up fee, but no specific information about the experiment or expected earnings was communicated to the subjects before the experiment \parencite[98]{Harrison2016}.
The full set of instructions delivered to the subjects is available in Appendix C of \textcite{Harrison2016}.

\subsection{Individual Level Estimation}

The authors of \textcite{Harrison2016} have provided us with the data and the code used to conduct the analysis and generate the various plots reported by \textcite{Harrison2016}.
\textcite{Harrison2016} use the popular statistical software Stata to conduct their analysis, and Stata's modified Newton-Rhapson (NR) algorithm to find the maximum likelihood estimates.
We, however, use the R statistical software, with the NR algorithm provided in the package \enquote{maxLik} to conduct our analysis throughout this chapter.
Both our approach and that of \textcite{Harrison2016} require \enquote{handwritten} likelihood functions due to the particular nature of recovering maximum likelihood estimates from non-linear structural models.
The handwritten program of \textcite{Harrison2016} is written in the Stata language, whereas our program is written in C++, and compiled and called by R.

For an in-depth discussion of how the NR algorithm finds the maximum of a function see \textcite[213-219]{Train2002}.
For our purposes, only a few key points about how the NR algorithm operates are useful to bear in mind.
Firstly, a maximum is declared when the gradient of the likelihood function approaches 0, and the matrix of second derivatives of the likelihood, the Hessian matrix, is negative definite.
These two conditions indicate that the likelihood function is locally concave at the point where these conditions hold (the Hessian condition), and that the point exists at a maximum of this local concavity (the gradient condition).
These conditions are shared by other \enquote{gradient-based} optimizers subject as the Boyden-Fletcher-Goldfarb-Shanno (BFGS) or Berndt-Hall-Hall-Hausman (BHHH) algorithms.

Secondly, the NR and other gradient-based algorithms are not \enquote{global} optimizers.
If the likelihood function is not globally concave, the NR optimizer is not guaranteed to reach a global optimum from any starting point.
For instance, if the log-likelihood function is highly bimodal and the initial values for the optimizer are near the smaller mode, the NR optimizer may converge on the maximum of the concave portion of the smaller mode.
The NR algorithm attempts to mitigate situations like this{\footnotemark}, but ultimately the NR algorithm is only guaranteed to find a global maximum if the likelihood function is globally concave \parencite[218]{Train2002}.
We do not, however, expect the likelihood functions applied to the data we recover from experiments to be globally concave \parencite[227]{Train2002}.
If we employed a linear-in-parameters utility function, as opposed to the non-linear functions we actually employ, we would have a globally concave log-likelihood function.

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	See \textcite[216]{Train2002}, for specifics about how NR attempts to mitigate this problem.
	Stata's \enquote{ml search} command additionally tries to mitigate this problem by initially searching for parameter sets that are near a global maximum, and using these found parameter sets as initial values for the NR algorithm.
}

% The Craft of Economics
% Edward E. Leamer
% p 25 -  Dissucesses the idea that two different statistical packages producing different results being shocking as "Economic Fiction"

Numerical optimization also takes place on a physical machine, and the limits of how computers manipulate and store numbers will also affect the result of an optimization exercise.
\textcite{Gould2006} discusses how real numbers are stored and processed in modern computers and how differences in the order of operations can lead to differences in how a computer stores a value.
Again, only a few points here are necessary to bear in mind.
Firstly, there is a limit at which a computer can effectively distinguish between two different real numbers.
Of particular interest to us is the limit at which a computer can distinguish between a small number and 0, as one of the conditions of finding an optimum was that the gradient must be equal to 0.{\footnotemark}
Indeed, even for peaked likelihood functions, there can be (and must be for continuous parameter sets), ranges of parameters at which the gradient is indistinguishable from 0.
Because of this, in the actual operation of an optimizer, a threshold is stipulated below which the gradient is considered equivalent to 0, and a (potentially different) threshold is stipulated below which the Hessian is considered negative definite.
These thresholds are very small numbers, but usually not the smallest numbers that a computer can distinguish from 0.
The issue with how computers store and manipulate numerical values is of course a very general issue and not unique to the NR algorithm, or the R or Stata statistical software.
Similar issues would arise for different optimization algorithms, such as BFGS or BHHH algorithms, though the differences between these algorithms and NR imply different issues as well.{\footnotemark}

\begin{lrbox}{\LstBoxR}
\begin{lstlisting}
.Machine$double.xmin == 0
FALSE
z <- .Machine$double.xmin + 0.1
z - 0.01 == 0
TRUE
\end{lstlisting}
\end{lrbox}

\begin{lrbox}{\LstBoxStata}
\begin{lstlisting}[language=bash]
di smallestdouble() == 0
0
scalar z = smallestdouble() + 0.1
di z - 0.1 == 0
1
\end{lstlisting}
\end{lrbox}

\addtocounter{footnote}{-2}
\stepcounter{footnote}\footnotetext{
For instance, in R, the smallest positive number recognized as different from 0 is given by the value of \texttt{.Machine\$double.xmin}, and in Stata is given by the value of \texttt{smallestdouble()}.
After having stored these values in either R or Stata, and then operating on them, these smallest values are then lost:

\noindent For R:

\usebox{\LstBoxR}

\noindent For Stata:

\usebox{\LstBoxStata}

The numerical precision is lost after the initial addition operation, and now the computer cannot distinguish between 0 and the operated on value, even though it is mathematically different from 0.
}
\stepcounter{footnote}\footnotetext{
	Again, \textcite[220-225]{Train2002} is a useful reference to understand how these algorithms operate.
}

What is important to note about these issues is that different optimization algorithms, initial values given to the optimizer, tolerances for convergence, or potentially even the order of operations in the \enquote{handwritten} programs used in optimizers can lead to different estimates of parameter values, or to different convergence codes.{\footnotemark}
Researchers generally recognise these issues and attempt estimation on a variety of optimizers within at least one statistical package, but seldom change the tolerances for convergence from those deemed \enquote{sane} defaults by the software's authors, or run estimations across different statistical software.{\footnotemark}

\addtocounter{footnote}{-2}
\stepcounter{footnote}\footnotetext{
	Generally optimizers give \enquote{codes} to signal the degree of confidence in the returned optimum.
	These may indicate that the gradient is below its tolerance level, that the gradient or likelihood hasn't decreased after many iterations, that the limit of iterations has been reached, or that the optimizer failed to converge on a single maximum.
	We follow \textcite{Harrison2016} in only considering estimates that have gradients below the given threshold value and a Hessian that is negative definite.
}
\stepcounter{footnote}\footnotetext{
	The NR, BFGS, and BHHH, optimizers are all available in Stata and R.
	Concerning tolerance levels, Stata's help file for its \texttt{ml\_maxopts} command states concerning the options for changing tolerance levels: \enquote{These options are seldom used.}
}

Bearing in mind the necessary criteria for reaching convergence in optimization and the limits of such optimization exercises,{\footnotemark} we now discuss the process of picking the \enquote{winning} model for each subject.
First, all four models models cited in equations (\ref{eq4:pw:eut}), (\ref{eq4:pw:pow}), (\ref{eq4:pw:inv}), (\ref{eq4:pw:pre}) are estimated for each subject.
Any estimate that didn't return a convergence code indicating both a gradient near 0 and a negative definite Hessian was dropped from consideration.
Additional rules were implemented to drop from consideration converged estimates that were considered unreasonable:
\begin{itemize}
	\item Any model with a CRRA coefficient estimated to be greater than 15 or less than -15.
	\item Any model with a CRRA coefficient estimated to be greater than .99 and less than 1.01.{\footnotemark}
	\item $\mathit{RDU_{Pow}}$ and $\mathit{RDU_{Invs}}$ models where the $\gamma$ parameter was estimated to be greater than 5.
\end{itemize}

The log-likelihood function given in equation (\ref{eq4:ll}) is equally applicable to all four models considered by \textcite{Harrison2016}, and seems a natural metric to declare a \enquote{winning} model among the 4 alternatives proposed.
However, since RDU models nest EUT as a special case (noted in equation \ref{eq4:pw:eut}), \textit{a priori} we'd expect RDU models to produce greater log-likelihoods than an EUT model on any given dataset.{\footnotemark}
\textcite[102]{Harrison2016} notes this issue and proposes the additional qualification on RDU models that the probability weighting function implied by the estimated model must be statistically significantly different from a linear function, the special case of EUT, at the 10, 5, or 1 percent significance levels.

\addtocounter{footnote}{-3}
\stepcounter{footnote}\footnotetext{
	There are some differences in convergences and estimations between our results and those reported by \textcite{Harrison2016}.
	These differences are detailed in Appendix A, but do not change the aggregate conclusions of \textcite{Harrison2016}.
	Through the remainder of this section, our own estimates using the data and exclusionary rules of \textcite{Harrison2016} are presented.
}
\stepcounter{footnote}\footnotetext{
	\textcite{Wakker2008} details how the CRRA utility function used throughout this chapter and in \textcite{Harrison2016} has certain asymptotic properties around 1.
	These properties may create numerical issues for the optimizer and so estimated values very near 1 are viewed as less credible.
}
\stepcounter{footnote}\footnotetext{
	This doesn't mean that RDU models \textit{necessarily} produce greater log-likelihoods than an EUT model on every or any given dataset, only that they have a high likelihood of doing so.
}

The null hypothesis for the $\mathit{RDU_{Pow}}$ and $\mathit{RDU_{Invs}}$ models is $H0: \gamma = 1$, and the null for the $\mathit{RDU_{Prelec}}$ model is $H0: \alpha = \beta = 1$.
Non-linear Wald tests are used to test these hypotheses.
Any RDU model that fails to reject the null hypothesis is removed from consideration as a \enquote{winning} model.
If the EUT model did not converge for the subject in question, the models considered will only consist of the RDU models which tested as different to EUT.
If the EUT model did not converge \textit{and} no RDU model tested as different to EUT, then all of the converged RDU models will be considered.
The \enquote{winning} model for each subject is chosen from among the models which have met the consideration qualifications on the basis of log-likelihood.

The winning model is then used to calculate the welfare consequences of the subject's choices on the insurance task.
We will call this process of picking a winning model among several alternative models a \enquote{classification} process, and in proceeding sections, describe the empirical limitations of this process.
Using the same classification processes employed by \textcite{Harrison2016} show a noticeably different distribution of subjects classified to the 4 models in Figure \ref{fig:HNG_pvals}.

\begin{figure}[h!]
	\center
	\caption{Classifying Subjects as EUT or RDU}
	%\caption{Estimates for each individual of EUT and RDU specifications \textcite[108]{Harrison2016} Data}
	\onlyinsubfile{
		\includegraphics[height=.25\paperheight]{figures/HNG_pvals.pdf}
	}
	\notinsubfile{
		\includegraphics[height=.25\paperheight]{ch4/figures/HNG_pvals.pdf}
	}
	\label{fig:HNG_pvals}
\end{figure}

The differences in the classification distribution between our results are driven almost entirely by differences in model convergence, not by differences in estimated values or p-values.
Going from the estimates of \textcite{Harrison2016} to our own, one subject for $\mathit{RDU_{Prelec}}$ changes from insignificantly different from EUT to significantly different at the 1\% level, one subject for $\mathit{RDU_{Invs}}$ changes from insignificant to significant at the 10\% level, and one subject for $\mathit{RDU_{Pow}}$ changes from significant at the 5\% level to the 1\% level.
Further details on differences are given in Appendix A.
We do however, replicate in Figure \ref{fig:HNG_CS} almost exactly the distribution of per-choice consumer surplus presented in Figure 10 of \textcite[108]{Harrison2016}.

\begin{figure}[h!]
	\center
	\caption{Distribution of Consumer Surplus, Using Data from \textcite{Harrison2016}}
	\onlyinsubfile{
		\includegraphics[height=.25\paperheight]{figures/HNG_CS.pdf}
	}
	\notinsubfile{
		\includegraphics[height=.25\paperheight]{ch4/figures/HNG_CS.pdf}
	}
	\label{fig:HNG_CS}
\end{figure}

\section{Individual Classification and Welfare Estimation Accuracy}

Whether the results presented in Figure \ref{fig:HNG_pvals} demonstrate an accurate estimation of the proportions of subjects belonging to those models depends on our confidence in the classification process to correctly classify a subject as one of these four models, as well as our confidence that the subjects in the experiments actually belong to one of the four models we test for.
Our confidence that the classification process can correctly classify a subject in turn depends on the nature of the experimental instrument presented to the subject.
In this section, we interrogate the ability of the classification process to correctly classify subjects given the instrument presented in \textcite{Harrison2016}, and in turn how accurate the welfare calculations are given a classification.

We conduct this interrogation via a simulation analysis, which we will describe in more depth shortly, and analyze the result with Bayes' Theorem.
We simulate subjects conforming to the EUT, $\mathit{RDU_{Pow}}$, $\mathit{RDU_{Invs}}$, and $\mathit{RDU_{Prelec}}$ models, have these simulated subjects respond to both the lottery and insurance task, estimate the subjects' responses to the lottery task, classify each subject based on the classification process described in the previous section, and calculate the welfare surplus for each subject based on the winning model.

A simulated subject is represented by a single parameter set and an assigned operating model.
For each model, we employ the CRRA utility function defined in (\ref{eq4:CRRA}) and the CU stochastic model defined in equations (\ref{eq4:RE.2}) and (\ref{eq4:W.cu}).
For EUT subjects, the parameter set consists of $\lbrace r, \lambda \rbrace$, for $\mathit{RDU_{Pow}}$ and $\mathit{RDU_{Invs}}$ subjects $\lbrace r, \gamma, \lambda \rbrace$, and for $\mathit{RDU_{Prelec}}$ subjects $\lbrace r, \alpha, \beta, \lambda \rbrace$.
The $r$ parameter in every set is the CRRA parameter from equation (\ref{eq4:CRRA}) and $\lambda$ is the precision parameter defined in equation (\ref{eq4:RE.2}).
The remaining $\gamma$, $\alpha$, and $\beta$ parameters relate to the probability weighting parameters of their respective models defined in equations (\ref{eq4:pw:pow}), (\ref{eq4:pw:inv}), and (\ref{eq4:pw:pre}).

For each model, we draw parameter sets from a joint uniform distribution over the parameters needed for that model, where the marginal distributions are uncorrelated.{\footnotemark}
For all models, the marginal distribution for $r$ is where $r \in [-1, 0.95]$ and  for $\lambda$ is $\lambda \in [0.01, 0.30]$.
For the $\mathit{RDU_{Pow}}$ and $\mathit{RDU_{Invs}}$ models, the marginal distribution for $\gamma$ is where $\gamma \in [0.10, 2]$.
For the $\mathit{RDU_{Prelec}}$ model the marginal distribution for $\alpha$ and $\beta$ is where $\alpha \in [0.10, 2]$ and $\beta \in [0.10, 2]$.

We draw 250,000 parameter sets for each model for a total of 1 million simulated subjects.
The number of draws from these joint distributions was chosen in an attempt to fill as much of the relevant parameter space as possible.{\footnotemark}
Each simulated subject uses the parameter set and operating model assigned to it to calculate the choice probabilities for each option in each lottery pair of the lottery task and the insurance task.
A random number is drawn from a univariate uniform distribution, and if the choice probability calculated for the $A$ option was greater than the random number, the subject chooses A, otherwise they choose B.
This process ensures that subjects' choices are made probabilistically with respect to the subjects' model and parameter set.{\footnotemark}

\addtocounter{footnote}{-3}
\stepcounter{footnote}\footnotetext{
	To create uncorrelated joint uniform distributions, uncorrelated normal distributions were generated using a Gaussian copula process.
	The inverse normal cumulative distribution function was then applied to each marginal distribution to get uncorrelated uniformly distributed variables in the $[0,1]$ space.
	These uniformly distributed variables were then stretched and shifted to fit the uniform spaces described here while retaining the 0 correlation coefficient.
	This process was employed to ensure that the (admittedly low) probability of accidental correlation that might occur from simply drawing from a uniform distribution directly was minimized.
}
\stepcounter{footnote}\footnotetext{
	A limitation of choosing the same number of draws for each model is that the square uniform space for the EUT model will have smaller gaps than the cubic space of the $\mathit{RDU_{Pow}}$ and $\mathit{RDU_{Invs}}$ models, which in turn have smaller gaps than the hypercubic space of the $\mathit{RDU_{Prelec}}$ model.
	The smaller the gaps between parameter sets in their joint space, the better the prediction accuracy of classifying subjects for the parameter sets that exist in the empty space.
}
\stepcounter{footnote}\footnotetext{
	Consider a choice probability for option $A$ calculated to be $0.90$, and therefore the choice probability for option $B$ is $0.10$.
	A random number drawn from a univariate uniform distribution has a 90\% chance of being below or equal to $0.90$, so option A would be chosen 90\% of the time.
}

After the subjects have made choices, each of the four models we consider is estimated for each subject on the choices made in the lottery task.
Any model which didn't converge with a gradient close to 0 and a negative definite Hessian matrix was dropped from consideration.
Any model which converged on parameters outside of exclusionary rules defined in the previous section was also dropped from consideration.
Each subject was then classified based on the classification process defined in the previous section.
With the parameters of the winning model, the welfare surplus of the choices made on the insurance task are calculated.

The accuracy of the classification process on the lottery task will be assessed using Bayes' Theorem, defined as follows:

\begin{equation}
	\label{eq4:bayes}
	P(A|B) = \frac{P(B|A) \times P(A)}{P(B)}
\end{equation}

\noindent where for each subject:

\begin{itemize}
	\item $A$ - The subject actually conforms to model $M$.
	\item $B$ - The subject has been classified as model $N$.
	\item $P(A)$ - The probability that any subject actually conforms to model $M$.
	\item $P(B)$ - The probability that any subject will be classified a model $N$.
	\item $P(B|A)$ - The probability that a subject will be classified as model N given the subject actually conforms to model $M$.
	\item $P(A|B)$ - The probability that a subject actually conforms to model $M$ given the subject has been classified as model $N$.
\end{itemize}

\noindent where $M$ and $N$ are one of EUT, $\mathit{RDU_{Pow}}$, $\mathit{RDU_{Invs}}$, and $\mathit{RDU_{Prelec}}$, and $M$ and $N$ can be the same model.

By definition of our simulation analysis, we know $A$ for each subject as we have assigned it in simulation.
We know $B$ for each subject after each subject has had the four models estimated on its lottery data and has been classified.
$P(A)$, $P(B)$, $P(B|A)$, and $P(A|B)$ will all depend on the particular parameters the simulated subjects in consideration actually employ, and how these parameters relate to the classification process.

Going forward we will present two interpretable cases of (\ref{eq4:bayes}).
Firstly, the case where the full set of simulated data is used.
With this data we can present $P(B|A)$ for the full set of simulated subjects for all $M$ and $N$ where $P(A) = 1$ for each $M$.
For this case, we would need to know what the real proportions of the population are that operate one of the four models considered in order to calculate $P(A)$ and $P(B)$ over the full set of simulated subjects.
We don't believe this is something which is useful unless a researcher expects real (non-simulated) populations to have uniformly distributed uncorrelated parameter sets for each of the four models.

This leads to the second case in which we define a hypothetical population of subjects in terms of the distributions of parameters for each model, and the proportion of each model type present in the population.
Knowing the proportion of each model type in this hypothetical population is equivalent to knowing $P(A)$.
Knowing the distribution of parameter sets for each model type and the state of $A$ for each subject lets us calculate $P(B)$, and $P(B|A)$.
These in turn allow us to calculate $P(A|B)$, for each model type.

We pick arbitrary proportions of each model, and arbitrary distributions for each model in the hypothetical population.
We select the proportion of EUT subjects in the population to be $0.5$, the proportion of $\mathit{RDU_{Pow}}$ subjects to be $0.1$, the proportion of $\mathit{RDU_{Invs}}$ subjects to be $0.1$ and the proportion of $\mathit{RDU_{Prelec}}$ subjects to be $0.3$.
These proportions are roughly similar to the proportions reported by \textcite[108]{Harrison2016}, though with more EUT and fewer $\mathit{RDU_{Prelec}}$ subjects, and slightly more $\mathit{RDU_{Pow}}$ and slightly less $\mathit{RDU_{Invs}}$ subjects than they report.

For all models, the marginal distributions of parameters are set to be uncorrelated with each other.
For all models, the distribution of the CRRA parameter is Normal: $r \sim \mathcal{N}(0.6, 0.1^2)$, and the distribution of the $\lambda$ parameter is log-normal: $\lambda \sim \mathcal{N}(\ln(x);0.10, 0.02^2)$.
For the $\mathit{RDU_{Pow}}$ and $\mathit{RDU_{Invs}}$ models, the $\gamma$ parameter is distributed log-normal: $\gamma \sim \mathcal{N}(\ln(x);0.6, 0.1^2)$.
For the $\mathit{RDU_{Prelec}}$ model, the $\alpha$ and $\beta$ parameters are distributed log-normal: $\alpha \sim \mathcal{N}(\ln(x);0.6, 0.1^2)$, $\beta \sim \mathcal{N}(\ln(x);1.6, 0.1^2)$.
These marginal distributions make up the population's joint distribution and were picked to make the EUT subjects moderately risk averse, the RDU subjects to be far away from equivalence to EUT, and for all subjects to make relatively precise choices.

For the second case example, we don't draw subjects directly from the 1 million simulated subjects.
Instead, for each model $M$, we fit 4 generalized additive models (GAM) \parencite{Hastie1986} to the simulated subjects actually conforming to $M$ with the dependent variable equal to 1 if they were classified as model $N$, and the independent variables as the subjects' real parameter values for model $M$.
Thus, 16 fitted models in total:
\begin{align}
	\label{eq4:GAM}
	\begin{split}
		(B &= N | A = EUT)                   = s(r) + s(\lambda)\\
		(B &= N | A = \mathit{RDU_{Pow}})    = s(r) + s(\gamma) + s(r, \gamma) + s(\lambda)\\
		(B &= N | A = \mathit{RDU_{Invs}})   = s(r) + s(\gamma) + s(r, \gamma) + s(\lambda)\\
		(B &= N | A = \mathit{RDU_{Prelec}}) = s(r) + s(\alpha) + s(\beta) +s(\alpha, \beta) + s(r, \alpha, \beta) + s(\lambda)
	\end{split}
\end{align}

\noindent where $N$ is one of EUT, $\mathit{RDU_{Pow}}$, $\mathit{RDU_{Invs}}$, $\mathit{RDU_{Prelec}}$, and $s(\cdot)$ indicates some smooth, potentially non-linear function of its arguments.

We then draw a sample of $100,000$ subjects from the joint population distribution above, with $100,000 \times 0.5 = 50,000$ EUT subjects, $100,000 \times 0.1 = 10,000$ $\mathit{RDU_{Pow}}$ and $\mathit{RDU_{Invs}}$ subjects, and $100,000 \times 0.3 = 30,000$ $\mathit{RDU_{Prelec}}$ subjects.
For every $M$ and $N$ we use the fitted models from equation (\ref{eq4:GAM}) to predict values of $P(B = N | A = M)$.
These predicted values for $P(B = N | A = M)$ will lie between $(0, 1)$ as the dependent variable is either 0 or 1.

\subsection{ \texorpdfstring{\textcite{Harrison2016}}{Harrison and Ng (2016)} Lottery Task Classification Success}

Using the process above, we first examine the \textcite{Harrison2016} lottery task:

\subsubsection{Case 1}

\begin{figure}[hp!]
	\center
	\caption{$P(B|A)$ for Given $\lambda$ Values: \textcite{Harrison2016} Lottery Instrument}
	\onlyinsubfile{
		\includegraphics[width=\textwidth]{figures/mu-winners-HNG_1.pdf}
	}
	\notinsubfile{
		\includegraphics[width=\textwidth]{ch4/figures/mu-winners-HNG_1.pdf}
	}
	\label{fig:HNG_mu_PBA}
\end{figure}

In Figure \ref{fig:HNG_mu_PBA}, we have $P(B|A)$ where $A$ is given by the 4 rows of the grid and $B$ is given by the columns, for the range of $\lambda$ values we simulated over.
Thus, the top-left-most plot is the probability that a subject that operates EUT will be classified as EUT.
Indeed, the diagonal of Figure \ref{fig:HNG_mu_PBA} shows the probability that a subject will be classified correctly as the model they actually operate.
This probability of classification is given for the three significance levels of 1\%, 5\%, and 10\%.

Additionally, any subject that had a probability weighting parameter less than 1.2 and greater than 0.8 was dropped before the GAM lines in Figure \ref{fig:HNG_mu_PBA} were estimated.
This was done to help ensure that subjects close to the special case of EUT didn't overly influence the results.

\subsubsection{Case 2}

In this case, rather than plot the results across a range of values, we can instead tabulate each element of equation (\ref{eq4:bayes}) assuming a 5\% significance level for the classification process.

\onlyinsubfile{
\begin{table}[ht!]
	\centering
	\captionsetup{justification=centering}
	\caption{$P(A)$}
	\label{tb:HNG_PA}
	\begin{adjustbox}{}
	\pgfplotstabletypeset[
		col sep=comma,
		every head row/.style={
			after row=\hline
		},
		display columns/0/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {EUT}
		},
		display columns/1/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {Power}
		},
		display columns/2/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {Inverse-S}
		},
		display columns/3/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {Prelec}
		},
	]{tables/HNG_1-PA.csv} % path/to/file
	\end{adjustbox}
\end{table}

\begin{table}[ht!]
	\centering
	\captionsetup{justification=centering}
	\caption{$P(B)$}
	\label{tb:HNG_PB}
	\begin{adjustbox}{}
	\pgfplotstabletypeset[
		col sep=comma,
		every head row/.style={
			after row=\hline
		},
		display columns/0/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {EUT}
		},
		display columns/1/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Power}
		},
		display columns/2/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Inverse-S}
		},
		display columns/3/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Prelec}
		},
	]{tables/HNG_1-PB.csv} % path/to/file
	\end{adjustbox}
\end{table}

\begin{table}[ht!]
	\centering
	\captionsetup{justification=centering}
	\caption{$P(B | A)$}
	\label{tb:HNG_PBA}
	\begin{adjustbox}{}
	\pgfplotstabletypeset[
		col sep=comma,
		every head row/.style={
			after row=\hline
		},
		display columns/0/.style={
			assume math mode = true,
			string type,
			column name = {}
		},
		display columns/1/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {EUT}
		},
		display columns/2/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Power}
		},
		display columns/3/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Inverse-S}
		},
		display columns/4/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Prelec}
		},
	]{tables/HNG_1-PBA.csv} % path/to/file
	\end{adjustbox}
\end{table}

\begin{table}[ht!]
	\centering
	\captionsetup{justification=centering}
	\caption{$P(A | B)$}
	\label{tb:HNG_PAB}
	\begin{adjustbox}{}
	\pgfplotstabletypeset[
		col sep=comma,
		every head row/.style={
			after row=\hline
		},
		display columns/0/.style={
			assume math mode = true,
			string type,
			column name = {}
		},
		display columns/1/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {EUT}
		},
		display columns/2/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Power}
		},
		display columns/3/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Inverse-S}
		},
		display columns/4/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Prelec}
		},
	]{tables/HNG_1-PAB.csv} % path/to/file
	\end{adjustbox}
\end{table}
}
\notinsubfile{
\begin{table}[ht!]
	\centering
	\captionsetup{justification=centering}
	\caption{$P(A)$}
	\label{tb:HNG_PA}
	\begin{adjustbox}{}
	\pgfplotstabletypeset[
		col sep=comma,
		every head row/.style={
			after row=\hline
		},
		display columns/0/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {EUT}
		},
		display columns/1/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {Power}
		},
		display columns/2/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {Inverse-S}
		},
		display columns/3/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {Prelec}
		},
	]{ch4/tables/HNG_1-PA.csv} % path/to/file
	\end{adjustbox}
\end{table}

\begin{table}[ht!]
	\centering
	\captionsetup{justification=centering}
	\caption{$P(B)$}
	\label{tb:HNG_PB}
	\begin{adjustbox}{}
	\pgfplotstabletypeset[
		col sep=comma,
		every head row/.style={
			after row=\hline
		},
		display columns/0/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {EUT}
		},
		display columns/1/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Power}
		},
		display columns/2/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Inverse-S}
		},
		display columns/3/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Prelec}
		},
	]{ch4/tables/HNG_1-PB.csv} % path/to/file
	\end{adjustbox}
\end{table}

\begin{table}[ht!]
	\centering
	\captionsetup{justification=centering}
	\caption{$P(B | A)$}
	\label{tb:HNG_PBA}
	\begin{adjustbox}{}
	\pgfplotstabletypeset[
		col sep=comma,
		every head row/.style={
			after row=\hline
		},
		display columns/0/.style={
			assume math mode = true,
			string type,
			column name = {}
		},
		display columns/1/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {EUT}
		},
		display columns/2/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Power}
		},
		display columns/3/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Inverse-S}
		},
		display columns/4/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Prelec}
		},
	]{ch4/tables/HNG_1-PBA.csv} % path/to/file
	\end{adjustbox}
\end{table}

\begin{table}[ht!]
	\centering
	\captionsetup{justification=centering}
	\caption{$P(A | B)$}
	\label{tb:HNG_PAB}
	\begin{adjustbox}{}
	\pgfplotstabletypeset[
		col sep=comma,
		every head row/.style={
			after row=\hline
		},
		display columns/0/.style={
			assume math mode = true,
			string type,
			column name = {}
		},
		display columns/1/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {EUT}
		},
		display columns/2/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Power}
		},
		display columns/3/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Inverse-S}
		},
		display columns/4/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Prelec}
		},
	]{ch4/tables/HNG_1-PAB.csv} % path/to/file
	\end{adjustbox}
\end{table}
}

In Table \ref{tb:HNG_PA} we have the probability that any given subject drawn from our hypothetical population will belong to the model given by the columns.
This is equal to the proportion of each model we specified initially.
In Table \ref{tb:HNG_PB} we have the probability that any given subject drawn from our hypothetical population will be classified as the model given by the columns. 
In Table \ref{tb:HNG_PBA} we have the probability that a subject will be classified as the column model, given that they actually operate the row model.
In Table \ref{tb:HNG_PAB} we have the probability that a subject actually operates the row model, given that they have been classified as the column model.

\subsubsection{Discussion}

An immediately grabbing result from Figure \ref{fig:HNG_mu_PBA} is the remarkably low probability that subjects operating either $\mathit{RDU_{Pow}}$ or $\mathit{RDU_{Invs}}$ will be correctly classified as the model they operate for a wide range of $\lambda$ values.
The probability that $\mathit{RDU_{Pow}}$ subjects will be correctly classified increases above 25\% for any significance level only as $\lambda$ decreases below 0.05.
The probability that $\mathit{RDU_{Invs}}$ subjects will be correctly classified never increases above 5\% for any value of $\lambda$.
For both of these models, they are far more likely to be misclassified as either EUT or $\mathit{RDU_{Prelec}}$ than to be classified correctly.

Additionally, subjects operating EUT, $\mathit{RDU_{Pow}}$, and $\mathit{RDU_{Prelec}}$ models do not get misclassified as $\mathit{RDU_{Invs}}$ with a probability noticeably different from 0 for any value of $\lambda$.
This result suggest that if the subjects we consider in real experiments only operate one of these four models, we should classify a vanishingly small proportion of these subjects as $\mathit{RDU_{Invs}}$.
However, as we saw in Figure \ref{fig:HNG_pvals}, when we estimate on real subject data, we \textit{do} classify a non-trivial proportion of subjects as $\mathit{RDU_{Invs}}$.
Given the small probability of observing any classification of $\mathit{RDU_{Invs}}$ from subjects operating one of the four models considered here, this suggests that these subjects classified as $\mathit{RDU_{Invs}}$ actually operate a model that presents as $\mathit{RDU_{Invs}}$ in this classification process, but is not one of the four models we consider here.
The hypothetical population analyzed in tables \ref{tb:HNG_PB} and \ref{tb:HNG_PBA} support the conclusion that, at least for a population like the one considered here, we should observe less than 1\% of subjects being classified as $\mathit{RDU_{Invs}}$.
Table \ref{tb:HNG_PBA} shows that if the population had been made up of 100\% $\mathit{RDU_{Invs}}$ subjects with preferences distributed as defined in our hypothetical population, only 1.3\% of them would have been classified as $\mathit{RDU_{Invs}}$.


\subsection{ \texorpdfstring{\textcite{Hey1994}}{Hey and Orme (1994)} Lottery Task and \texorpdfstring{\textcite{Harrison2016}}{Harrison and Ng (2016)} Insurance Task}
\begin{figure}[h!]
	\center
	\caption{$P(B|A)$ for Given $\lambda$ Values: \textcite{Hey1994} Lottery Instrument}
	\onlyinsubfile{
		\includegraphics[width=\textwidth]{figures/mu-winners-HO.pdf}
	}
	\notinsubfile{
		\includegraphics[width=\textwidth]{ch4/figures/mu-winners-HO.pdf}
	}
	\label{fig:HO_mu_winner}
\end{figure}
\section{Synthetic Laboratories}

Discuss how simulation methods used in this chapter are more akin to a laboratory experiment than to analytical approximation.
There are Duhem-Quine auxiliary hypotheses associated with this kind of estimation, notably the optimization settings.
This type of \enquote{synthetic} laboratory is useful in alleviating Duhem-Quine auxiliary hypotheses associated with laboratory environments with real people.

\section{Conclusions}

\onlyinsubfile{
\newpage
\printbibliography[segment=4, heading=subbibliography]
}



\printbibliography

\end{document}
