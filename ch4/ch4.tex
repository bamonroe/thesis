\documentclass[../main.tex]{subfiles}

\begin{document}

\onehalfspacing
\setcounter{chapter}{3}

\chapter{Welfare From Experimental Instruments}

\lltoc % Table of contents only when locally compiled

In Chapter 1 we described the efforts of economists to account for apparent violations of Expected Utility Theory (EUT) in economic experiments.
Some of these efforts were directed at the development of alternative deterministic theories of utility, such as Prospect Theory by \textcite{Kahneman1979}, Rank Dependent Utility (RDU) by \textcite{Quiggin1982}, and Regret Theory by \textcite{Bell1982}, \textcite{Loomes1982}.
Other efforts were focused on the redevelopment of stochastic models, such as the constant error or \enquote{tremble} model by \textcite{Harless1994}, the Strong Utility model by \textcite{Hey1994}, the random preference model by \textcite{Loomes1995}, along with many derivatives of the Strong Utility model.
Much of the newly proposed theoretical explanations of the apparent violations of EUT we tested experimentally.
A well known example is that of \textcite{Hey1994} (HO), who conduct an experiment to test if any of a variety of generalizations (and one restriction) of EUT can explain experimentally collected data significantly better than EUT while utilizing the Strong Utility model.
HO engage in picking "winning" models for each subject on the basis of their estimates for each model and whether each model can be said to be different from EUT.
They conclude that \enquote{our study indicates that behavior can be reasonably well modelled (to what might be termed a \enquote{reasonable approximation}) as \enquote{EU plus noise.}}

However, HO note:
\enquote{The inferences that can be drawn \textelp{} about the adequacy or otherwise of EU are not, however, clear cut - mainly because of the large number of generalizations of EU under consideration.
A this research has evolved, and then number of generalizations under consideration has increased, the number of subjects for whom EU emerges as \enquote{the winners} has declined. 
This is inevitable, though it is not clear how one should judge the rate of decline.
\textelp{} Monte Carlo work would be needed to shed more accurate light on such issues}

The concerns raised by HO can be considered that of statistical power and how much economists should care about potential misidentification, that is, how much should we care about type I and type II errors.
In this chapter, we will analyze the experimental instruments utilized by \textcite{Harrison2016} (HNG) for its ability to accurately recover the utility functions of agents faced with the instruments.
The analysis will focus firstly on the ability of the instrument to correctly classify an agent operating one of four different utility models, as is done in HNG, and secondly on the welfare consequences of this characterization.
Thus we attempt to remove some uncertainty about the power of the instrument, and propse metrics to address the question of how much economists should care about statistical power issues by linking them directly with welfare evaluations.

To begin this analysis, we will describe and replicate the classification and welfare calculation exercises of HNG.
Next we will conduct a simulation analysis on the lottery instrument used in HNG to determine the frequency of misclassification for two of the four models in question, and the welfare consequences thereof.
We next propose two ways to potentially alleviate the welfare concerns of misidentification.

\section{Estimating a Benchmark using \texorpdfstring{\textcite{Harrison2016}}{Harrison and Ng (2015)}}
\label{sec4:Bench}

\textcite{Harrison2016} report the results of an experiment intended to evaluate the welfare consequences of individuals' decisions to purchase insurance.
This is in part a response to the large literature cited by \textcite[92]{Harrison2016} which evaluates insurance on the basis of \enquote{take-up}: the rate at which individuals purchase insurance.
They argue that although a take-up metric is transparent and easy to measure, it doesn't allow for statements about whether an individual \textit{should} have taken up the insurance product, and it does not quantify the consumer surplus from making the correct insurance purchase decision.
These are, however, precisely the kind of normative welfare statements that economists should be making about the economic choices of agents.
They are also the kind of normative welfare statements that can be made from estimating the utility functions of individuals and evaluating their choices with respect to these functions.

\textcite{Harrison2016} address the problem of evaluating the welfare consequences of the decision to purchase insurance or not by conducting a 2-part experiment.
In the first part each subject is presented with a battery of 80 lottery pairs and asked to select one lottery from each pair that will be played out for payment.
This part will be referred to as the \enquote{lottery task} throughout.
The responses of each subject to the lottery task are used to estimate utility functions for that individual.
In the second part each subject is endowed with \money{20} and presented with 24 choices where they are asked to choose between a lottery which will result in a loss of \money{15} with some probability $p$ or no loss of the initial endowment with probability $(1-p)$, and a certain amount of money between \money{15.20} and \money{19.80}.
The choice of the certain amount of money is framed as the purchase of insurance against the risk of loss in the lottery option.
This part will be referred to as the \enquote{insurance task} throughout.
Both of these instruments are detailed in full in the Appendix (to be added).

For each individual, \textcite{Harrison2016} use the data recovered in the lottery task to estimate four models which can be described in the framework of Rank Dependent Utility (RDU) as first proposed by \textcite{Quiggin1982}:
\begin{equation}
	\label{eq4:RDU}
	RDU = \sum_{i=1}^{I} \left[ w_i(p) \times u(x_i) \right]
\end{equation}
\noindent where $i$ indexes the outcomes, $x_i$, from $\{1,\ldots,I\}$ with $i=1$ being the smallest outcome in the lottery and $i=I$ being the greatest outcome in the lottery, $u(\cdot)$ is a standard utility function, $w_i(\cdot)$ decision weight function applied to outcome $i$ given the distribution of probabilities in the lottery ranked by outcome, $p$.
The decision weight function, $w_i(\cdot)$, takes the form:
\begin{equation}
	\label{eq4:dweight}
	w_i(p) =
	\begin{cases}
		\omega\left(\displaystyle\sum_{j=i}^I p_j\right) - \omega\left(\displaystyle\sum_{k=i+1}^I p_k\right) & \text{for } i<I \\
		\omega(p_i) & \text{for } i = I
	\end{cases}
\end{equation}
\noindent where the probability weighting function, $\omega(\cdot)$, can take a variety of parametric or non-parametric forms.
HNG estimate four probability weighting functions (pwf).
The first pwf is the linear function:
\begin{equation}
	\label{eq4:pw:eut}
	\omega(p_i) = p_i
\end{equation}

\noindent The second pwf is the power function ($\mathit{RDU_{Pow}}$) used by \textcite{Quiggin1982}:
\begin{equation}
	\label{eq4:pw:pow}
	\omega(p_i)=p_i^\gamma
\end{equation}

\noindent where $\gamma > 0$. 
The third pwf is the \enquote{Inverse-S} shaped function ($\mathit{RDU_{Invs}}$) popularized by \textcite{Tversky1992}:
\begin{equation}
	\label{eq4:pw:inv}
	\omega(p_i) = \frac{p_i^\gamma}{\biggl(p_i^\gamma + {(1-p_i)}^\gamma\biggr)^{ \frac{1}{\gamma} } }
\end{equation}

\noindent where $\gamma > 0$. 
The fourth pwf is the flexible function proposed by \textcite{Prelec1998} ($\mathit{RDU_{Prelec}}$):
\begin{equation}
	\label{eq4:pw:pre}
	\omega(p_i)=\exp(-\beta(-\ln(p_i))^\alpha)
\end{equation}
\noindent where $\alpha > 0$ and $\beta > 0$.

The functional form of an RDU model with the linear probability weighting function in equation (\ref{eq4:pw:eut}) is equivalent to Expected Utility Theory (EUT), and will be referred to as EUT throughout.
In all the remaining probability weighting functions, there exist values for the probability weighting parameters which allow $w_i(p) = p_i$, the special case of EUT.

For all four models, \textcite{Harrison2016} use the CRRA utility function:
\begin{equation}
	\label{eq4:CRRA}
	u(x) = \frac{x^{(1-r)}}{(1-r)}
\end{equation}
\noindent where $r$ is the coefficient of relative risk aversion proposed by \textcite{Pratt1964}.

I continue to use the notation used in chapters 2 and 3 to describe a choice scenario by a subject, but limit it to a binary choice between two options, $j$ and $k$.
In this framework a choice of option $j$ in task $t$ is indicated by the function $y_t = j$, where $y_t = 1 \geq^n y_t = 2$.
The values of $j$ and $k$ do not indicate the order or frame with which the options in task $t$ were presented to the subject, but rather the ordinal rank the subject's utility function assigns to the options, with 1 always being the option of greatest utility.
This notation is useful when describing the welfare consequences of choices below.

\textcite{Harrison2016} also use Contextual Utility (CU), as defined by \textcite{Wilcox2008}, as the stochastic model.
Thus for the models utilized, the probability that option $j$ is chosen is given by:
\begin{align}
	\label{eq4:RE.2}
	\begin{split}
		{\Prob}(y_t = j) &= {\Prob}\left(  \epsilon_t \geq \frac{1}{\lambda_n} \left[ G(\beta_n,X_{kt}) - G(\beta_n,X_{jt}) \right] \right)\\
		&= 1 - F\left( \dfrac{G(\beta_n,X_{kt}) - G(\beta_n,X_{jt})}{D(\beta_n,X_t)\lambda_n }  \right)
	\end{split}
\end{align}

\noindent where $\epsilon_t$ is a mean 0 error term, $F$ is a symmetric cumulative distribution function (cdf), meaning $1 - F(x)  = F(-x)$, $G(\cdot)$ is the RDU utility model that takes the parameters $\beta_n$ to calculate the utility of lottery $j$ or $k$ in task $t$ comprised of outcomes and probabilities $X_{jt}$, and $\lambda_n$ is a precision parameter.
The function $D(\cdot)$ separates contextual utility from a Strong Utility model:
\begin{align}
	\label{eq4:W.cu}
	\begin{split}
		&D(\beta_n,X_t) = \mathit{max}[u(x_{it})] - \mathit{min}[u(x_{it})]\\
		&\mathit{st.}\; w_i(x_{it}) \neq 0
	\end{split}
\end{align}

Usually, the Normal or Logistic cdf is chosen for $F$, and employ the Logistic cdf for all calculations throughout.
Given that each choice considered here only involves two lottery options, we can define the probability of choosing option $j$ given a particular model, parameter set $\beta_n$, precision parameter $\lambda_n$, and outcomes and probabilities of option $j$, $X_{jt}$, as
\begin{equation}
	\label{eq4:RE.f}
	{\Prob}(y_t=j) =\dfrac{\exp\!\left( \dfrac{ G(\beta_n,X_{jt}) }{ D(\beta_n,X_{t})\lambda_n }  \right)}{  \exp\!\left( \dfrac{ G(\beta_n,X_{jt}) }{ D(\beta_n,X_{t})\lambda_n }  \right) + \exp\!\left( \dfrac{ G(\beta_n,X_{kt}) }{ D(\beta_n,X_{t})\lambda_n }  \right)    }
\end{equation}

\noindent These choice probabilities in turn are logged and summed to produce a log-likelihood function for each of the four different models:
\begin{equation}
	\label{eq4:ll}
	\ensuremath{\mathit{LL_n}} = \sum_{t}^T \ln \left[ {\Prob}(y_t) \right]
\end{equation}

As a metric of welfare, \textcite{Harrison2016} primarily use the consumer surplus (CS) of each choice.
The CS of each choice is defined as the difference between the certainty equivalent ({\CE}) of the chosen option and the certainty equivalent of the unchosen option.
Since the CRRA utility function defined in equation (\ref{eq4:CRRA}) is used for all models discussed, we can define the {\CE} as:

\begin{align}
	\label{eq4:CEcalc}
	\begin{split}
		&\sum_{i=1}^{I} w_i(p) \frac{x_{ij}^{(1-r)}}{(1-r)} = \frac{ {\CE}_j^{(1-r)}}{(1-r)}\\
		&{\CE}_j =  \left( (1-r) \times \sum_{i=1}^{I} w_i(p) \frac{x_{ij}^{1-r}}{(1-r)} \right)^{ \displaystyle\nicefrac{1}{(1-r)} } ,
	\end{split}
\end{align}

\noindent and the welfare surplus metric derived from this {\CE} for any choice as:

\begin{equation}
	\label{eq4:wsurplus}
	\Delta W_{nt} =  {\CE}_{nyt} - {\CE}_{n1t}^Z ,
\end{equation}

\noindent and the accumulated welfare surplus as:

\begin{equation}
	\label{eq4:wsurplusT}
	\Delta W_{nT} = \sum_{t=1}^T \left( {\CE}_{nyt} - {\CE}_{n1t}^Z \right)
\end{equation}

\noindent where the $y$ subscript indicates the option chosen (either 1 or 2 in the binary scenario we consider here), and the $Z$ superscript indicates the remaining, unchosen options, of which the {\CE} with the greatest value, designated by the subscript 1, is considered the foregone opportunity.

\textcite[106]{Harrison2016} consider an additional metric of forgone welfare surplus as the difference between the maximal {\CE} for every choice and the {\CE} of the option actually chosen by the subject
\begin{equation}
	\label{eq4:wforgone}
	\Delta F_{nt} = -1 \times \left( {\CE}_{n1t} - {\CE}_{nyt} \right) , 
\end{equation}

\noindent and the accumulated forgone welfare surplus

\begin{equation}
	\label{eq4:wforgoneT}
	\Delta F_{nT} = \sum_{t=1}^T  -1 \times \left( {\CE}_{n1t} - {\CE}_{nyt} \right)
\end{equation}

\noindent With these metrics, the best possible value for any subject is 0, which would indicate that all choices made were optimal, whereas any positive value indicates the amount of welfare surplus forgone by the subject due to choice errors.
These metrics line up easily with the metrics defined in equations (\ref{eq4:wsurplus}) and (\ref{eq4:wsurplusT}), as should $y_t \neq 1$, ${\CE}_{n1t}^Z = {\CE}_{n1t}$.

\textcite{Harrison2016} estimate values of the CRRA utility parameter, $r$, the probability weighting parameters, $\gamma, \alpha, \beta$, and the stochastic parameter $\lambda$, for each of the models presented above via maximum likelihood estimation (MLE) using the choices made by the subjects in the lottery task.
\textcite[107,110]{Harrison2016} initially calculate the welfare consequences of the choices made by each subject by using only the point estimates from the MLE, and then employ a bootstrap method which incorporates the covariance matrix of the standard errors.

For the bootstrap method, a multivariate normal distribution of parameter sets is bootstrapped from the estimates using the point estimates of these parameters as the means of the marginal distributions, and the covariance matrix of standard errors used as the covariance matrix of standard deviations.
For each subject's parameter estimates 500 draws of parameter sets were taken, the welfare metrics calculated for each set of parameters, and then the values of the metrics averaged across the 500 draws.
Since the covariance matrix used in the bootstrap method draws parameters from the joint distribution with respect to their density in the joint distribution, only a simple average is needed.

The experimental subjects consisted of 111 undergraduate students enrolled in several different colleges at Georgia State University, USA.
All experimental sessions were conducted in 2014 at the ExCEN experimental lab of Georgia State University.
Every subject received, and expected to receive, a guaranteed \money{5} show up fee, but no specific information about the experiment or expected earnings was communicated to the subjects before the experiment \parencite[98]{Harrison2016}.
The full set of instructions delivered to the subjects is available in Appendix C of \textcite{Harrison2016}.

\subsection{Individual Level Estimation}
\label{sec4:ILE}

HNG employ a multi-step process for picking a \enquote{winning} model for each subject.
First, all four models models cited in equations (\ref{eq4:pw:eut}), (\ref{eq4:pw:pow}), (\ref{eq4:pw:inv}), (\ref{eq4:pw:pre}) are estimated for each subject.
Next, data are dropped from analysis on the basis of \textit{ex ante} defined set of \enquote{exclusionary rules} applied to every model estimated on the subjects.
Finally, a \enquote{classification process} is employed to choose a model to categorize the subject as.
HNG propose 4 exclusionary rules:
\begin{itemize}
	\item Any estimate that didn't return a convergence code indicating both a gradient near 0 and a negative definite Hessian.
	\item Any model with a CRRA coefficient estimated to be greater than 15 or less than -15.
	\item $\mathit{RDU_{Pow}}$ and $\mathit{RDU_{Invs}}$ models where the $\gamma$ parameter was estimated to be greater than 5.
	\item Any model with a CRRA coefficient estimated to be greater than .99 and less than 1.01.
\end{itemize}

\noindent The gradient and Hessian conditions indicate that the estimates are at a local maximum of a concave portion of the likelihood function.
The next 2 rules indicate parameter values that although mathematically possible for the given functionals, nonetheless are considered to be extreme to the point of not being reliable.
\textcite{Wakker2008} details how the CRRA utility function has certain asymptotic properties around 1.
These properties may create numerical issues for the optimizer and so estimated values very near 1 are viewed as less credible and so are excluded from the analysis.

The classification process proposed by HNG applies to all the remaining, non-excluded data.
The log-likelihood function given in equation (\ref{eq4:ll}) is equally applicable to all four models considered by HNG, and seems a natural metric to declare a \enquote{winning} model among the 4 alternatives proposed.
However, since RDU models nest EUT as a special case (noted in equation \ref{eq4:pw:eut}), \textit{a priori} we would expect RDU models to produce greater log-likelihoods than an EUT model on any given dataset.
\textcite[102]{Harrison2016} note this issue and propose the additional qualification on RDU models that the probability weighting function implied by the estimated model must be statistically significantly different from a linear function, the special case of EUT, at the 10, 5, or 1 percent significance levels.

The null hypothesis for the $\mathit{RDU_{Pow}}$ and $\mathit{RDU_{Invs}}$ models is $H_0: \gamma = 1$, and the null for the $\mathit{RDU_{Prelec}}$ model is $H_0: \alpha = \beta = 1$.
Non-linear Wald tests are used to test these hypotheses.
Any RDU model that fails to reject the null hypothesis is removed from consideration as a \enquote{winning} model.
If the EUT model did not converge for the subject in question, the models considered will only consist of the RDU models which tested as different to EUT.
If the EUT model did not converge \textit{and} no RDU model tested as different to EUT, then all of the converged RDU models will be considered.
The \enquote{winning} model for each subject is chosen from among the models which have met criteria derived from the Wald test.
The winning model is then used to calculate the welfare consequences of the subject's choices on the insurance task.

When I utilize the same classification processes employed by \textcite{Harrison2016} on their data, we see a somewhat different distribution of subjects classified to the 4 models in Figure \ref{fig:HNG_pvals}.
These differences are relatively minor, showing somewhat more RDU subjects and less EUT subjects than reported by HNG.
Further details on differences are given in Appendix B (to be added).
I do however, replicate in Figure \ref{fig:HNG_CS} almost exactly the distribution of per-choice consumer surplus presented in Figure 10 of \textcite[108]{Harrison2016}.
This suggests a degree of leeway in the classification process in terms of its effect on the characterization of subjects.

\begin{figure}[h!]
	\center
	\caption{Classifying Subjects as EUT or RDU}
	%\caption{Estimates for each individual of EUT and RDU specifications \textcite[108]{Harrison2016} Data}
	\onlyinsubfile{
		\includegraphics[height=.25\paperheight]{figures/real/HNG_pvals.pdf}
	}
	\notinsubfile{
		\includegraphics[height=.25\paperheight]{ch4/figures/real/HNG_pvals.pdf}
	}
	\label{fig:HNG_pvals}
\end{figure}

\begin{figure}[h!]
	\center
	\caption{Distribution of Consumer Surplus, Using Data from \textcite{Harrison2016}}
	\onlyinsubfile{
		\includegraphics[height=.25\paperheight]{figures/real/HNG_CS.pdf}
	}
	\notinsubfile{
		\includegraphics[height=.25\paperheight]{ch4/figures/real/HNG_CS.pdf}
	}
	\label{fig:HNG_CS}
\end{figure}

\section{Individual Classification and Welfare Estimation Accuracy}
\label{sec4:IC}

Whether the results presented in Figure \ref{fig:HNG_pvals} demonstrate an accurate estimation of the proportions of subjects belonging to those models depends on our confidence in the classification process to correctly classify a subject as one of these four models, as well as our confidence that the subjects in the experiments actually belong to one of the four models we test for.
Our confidence that the classification process can correctly classify a subject in turn depends on the nature of the experimental instrument presented to the subject.

The degree of confidence of the classification process, and indeed most statistical tests in the economics literature, can be assessed through power analysis.
However, power analyses are rarely conducted in parallel with econometric estimations.
\textcite{McCloskey1996} find that only 4.4\% of the 181 papers published in \textit{The American Economic Review} considered the power of the test they were performing.
\textcite[6]{Zhang2013} review all papers published in the journal \textit{Experimental Economics} for the years 2010-2012, and find that no paper stated the optimal sample size for their analyses, and only one paper mentions power as an issue.

There are some examples of experimental economists utilizing power calculations to inform their analysis or experimental designs.
\textcite{Rutstrom2009} conduct a power analysis by simulating agent behavior in a matching pennies games and choosing payoffs that would result in the best chance of identifying the effect they sought to identify if it were there.
In this instance, \textcite{Rutstrom2009} conduct a power analysis in order to influence the design of their experiment.
\textcite[8]{Wilcox2015} conduct Monte Carlo simulations of agents responding to a lottery battery all of which operate the CRRA utility function, the $\mathit{RDU_{Prelec}}$ probability weighting function, and the CU stochastic model.
\textcite{Wilcox2015} designates four data generating processes (DGP) by specifying four parametrizations of these models and uses them to generate choice data, with each DGP making choices on the instrument 1000 times.
They then estimate non-parametric RDU models for each of the 1000 choice realizations per DGP and classify the resulting estimates into one of 5 categories, one for each of the DGP and an additional \enquote{unclassified} category.
This is an example of using power analysis to lend support to the researchers methods and conclusions, in this case, whether or not subjects actually operate an $\mathit{RDU_{Invs}}$ like probability weighting function.
Both of these kinds of analysis are useful for understanding the support and limitations of experimental research.

In this section, we interrogate the ability of the classification process to correctly classify subjects given the instrument presented in \textcite{Harrison2016}, and in turn how accurate the welfare calculations are given a classification.
I conduct this interrogation via a simulation analysis which resembles an extension of the Monte Carlo analysis performed by \textcite{Wilcox2015}.
I simulate subjects conforming to the EUT and $\mathit{RDU_{Prelec}}$ models, have these simulated subjects respond to both the lottery and insurance task, estimate the subjects' parameter sets given their responses to the lottery task, classify each subject based on the classification process employed by HNG described in the previous section, and calculate the welfare surplus for each subject based on the winning model.{\footnotemark}

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	I restrict the analysis to only EUT and $\mathit{RDU_{Prelec}}$ subjects and estimated models to improve the clarity of the discussion.
	However, choice data exist for $\mathit{RDU_{Pow}}$ and $\mathit{RDU_{Invs}}$ subjects and $\mathit{RDU_{Pow}}$ and $\mathit{RDU_{Invs}}$ model estimations exist for all subject models.
}

A simulated subject is represented by a single parameter set and an assigned operating model.
For each model, we employ the CRRA utility function defined in (\ref{eq4:CRRA}) and the CU stochastic model defined in equations (\ref{eq4:RE.2}) and (\ref{eq4:W.cu}).
For EUT subjects, the parameter set consists of $\lbrace r, \lambda \rbrace$, and for $\mathit{RDU_{Prelec}}$ subjects $\lbrace r, \alpha, \beta, \lambda \rbrace$.
The $r$ parameter in every set is the CRRA parameter from equation (\ref{eq4:CRRA}) and $\lambda$ is the precision parameter defined in equation (\ref{eq4:RE.2}).
The remaining $\alpha$, and $\beta$ parameters relate to the probability weighting parameters of the $\mathit{RDU_{Prelec}}$ model defined in equation (\ref{eq4:pw:pre}).

For each model, we draw parameter sets from a joint uniform distribution over the parameters needed for that model, where the marginal distributions are uncorrelated.{\footnotemark}
For both models, the marginal distribution for $r$ is where $r \in [-1, 0.95]$ and  for $\lambda$ is $\lambda \in [0.01, 0.30]$.
For the $\mathit{RDU_{Prelec}}$ model the marginal distribution for $\alpha$ and $\beta$ is where $\alpha \in [0.10, 2]$ and $\beta \in [0.10, 2]$.

We draw 250k parameter sets for each model for a total of 500k simulated subjects.
The number of draws from these joint distributions was chosen in an attempt to fill as much of the relevant parameter space as possible.{\footnotemark}
Each simulated subject uses the parameter set and operating model assigned to it to calculate the choice probabilities for each option in each lottery pair of the lottery task and the insurance task.
A random number is drawn from a univariate uniform distribution, and if the choice probability calculated for the $A$ option was greater than the random number, the subject chooses A, otherwise they choose B.
This process ensures that subjects' choices are made probabilistically with respect to the subjects' model and parameter set.{\footnotemark}

\addtocounter{footnote}{-3}
\stepcounter{footnote}\footnotetext{
	To create uncorrelated joint uniform distributions, uncorrelated normal distributions were generated using a Gaussian copula process.
	The inverse normal cumulative distribution function was then applied to each marginal distribution to get uncorrelated uniformly distributed variables in the $[0,1]$ space.
	These uniformly distributed variables were then stretched and shifted to fit the uniform spaces described here while retaining the 0 correlation coefficient.
	This process was employed to ensure that the (admittedly low) probability of accidental correlation that might occur from simply drawing from a uniform distribution directly was minimized.
}
\stepcounter{footnote}\footnotetext{
	A limitation of choosing the same number of draws for each model is that the square uniform space for the EUT model will have smaller gaps than the cubic space of the $\mathit{RDU_{Pow}}$ and $\mathit{RDU_{Invs}}$ models, which in turn have smaller gaps than the hypercubic space of the $\mathit{RDU_{Prelec}}$ model.
	The smaller the gaps between parameter sets in their joint space, the better the prediction accuracy of classifying subjects for the parameter sets that exist in the empty space.
}
\stepcounter{footnote}\footnotetext{
	Consider a choice probability for option $A$ calculated to be $0.90$, and therefore the choice probability for option $B$ is $0.10$.
	A random number drawn from a univariate uniform distribution has a 90\% chance of being below or equal to $0.90$, so option A would be chosen 90\% of the time by the simulated subject.
}

After the subjects have made choices, each of the models we consider is estimated for each subject on the choices made in the lottery task.
Any model which didn't converge with a gradient close to 0 and a negative definite Hessian matrix or converged on parameters outside of exclusionary rules defined in the previous section was also dropped from consideration.
Each subject was then classified based on the classification process defined in the previous section using a 5\% significance level.
If no model met the consideration criteria, the subject was classified \enquote{NA}.
The welfare surplus of the choices made on the insurance task are then calculated using the parameters of the winning model.

This process of classification simulation differs from that employed by \textcite{Wilcox2015} in that I simulate a total of 500k DGP, each producing a single set of choice data, whereas \textcite{Wilcox2015} simulate 4 GDP, each producing 1000 sets of choice data.
The approach of \textcite{Wilcox2015} allows for individual DGP to not be characterized by a single set of choices, while the approach I employ allows us to see how the power of the instrument changes with resect to a wide range of DGP.
The limitation of the approach I employ of only generating one choice data set per DGP I believe is mitigated by the large number of simulated subjects employed.
Consider an EUT subject with a CRRA parameter of 0.5 and a $\lambda$ value of 0.1.
There is only one choice dataset for this particular subject, but there are approximately 430 subjects, and thus 430 more choice datasets, in the range CRRA $\in (0.475,0.525)$, and $\lambda \in (0.09, 0.11)$.
If we can consider the choice probabilities for subjects in this range of parameters to be similar, we can have relatively accurate power estimations for subjects in this range.

\subsection{\texorpdfstring{\textcite{Harrison2016}}{Harrison and Ng (2016)} Classification Power}

With this assumption of similarity, we fit generalized additive models (GAM) \parencite{Hastie1986} to the classification data to make predictions of classification likelihoods.
First we subset the data based on the models the simulated subjects actually operate, either EUT or $\mathit{RDU_{Prelec}}$.
For each pooled group we fit a GAM model predicting whether EUT or $\mathit{RDU_{Prelec}}$ was the winning model, or if no model was declared a winner (all considered models failed the exclusionary rules).
\begin{align}
	\label{eq4:GAM}
	\begin{split}
		(winner = N | A = EUT)                   &= s(r) + s(\lambda)\\
		(winner = N | A = \mathit{RDU_{Prelec}}) &= s(r) + s(\alpha) + s(\beta) +s(\alpha, \beta) + s(r, \alpha, \beta) + s(\lambda)
	\end{split}
\end{align}

\noindent where $N$ is one of EUT, $\mathit{RDU_{Prelec}}$, or \enquote{NA}. and $s(\cdot)$ indicates some smooth, potentially non-linear function of its arguments.

The dependent variable in each of the GAM models in equation (\ref{eq4:GAM}) is either 1 if the subject was classified as model $N$, or 0 if the subject was not.
The independent variables in each model are smooth functions of the actual parameter values the subjects operates.
For every model, each parameter gets its own smooth function, and for the $\mathit{RDU_{Prelec}}$ model, the probability weighting parameters are additionally interacted with the CRRA parameter and each other.
Thus, 3 fitted GAM models for each of the two model types in the population, resulting in 6 fitted models in total.
I repeat this process but drop subjects that were classified as \enquote{NA} from the data before fitting the models.
This results in 4 additional models.
Given the fitted models and a parameter set for $M$, we can use a fitted GAM model to predict the probability that a subject with the given parameter set will be classified as any of the $N$ models.
The results of this fitting process are presented in Figures \ref{fig:HNG1_win_mu}, \ref{fig:HNG1_win_eut}, and \ref{fig:HNG1_win_pre}.

\begin{figure}[hp!]
	\center
	\caption{Probability of \enquote{Winning} for Given $\lambda$ Values}
	\onlyinsubfile{
		\includegraphics[width=\textwidth]{figures/HNG_1/win_05-all-win-HNG_1.pdf}
		%\includegraphics[height=.5\paperheight, width=\textwidth]{figures/mu-winners-HNG_1.pdf}
	}
	\notinsubfile{
		\includegraphics[width=\textwidth]{ch4/figures/HNG_1/win_05-all-win-HNG_1.pdf}
	}
	\label{fig:HNG1_win_mu}
\end{figure}

\begin{figure}[hp!]
	\center
	\caption{Probability of \enquote{Winning} for EUT subjects}
	\onlyinsubfile{
		\includegraphics[width=\textwidth]{figures/HNG_1/win_05-EUT-win-HNG_1.pdf}
		%\includegraphics[height=.5\paperheight, width=\textwidth]{figures/mu-winners-HNG_1.pdf}
	}
	\notinsubfile{
		\includegraphics[width=\textwidth]{ch4/figures/HNG_1/win_05-EUT-win-HNG_1.pdf}
	}
	\label{fig:HNG1_win_eut}
\end{figure}

\begin{figure}[hp!]
	\center
	\caption{Probability of \enquote{Winning} for $\mathit{RDU_{Prelec}}$ subjects}
	\onlyinsubfile{
		\includegraphics[width=\textwidth]{figures/HNG_1/win_05-PRE-win-HNG_1.pdf}
		%\includegraphics[height=.5\paperheight, width=\textwidth]{figures/mu-winners-HNG_1.pdf}
	}
	\notinsubfile{
		\includegraphics[width=\textwidth]{ch4/figures/HNG_1/win_05-PRE-win-HNG_1.pdf}
	}
	\label{fig:HNG1_win_pre}
\end{figure}

In Figures \ref{fig:HNG1_win_mu}, \ref{fig:HNG1_win_eut}, and \ref{fig:HNG1_win_pre} the X-axis is the simulated subjects' values of the parameter for that plot, and the Y-axis is the probability that a given model was declared the winner.
In each Figure the solid, red line indicates the estimates for the EUT model, the dotted, green line indicates the estimates for the $\mathit{RDU_{Prelec}}$ model, and the short dashed, blue line indicates the estimates for non-convergence or excluded.
In all figures, the 95\% confidence interval is given by the long dashed lines surrounding the lines given above.
In each Figure, the second row contains estimates derived from all the subjects, while the first row only contains estimates derived from subjects that were classified as either EUT or $\mathit{RDU_{Prelec}}$.

In Figure \ref{fig:HNG1_win_mu}, the first column contains estimates for EUT subjects, while the second column contains estimates for $\mathit{RDU_{Prelec}}$ subjects.
The X-axis of this figure is the value of the $\lambda$ parameter.
Thus, the top-left plot shows how the probability of an EUT subject with a converged model is classified as either EUT or $\mathit{RDU_{Prelec}}$ for a range of $\lambda$ values.
In Figures \ref{fig:HNG1_win_eut} and \ref{fig:HNG1_win_pre}, the columns indicate the parameter given on the X-axis.
Thus, in Figure \ref{fig:HNG1_win_eut}, the top-left plot shows how the probability of an EUT subject with a converged model is classified as either EUT or $\mathit{RDU_{Prelec}}$ for a range of CRRA values.
In Figure \ref{fig:HNG1_win_pre}, the bottom-right plot shows how the probability of an $\mathit{RDU_{Prelec}}$ subject is classified as either EUT, $\mathit{RDU_{Prelec}}$, or \enquote{NA} for a range of $\beta$ values.

In Figure \ref{fig:HNG1_win_eut} and in the left column of Figure \ref{fig:HNG1_win_mu}, the red solid line shows the probability of EUT subjects being correctly classified as EUT.
In Figure \ref{fig:HNG1_win_pre} and in the right column of Figure \ref{fig:HNG1_win_mu}, the green dotted line shows the probability of $\mathit{RDU_{Prelec}}$ subjects being correctly classified as $\mathit{RDU_{Prelec}}$.

The results presented in Figures \ref{fig:HNG1_win_mu}, \ref{fig:HNG1_win_eut} and \ref{fig:HNG1_win_pre} offer some surprising and intuitive results.
In Figure \ref{fig:HNG1_win_mu} we see that the likelihood EUT subjects being misclassified as $\mathit{RDU_{Prelec}}$, $\mathit{RDU_{Prelec}}$ subjects being misclassified as EUT, and either type of subject failing to produce any estimates that pass the exclusionary criteria increases with $\lambda$.
This is very intuitive. 
As the $\lambda$ parameter increases, the likelihood that a subject makes a choice error increases.
For EUT subjects, these choices errors can present as probability weighting when there is none, and for $\mathit{RDU_{Prelec}}$ subjects these choice errors can present as linear probability weighting.
Another way to characterize this effect is to say that as $\lambda$ increases the noise in the data increases, indeed, as $\lambda \to \infty$ choice probabilities for every option are equal, resulting in totally random data.
The more noise there is in the data, the lower the likelihood of the optimizer converging on reasonable, or any, estimates.

Additionally, in in the third and fourth columns of Figure \ref{fig:HNG1_win_pre} we have additionally intuitive results.
We can see in these columns that the probability of an $\mathit{RDU_{Prelec}}$ subject being misclassified as EUT peaks when the probability weighting parameters approach the value of 1.
Since the $\mathit{RDU_{Prelec}}$ model nests EUT when $\alpha = \beta = 1$, we should expect the likelihood of misclassification to increase around these values.

%Recall, however, that the parameters for our simulated subjects were distributed uniformly over the parameter space of interest.
%This means that for the simulated subjects with $\alpha$ values between $(0.95, 1.05)$, 95\% of them will have $\beta$ values outside the range $(0.95, 1.05)$, and for for the simulated subjects with $\alpha$ values between $(0.9, 1.1)$, 90\% of them will have $\beta$ values outside the range $(0.9, 1.1)$,
%Thus, the vast majority of simulated subjects that are misclassified as EUT when one probability weighting parameter equals 1 still have some degree of probability weighting driven by the other parameter.






%\subsubsection{Case 2}
%
%In this case, rather than plot the results across a range of values, we can instead tabulate each element of equation (\ref{eq4:bayes}) assuming a 5\% significance level for the classification process.
%
%\onlyinsubfile{
%\begin{table}[ht!]
%	\centering
%	\captionsetup{justification=centering}
%	\caption{$P(A)$}
%	\label{tb:HNG1_PA}
%	\begin{adjustbox}{}
%	\pgfplotstabletypeset[
%		col sep=comma,
%		every head row/.style={
%			after row=\hline
%		},
%		display columns/0/.style={
%			precision = 2,
%			fixed,
%			zerofill,
%			column name = {EUT}
%		},
%		display columns/1/.style={
%			precision = 2,
%			fixed,
%			zerofill,
%			column name = {Power}
%		},
%		display columns/2/.style={
%			precision = 2,
%			fixed,
%			zerofill,
%			column name = {Inverse-S}
%		},
%		display columns/3/.style={
%			precision = 2,
%			fixed,
%			zerofill,
%			column name = {Prelec}
%		},
%	]{tables/HNG_1-PA.csv} % path/to/file
%	\end{adjustbox}
%\end{table}
%%\bigskip
%\begin{table}[ht!]
%	\centering
%	\captionsetup{justification=centering}
%	\caption{$P(B)$}
%	\label{tb:HNG1_PB}
%	\begin{adjustbox}{}
%	\pgfplotstabletypeset[
%		col sep=comma,
%		every head row/.style={
%			after row=\hline
%		},
%		display columns/0/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {EUT}
%		},
%		display columns/1/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {Power}
%		},
%		display columns/2/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {Inverse-S}
%		},
%		display columns/3/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {Prelec}
%		},
%	]{tables/HNG_1-PB.csv} % path/to/file
%	\end{adjustbox}
%\end{table}
%%\bigskip
%\begin{table}[ht!]
%	\centering
%	\captionsetup{justification=centering}
%	\caption{$P(B | A)$}
%	\label{tb:HNG1_PBA}
%	\begin{adjustbox}{}
%	\pgfplotstabletypeset[
%		col sep=comma,
%		every head row/.style={
%			before row={
%				&
%				\multicolumn{4}{c}{Classified Model (B)}\\
%			},
%			after row=\hline
%		},
%		display columns/0/.style={
%			assume math mode = true,
%			string type,
%			column name = {}
%		},
%		display columns/1/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {EUT}
%		},
%		display columns/2/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {Power}
%		},
%		display columns/3/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {Inverse-S}
%		},
%		display columns/4/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {Prelec}
%		},
%	]{tables/HNG_1-PBA.csv} % path/to/file
%	\end{adjustbox}
%\end{table}
%%\bigskip
%\begin{table}[ht!]
%	\centering
%	\captionsetup{justification=centering}
%	\caption{$P(A | B)$}
%	\label{tb:HNG1_PAB}
%	\begin{adjustbox}{}
%	\pgfplotstabletypeset[
%		col sep=comma,
%		every head row/.style={
%			before row={
%				\cnline{} &
%				\multicolumn{4}{c}{Classified Model (B)}\\
%			},
%			after row=\hline
%		},
%		display columns/0/.style={
%			assume math mode = true,
%			string type,
%			column name = {}
%		},
%		display columns/1/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {EUT}
%		},
%		display columns/2/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {Power}
%		},
%		display columns/3/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {Inverse-S}
%		},
%		display columns/4/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {Prelec}
%		},
%	]{tables/HNG_1-PAB.csv} % path/to/file
%	\end{adjustbox}
%\end{table}
%}
%\notinsubfile{
%\begin{table}[ht!]
%	\centering
%	\captionsetup{justification=centering}
%	\caption{$P(A)$}
%	\label{tb:HNG1_PA}
%	\begin{adjustbox}{}
%	\pgfplotstabletypeset[
%		col sep=comma,
%		every head row/.style={
%			after row=\hline
%		},
%		display columns/0/.style={
%			precision = 2,
%			fixed,
%			zerofill,
%			column name = {EUT}
%		},
%		display columns/1/.style={
%			precision = 2,
%			fixed,
%			zerofill,
%			column name = {Power}
%		},
%		display columns/2/.style={
%			precision = 2,
%			fixed,
%			zerofill,
%			column name = {Inverse-S}
%		},
%		display columns/3/.style={
%			precision = 2,
%			fixed,
%			zerofill,
%			column name = {Prelec}
%		},
%	]{ch4/tables/HNG_1-PA.csv} % path/to/file
%	\end{adjustbox}
%\end{table}
%%\bigskip
%\begin{table}[ht!]
%	\centering
%	\captionsetup{justification=centering}
%	\caption{$P(B)$}
%	\label{tb:HNG1_PB}
%	\begin{adjustbox}{}
%	\pgfplotstabletypeset[
%		col sep=comma,
%		every head row/.style={
%			after row=\hline
%		},
%		display columns/0/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {EUT}
%		},
%		display columns/1/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {Power}
%		},
%		display columns/2/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {Inverse-S}
%		},
%		display columns/3/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {Prelec}
%		},
%	]{ch4/tables/HNG_1-PB.csv} % path/to/file
%	\end{adjustbox}
%\end{table}
%%\bigskip
%\begin{table}[ht!]
%	\centering
%	\captionsetup{justification=centering}
%	\caption{$P(B | A)$}
%	\label{tb:HNG1_PBA}
%	\begin{adjustbox}{}
%	\pgfplotstabletypeset[
%		col sep=comma,
%		every head row/.style={
%			before row={
%				\cnline{} &
%				\multicolumn{4}{c}{Classified Model (B)}\\
%			},
%			after row=\hline
%		},
%		display columns/0/.style={
%			assume math mode = true,
%			string type,
%			column name = {}
%		},
%		display columns/1/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {EUT}
%		},
%		display columns/2/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {Power}
%		},
%		display columns/3/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {Inverse-S}
%		},
%		display columns/4/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {Prelec}
%		},
%	]{ch4/tables/HNG_1-PBA.csv} % path/to/file
%	\end{adjustbox}
%\end{table}
%%\bigskip
%\begin{table}[ht!]
%	\centering
%	\captionsetup{justification=centering}
%	\caption{$P(A | B)$}
%	\label{tb:HNG1_PAB}
%	\begin{adjustbox}{}
%	\pgfplotstabletypeset[
%		col sep=comma,
%		every head row/.style={
%			before row={
%				 &
%				\multicolumn{4}{c}{Classified Model (B)}\\
%			},
%			after row=\hline
%		},
%		display columns/0/.style={
%			assume math mode = true,
%			string type,
%			column name = {}
%		},
%		display columns/1/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {EUT}
%		},
%		display columns/2/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {Power}
%		},
%		display columns/3/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {Inverse-S}
%		},
%		display columns/4/.style={
%			precision = 3,
%			fixed,
%			zerofill,
%			column name = {Prelec}
%		},
%	]{ch4/tables/HNG_1-PAB.csv} % path/to/file
%	\end{adjustbox}
%\end{table}
%}
%
%\break
%
%In Table \ref{tb:HNG1_PA} we have the probability that any given subject drawn from our hypothetical population will belong to the model given by the columns.
%This is equal to the proportion of each model we specified initially.
%In Table \ref{tb:HNG1_PB} we have the probability that a subject drawn at random from our hypothetical population will be classified as the model given by the columns.
%In Table \ref{tb:HNG1_PBA} we have the probability that a subject will be classified as the column model, given that they actually operate the row model.
%The rows of this table therefore sum to 1.
%In Table \ref{tb:HNG1_PAB} we have the probability that a subject actually operates the row model, given that they have been classified as the column model.
%The columns of this table therefore sum to 1.

\subsection{\texorpdfstring{\textcite{Harrison2016}}{Harrison and Ng (2016)} Insurance Task Welfare Expectations}
\label{sec4:WT}

The conditional probabilities provided in Figure \ref{fig:HNG1_mu_PBA} and tables \ref{tb:HNG1_PBA} and \ref{tb:HNG1_PAB} are useful in terms of describing the degree of success the classification process has in correctly identifying the model operated by a subject.
The classification process itself however is only useful to economists in as much as it provides us with a model that allows us to make normative characterizations of subjects' choices.
Given our simulation process, we can measure the success of the classification process in normative terms by calculating the difference in the estimated welfare surplus of the choices made in the \textcite{Harrison2016} insurance task against actual welfare surplus for each subject.

Utilizing the definition of accumulated welfare surplus is given by equation (\ref{eq4:wsurplusT}), we follow \textcite[110-111]{Harrison2016} and bootstrap the estimated welfare surplus of the subjects.
We generate 500 random draws from a multivariate normal distribution using the point estimates of the parameters of the winning model as the means of the marginal distributions, and the inverse of the estimated Hessian matrix as the covariance matrix.
With each draw we calculate equation (\ref{eq4:wsurplusT}) and define the estimated welfare surplus as the average of these 500 calculations.
Therefore the difference between the estimated and real welfare is given by:

\begin{equation}
	\label{eq4:wsurplusDiff}
	D_N = \Delta W_{nT}(\hat{\Omega}_N) - \Delta W_{nT}(\Omega)
\end{equation}

\noindent where $N$ is the model the subject has been classified as operating, $\Omega$ is the set of parameters that define the utility function actually employed by subject $n$, and $\hat{\Omega}_N$ is the set of estimated parameters for model $N$ for subject $n$.
If the subject has been misclassified, $\Omega$ and $\hat{\Omega}_N$ will not represent the same set of parameters.

Just as above, we will present 2 cases of equation (\ref{eq4:wsurplusDiff}).
In Case 1, we group subjects by the model they actually operate, and calculate equation (\ref{eq4:wsurplusDiff}) for each subject using the estimated parameters of the model the subject was classified as operating at the 5\% significance level.
In Case 2, we will utilize the same hypothetical population as before, fit GAM models to the simulated data, and predict the difference in welfare surplus for the hypothetical population:

\begin{align}
	\label{eq4:GAM_welfare}
	\begin{split}
		(D_{N,M} | M &= EUT)                   = s(r) + s(\lambda)\\
		(D_{N,M} | M &= \mathit{RDU_{Pow}})    = s(r) + s(\gamma) + s(r, \gamma) + s(\lambda)\\
		(D_{N,M} | M &= \mathit{RDU_{Invs}})   = s(r) + s(\gamma) + s(r, \gamma) + s(\lambda)\\
		(D_{N,M} | M &= \mathit{RDU_{Prelec}}) = s(r) + s(\alpha) + s(\beta) +s(\alpha, \beta) + s(r, \alpha, \beta) + s(\lambda)
	\end{split}
\end{align}

\noindent where $N$ indicates the model that the subject was classified as, $M$ indicates the model the subject actually operates, and $s(\cdot)$ indicates some smooth, potentially non-linear function of its arguments.
Thus 16 fitted models, one for each combination of 4 $M$ models and 4 $N$ models.
As was done in the previous section, we draw a sample of $100,000$ subjects from the joint population distribution defined in the previous section, with $100,000 \times 0.5 = 50,000$ EUT subjects, $100,000 \times 0.1 = 10,000$ $\mathit{RDU_{Pow}}$ and $\mathit{RDU_{Invs}}$ subjects, and $100,000 \times 0.3 = 30,000$ $\mathit{RDU_{Prelec}}$ subjects.
For each of the sampled subjects, we fit the model from equation (\ref{eq4:GAM_welfare}) corresponding the model $M$ they actually operate for each of the four $N$ models they could potentially be classified as operating.
This gives us the welfare surplus difference for each possible classification for every subject.

\subsubsection{Case 1}

First we present the welfare surplus difference for the subjects operating $\mathit{RDU_{Pow}}$ and $\mathit{RDU_{Invs}}$ models in Figure \ref{fig:HNG1_POW_INV_welfare}, and then for the subjects operating EUT and $\mathit{RDU_{Prelec}}$ models in \ref{fig:HNG1_EUT_PRE_welfare}.
The left column of Figure \ref{fig:HNG1_POW_INV_welfare} plots the difference in welfare surplus for $\mathit{RDU_{Pow}}$ and the right column plots the difference in welfare surplus for $\mathit{RDU_{Invs}}$.
Each row represents subjects grouped by their $\lambda$ parameter, with the top row containing subjects with $0.01 < \lambda < 0.10$, the middle row containing $0.1 < \lambda < 0.2$, and the bottom row $0.2 < \lambda < 0.3$.
Thus, in the top left plot, we have subjects that operate a $\mathit{RDU_{Pow}}$ model with $0.01 < \lambda < 0.10$.
Likewise, the bottom right plot shows subjects that operate a $\mathit{RDU_{Invs}}$ model with $0.2 < \lambda < 0.3$.
The four lines in each plot show the calculated welfare surplus difference for subjects who were classified as operating each of the four possible models and how this difference changes with the probability weighting parameter for each model.

Similarly, the left column of \ref{fig:HNG1_EUT_PRE_welfare} shows subjects that operate an EUT model, while the middle and right columns show subjects that operate a $\mathit{RDU_{Prelec}}$ model.
The left column plots the welfare surplus difference by the CRRA parameter for the EUT subjects, while the middle column plots the welfare surplus difference by the $\alpha$ probability weighting parameter and the right column plots the welfare surplus difference by the $\beta$ probability weighing parameter for $\mathit{RDU_{Prelec}}$ subjects.
Again, each row represents subjects grouped by their $\lambda$ parameter, with the top row containing subjects with $0.01 < \lambda < 0.10$, the middle row containing $0.1 < \lambda < 0.2$, and the bottom row $0.2 < \lambda < 0.3$.
Thus, the top leftmost plot shows subjects that operate a EUT model with $0.01 < \lambda < 0.10$, and the bottom right plot shows subjects that operate a $\mathit{RDU_{Pow}}$ model with $0.2 < \lambda < 0.3$.

Unlike Figure \ref{fig:HNG1_POW_INV_welfare}, Figure \ref{fig:HNG1_EUT_PRE_welfare} does not display subjects that were classified as $\mathit{RDU_{Invs}}$ as there were too few subjects to draw meaningful plots.
For instance, of the subjects that operate a $\mathit{RDU_{Prelec}}$ model with $0.01 < \lambda < 0.10$, thus the top middle and rightmost plots, there were only 12 subjects that were classified as operating a $\mathit{RDU_{Invs}}$ model.
This is compared to 25,678 subjects that were classified as operating an EUT model, 5,546 as operating an $\mathit{RDU_{Pow}}$ model, and 42,480 as operating a $\mathit{RDU_{Prelec}}$ model.

As was done in Figures \ref{fig:HNG1_pre_a_win} and \ref{fig:HNG1_pre_b_win}, the middle column of Figure \ref{fig:HNG1_EUT_PRE_welfare} does not contain subjects that have $\beta$ parameters greater than 0.8 and less than 1.2, and the right column of Figure \ref{fig:HNG1_EUT_PRE_welfare} does not contain subjects that have $\alpha$ parameters greater than 0.8 and less than 1.
It is important to note that no plot within either Figure \ref{fig:HNG1_POW_INV_welfare} or \ref{fig:HNG1_EUT_PRE_welfare} share a y-axis scale with any other plot.
The difference in welfare surplus changes greatly from model to model and from parameter to parameter, keeping all plots on the same y-axis scale would hide some of the nuance of these differences.

\begin{figure}[hp!]
	\center
	\caption{$P(B|RDU_{Prelec})$ for Given $\beta$ Values}
	\onlyinsubfile{
		\includegraphics[width=\textwidth]{figures/pi-welfare5.pdf}
		%\includegraphics[width=\textwidth, height=.6\paperheight]{figures/pre-welfare5.pdf}
	}
	\notinsubfile{
		\includegraphics[width=\textwidth]{ch4/figures/pi-welfare5.pdf}
		%\includegraphics[height=.3\paperheight]{ch4/figures/pre-welfare5.pdf}
	}
	\label{fig:HNG1_POW_INV_welfare}
\end{figure}

\begin{figure}[hp!]
	\center
	\caption{$P(B|RDU_{Prelec})$ for Given $\beta$ Values}
	\onlyinsubfile{
		\includegraphics[width=\textwidth]{figures/ep-welfare5.pdf}
		%\includegraphics[width=\textwidth, height=.6\paperheight]{figures/pre-welfare5.pdf}
	}
	\notinsubfile{
		\includegraphics[width=\textwidth]{ch4/figures/ep-welfare5.pdf}
		%\includegraphics[height=.3\paperheight]{ch4/figures/pre-welfare5.pdf}
	}
	\label{fig:HNG1_EUT_PRE_welfare}
\end{figure}

\subsubsection{Case 2}

In Case 2, we present the predicted welfare surplus difference for our hypothetical population given the GAM models defined in equiation (\ref{eq4:GAM_welfare}).
Table \ref{tb:HNG1_wsum} shows the average welfare surplus difference for subjects operating the models given by the rows, but classified as the models given by the columns.
This, the top rightmost cell shows the average weflare surplus for subjects who operate an EUT model and were correctly classified as operating an EUT model, while the top rightmost column shows the average welfare surplus of subjects who operate a EUT model by were classified as operating a $\mathit{RDU_{Prelec}}$ model.

Table \ref{tb:HNG1_PBA_wel} shows the expected average welfare surplus difference for subjects who actually operate the models given.
This is defined by first multiplying element-wise the matrix given by table \ref{tb:HNG1_PBA} and the matrix given in table \ref{tb:HNG1_wsum}, and then summing each row of the resulting matrix:

\begin{equation}
	\label{eq4:PBA_wel}
	E [ D_{NM} | M ] = \sum^N P(B = N | A = M) \times D_{NM}
\end{equation}

Table \ref{tb:HNG1_PAB_wel} shows the expected average welfare surplus difference for subjects who were classified as operating the models given.
This is defined by first multiplying element-wise the matrix given by table \ref{tb:HNG1_PAB} and the matrix given in table \ref{tb:HNG1_wsum}, and then summing each column of the matrix:

\begin{equation}
	\label{eq4:PBA_wel2}
	E [ D_{NM} | N ] = \sum^M P(A = M | B = N) \times D_{NM}
\end{equation}


\onlyinsubfile{
\begin{table}[ht!]
	\centering
	\captionsetup{justification=centering}
	\caption{Welfare Surplus Difference by Model and Classification}
	\label{tb:HNG1_wsum}
	\begin{adjustbox}{}
	\pgfplotstabletypeset[
		col sep=comma,
		every head row/.style={
			before row={
				&
				\multicolumn{4}{c}{Classified Model (B)}\\
			},
			after row=\hline
		},
		display columns/0/.style={
			assume math mode = true,
			string type,
			column name = {}
		},
		display columns/1/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {EUT}
		},
		display columns/2/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Power}
		},
		display columns/3/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Inverse-S}
		},
		display columns/4/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Prelec}
		},
	]{tables/HNG_1-wsum.csv} % path/to/file
	\end{adjustbox}
\end{table}
%\bigskip
\begin{table}[ht!]
	\centering
	\captionsetup{justification=centering}
	\caption{Expected Welfare Surplus Difference, Given Operating Model}
	\label{tb:HNG1_PBA_wel}
	\begin{adjustbox}{}
	\pgfplotstabletypeset[
		col sep=comma,
		every head row/.style={
			after row=\hline
		},
		display columns/0/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {EUT}
		},
		display columns/1/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {Power}
		},
		display columns/2/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {Inverse-S}
		},
		display columns/3/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {Prelec}
		},
	]{tables/HNG_1-PBA-wel.csv} % path/to/file
	\end{adjustbox}
\end{table}
%\bigskip
\begin{table}[ht!]
	\centering
	\captionsetup{justification=centering}
	\caption{Expected Welfare Surplus Difference, Given Classification Model}
	\label{tb:HNG1_PAB_wel}
	\begin{adjustbox}{}
	\pgfplotstabletypeset[
		col sep=comma,
		every head row/.style={
			after row=\hline
		},
		display columns/0/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {EUT}
		},
		display columns/1/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {Power}
		},
		display columns/2/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {Inverse-S}
		},
		display columns/3/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {Prelec}
		},
	]{tables/HNG_1-PAB-wel.csv} % path/to/file
	\end{adjustbox}
\end{table}
}
\notinsubfile{
\begin{table}[ht!]
	\centering
	\captionsetup{justification=centering}
	\caption{Welfare Surplus Difference by Model and Classification}
	\label{tb:HNG1_wsum}
	\begin{adjustbox}{}
	\pgfplotstabletypeset[
		col sep=comma,
		every head row/.style={
			before row={
				&
				\multicolumn{4}{c}{Classified Model (B)}\\
			},
			after row=\hline
		},
		display columns/0/.style={
			assume math mode = true,
			string type,
			column name = {}
		},
		display columns/1/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {EUT}
		},
		display columns/2/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Power}
		},
		display columns/3/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Inverse-S}
		},
		display columns/4/.style={
			precision = 3,
			fixed,
			zerofill,
			column name = {Prelec}
		},
	]{ch4/tables/HNG_1-wsum.csv} % path/to/file
	\end{adjustbox}
\end{table}
%\bigskip
\begin{table}[ht!]
	\centering
	\captionsetup{justification=centering}
	\caption{Expected Welfare Surplus Difference, Given A}
	\label{tb:HNG1_PBA_wel}
	\begin{adjustbox}{}
	\pgfplotstabletypeset[
		col sep=comma,
		every head row/.style={
			after row=\hline
		},
		display columns/0/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {EUT}
		},
		display columns/1/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {Power}
		},
		display columns/2/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {Inverse-S}
		},
		display columns/3/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {Prelec}
		},
	]{ch4/tables/HNG_1-PBA-wel.csv} % path/to/file
	\end{adjustbox}
\end{table}
%\bigskip
\begin{table}[ht!]
	\centering
	\captionsetup{justification=centering}
	\caption{Expected Welfare Surplus Difference, Given B}
	\label{tb:HNG1_PAB_wel}
	\begin{adjustbox}{}
	\pgfplotstabletypeset[
		col sep=comma,
		every head row/.style={
			after row=\hline
		},
		display columns/0/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {EUT}
		},
		display columns/1/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {Power}
		},
		display columns/2/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {Inverse-S}
		},
		display columns/3/.style={
			precision = 2,
			fixed,
			zerofill,
			column name = {Prelec}
		},
	]{ch4/tables/HNG_1-PAB-wel.csv} % path/to/file
	\end{adjustbox}
\end{table}
}

\subsubsection{Discussion}

The discussion about how the classification process relates to the welfare surplus of the subject being classified is in many ways more important than the previous discussion of the accuracy of the process itself.
This is because economists distinguish themselves from decision theorists by making normative statements about how an individuals economic choices relate to their economic well-being.
The accuracy of the classification process is valuable in only as much as it can aid in the accuracy of the normative statements we can construct using this process.
\textcite[25]{Leamer2012} makes a similar statement when discussing the general fallibility of macroeconomic models: \enquote{Fortunately, our goal as economists is not soundness, but usefulness.}

From Figures \ref{fig:HNG1_POW_INV_welfare} and \ref{fig:HNG1_EUT_PRE_welfare}, we can see that there are parameter values for every model where the welfare surplus difference is not noticeably different between correctly and incorrectly classified subjects, and in some cases the welfare surplus difference for misclassified subjects is closer to 0 than for correctly classified subjects.
In the right column of Figure \ref{fig:HNG1_POW_INV_welfare}, representing subjects that actually operate the $\mathit{RDU_{Invs}}$ model, we see that for values of $\gamma$ greater than roughly 0.75, subjects that have been misclassified as one of the three alternative models generally have welfare surplus estimates that are closer to the real welfare surplus than subjects that have been correctly classified as operating a $\mathit{RDU_{Invs}}$ model.
In the left column of Figure \ref{fig:HNG1_POW_INV_welfare}, representing subjects that actually operate the $\mathit{RDU_{Pow}}$ model, we see that subjects that have been misclassified as operating an EUT model have welfare surplus estimates that are close to the real welfare surplus of the subjects for most values of $\gamma$, but in particular for values of $\gamma$ greater than 0.75.
In fact, for the middle and bottom rows of the left column of Figure \ref{fig:HNG1_POW_INV_welfare}, representing subjects with increasingly greater $\lambda$ values, we see that as $\gamma$ increases beyond 1.5, subjects that have been misclassified as EUT have welfare surplus differences closer to 0 than subjects that have been correctly classified as $\mathit{RDU_{Pow}}$.
Table \ref{tb:HNG1_wsum} shows that subjects that actually operate a $\mathit{RDU_{Invs}}$ model but have been classified as operating a $\mathit{RDU_{Pow}}$ model on average have welfare surplus estimates closer to their real welfare surplus than the subjects that have been correctly classified as operating a $\mathit{RDU_{Invs}}$ model.

That misclassified subjects in these cases have welfare surplus estimates relatively close to the subjects' real welfare surplus demonstrates that even though the classification process has not been accurate for these subjects, it nonetheless can be useful when used to characterize the welfare surplus of subjects' choices in the insurance task.
This is good news with respect to subjects actually operating the $\mathit{RDU_{Pow}}$ model and especially the $\mathit{RDU_{Invs}}$ model given the particularly low probability of correctly identifying subjects as operating either of these models.

However, Figures \ref{fig:HNG1_POW_INV_welfare} and \ref{fig:HNG1_EUT_PRE_welfare} also show that for wide ranges of parameter values, misclassified subjects have welfare surplus estimates that are significantly different from the real welfare surplus and are farther from the real welfare surplus estimates than the correctly classified subjects.
This is evident in the right column of Figure \ref{fig:HNG1_POW_INV_welfare}, representing subjects that actually operate the $\mathit{RDU_{Invs}}$ model, for values of $\gamma$ less than 0.75.
We see in this column that as $\gamma$ gets closer to 0, and thus representing an increasing amount of probability weighting, subjects that have been misclassified as EUT have particularly poor welfare surplus characterizations.
This poor characterization of welfare surplus is also true for the subjects that have been misclassified as $\mathit{RDU_{Pow}}$ and $\mathit{RDU_{Prelec}}$, but to a lesser extent, with subjects misclassified as $\mathit{RDU_{Prelec}}$ faring the best among the misclassified subjects.
We see in to a much less dramatic extent in the left column of Figure \ref{fig:HNG1_POW_INV_welfare}, which represents subjects that actually operate the $\mathit{RDU_{Pow}}$ model, that as $\gamma$ decreases, $\mathit{RDU_{Pow}}$ subjects that have been misclassified have welfare surplus estimates that increasingly diverge from the real welfare surplus, and correctly classified subjects start to outperform their incorrectly classified counterparts.

In Figure \ref{fig:HNG1_EUT_PRE_welfare}, we see that for almost all parameter values, subjects that have been correctly classified as operating either the EUT or $\mathit{RDU_{Prelec}}$ models have welfare surplus estimates that are closer to the real estimates than subjects that have been misclassified as operating an alternative model.
In the middle column of Figure \ref{fig:HNG1_EUT_PRE_welfare}, representing subjects actually operating the $\mathit{RDU_{Prelec}}$ model, we see that for values of $\alpha$ less than 1, subjects that have been misclassified as operating an EUT model, and to a much lesser extent a $\mathit{RDU_{Pow}}$ model, have welfare surplus estimates that rapidly diverge from the real surplus value.
In the right column of Figure \ref{fig:HNG1_EUT_PRE_welfare}, we see generally that as $\beta$ increases past 1, the subjects that have been incorrectly classified as operating a EUT model also have welfare surplus estimates that increasingly differ from the real welfare surplus, but this divergence is of roughly the same magnitude seen in the middle column of Figure \ref{fig:HNG1_EUT_PRE_welfare} as $\alpha$ increases above 1.

That subjects actually operating a $\mathit{RDU_{Prelec}}$ model are badly characterized by an EUT model when they have probability weighing parameters that differ greatly from 1 should not be surprising.
The $\mathit{RDU_{Prelec}}$ model is the most flexible of the three RDU models considered here, which allows it to fit data well, but also means there are more opportunities for misclassification as EUT or $\mathit{RDU_{Pow}}$ to matter in meaningful ways.

This is apparent in tables \ref{tb:HNG1_wsum}, \ref{tb:HNG1_PBA_wel} and \ref{tb:HNG1_PAB_wel}.
In the fourth row of table \ref{tb:HNG1_wsum}, representing subjects that actually operate the $\mathit{RDU_{Prelec}}$ model, we see that misclassified subjects, represented in the first, second, and third columns, have much more negative welfare surplus difference estimates than subjects that were correctly classified as operating the $\mathit{RDU_{Prelec}}$ model.
In table \ref{tb:HNG1_PBA} we see that the probability of a subject operating a $\mathit{RDU_{Prelec}}$ model being misclassified as operating a EUT model is actually .549, which means that the majority of subjects that actually operate the $\mathit{RDU_{Prelec}}$ model will have welfare surplus characterizations that differ greatly from their real welfare surplus.
We see in table \ref{tb:HNG1_PBA_wel} that subjects actually operating the $\mathit{RDU_{Prelec}}$ model are expected to be the worst characterized by the models they've been classified as.

Across all four models, table \ref{tb:HNG1_PBA_wel} shows that subjects operating the EUT and $\mathit{RDU_{Pow}}$ models are expected to be the best characterized by the models they've been classified as.
The models that these subjects are likely to be misclassified as, with probabilities given in table \ref{tb:HNG1_PBA}, provide estimates of welfare surplus that are relatively close to the real welfare surplus values.
In the EUT case, subjects also have a relatively high probability of being correctly classified as operating an EUT model, which provides the most accurate welfare surplus estimates across the entire range of CRRA and $\lambda$ parameters.

Table \ref{tb:HNG1_PAB_wel} shows the expected welfare surplus difference by classification model.
We see from this table that subjects that have been classified as operating a $\mathit{RDU_{Prelec}}$ model, regardless of the model the subjects actually operate, have welfare surplus differences closest to 0, and are therefore the best characterized.
Subjects that have been classified as operating the $\mathit{RDU_{Invs}}$ model have the most negative welfare surplus differences of the four models, meaning that subjects classified as $\mathit{RDU_{Invs}}$ are the worst characterized.
This is unsurprising given the low probability of any subject being classified as $\mathit{RDU_{Invs}}$.
Subjects that have been classified as operating either EUT or $\mathit{RDU_{Pow}}$ models are roughly equally well served by the characterization.

\section{Artificial Laboratories}

The first section of this chapter, discussing the details of how the classification process utilized in \textcite{Harrison2016} is operationalized, and the second section of this chapter, discussing how accurate this classification process is in a world where subjects only actually operate one of the four models that are considered in the classification process, can both be considered in a broader discussion of experimental methodology.
We believe the simulation methods used in this chapter are more akin to a laboratory experiment than to the analytical approximations conducted in chapter 3, in that their intention is to test hypotheses, not merely calculate an approximated statistic.

Specifically, this chapter concerns itself with conducting an experiment in order to test hypotheses related to the two following questions:
First, can the classification process proposed by \textcite{Harrison2016}, combined with subjects' responses to the lottery task instrument utilized by \textcite{Harrison2016}, provide accurate information about the models subjects actually operate;
secondly, can the classification process provide information that usefully characterizes the welfare consequences of subjects' responses to the insurance task instrument.
The first question suggests a null hypothesis of yes, the classification process provides accurate classification information, within some reasonable degree of confidence, against an alternative hypothesis that it does not.
The second question also suggest a null hypothesis of yes, the results of the classification process are useful, regardless of their accuracy, in characterizing the welfare consequences of subjects responses in the insurance tasks, against an alternative hypothesis that it do not.
These two hypothesis are themselves Duhem-Quine \parencite{Duhem1954, Quine1953} auxiliary hypotheses to those proposed by \textcite{Harrison2016}.

There are close corollaries between the aspects of experiments described by \textcite{Harrison2004} and \textcite{Smith1982} and the techniques employed in this chapter.
In the terminology of \textcite[924-927]{Smith1982}, we have well defined agents and environments, and institutionally defined message spaces and outcome allocation rules.


There are Duhem-Quine auxiliary hypotheses associated with this kind of estimation, notably the optimization settings.
This type of \enquote{synthetic} laboratory is useful in alleviating Duhem-Quine auxiliary hypotheses associated with laboratory environments with real people.


That subjects operating the $\mathit{RDU_{Prelec}}$ model are expected to be the worst characterized by the model they have been classified as, but subjects that have been classified as operating a $\mathit{RDU_{Prelec}}$ are expected to be the best characterized by this model introduces interesting questions about the usefulness of the $\mathit{RDU_{Prelec}}$ model.
Firstly, it is important to keep in mind that the welfare surplus characterizations given in this section are subject to the classification process; we are only considering the welfare consequences of this classification process, not of another process.

\section{Conclusions}

% Wilcox (2008), pg. 264)
%In fact, this seems to be the case in most such simulated data sets with individual estimation when the fit comparison is confined to the same choice data used for estimation – that is, for in-sample fit comparisons.

\section{Appendix - Numerical Optimizations}

\textcite{Harrison2016} use the popular statistical software Stata to conduct their analysis, and Stata's modified Newton-Rhapson (NR) algorithm to find the maximum likelihood estimates.
I, however, use the R statistical software, with the NR algorithm provided in the package \enquote{maxLik} to conduct our analysis throughout this chapter.
Both our approach and that of \textcite{Harrison2016} require \enquote{handwritten} likelihood functions due to the particular nature of recovering maximum likelihood estimates from non-linear structural models.
The handwritten program of \textcite{Harrison2016} is written in the Stata language, whereas our program is written in C++, and compiled and called by R.

For an in-depth discussion of how the NR algorithm finds the maximum of a function see \textcite[213-219]{Train2002}.
For our purposes, only a few key points about how the NR algorithm operates are useful to bear in mind.
Firstly, a maximum is declared when the gradient of the likelihood function approaches 0, and the matrix of second derivatives of the likelihood, the Hessian matrix, is negative definite.
These two conditions indicate that the likelihood function is locally concave at the point where these conditions hold (the Hessian condition), and that the point exists at a maximum of this local concavity (the gradient condition).
These conditions are shared by other \enquote{gradient-based} optimizers subject as the Boyden-Fletcher-Goldfarb-Shanno (BFGS) or Berndt-Hall-Hall-Hausman (BHHH) algorithms.

Secondly, the NR and other gradient-based algorithms are not \enquote{global} optimizers.
If the likelihood function is not globally concave, the NR optimizer is not guaranteed to reach a global optimum from any starting point.
For instance, if the log-likelihood function is highly bimodal and the initial values for the optimizer are near the smaller mode, the NR optimizer may converge on the maximum of the concave portion of the smaller mode.
The NR algorithm attempts to mitigate situations like this{\footnotemark}, but ultimately the NR algorithm is only guaranteed to find a global maximum if the likelihood function is globally concave \parencite[218]{Train2002}.
I do not, however, expect the likelihood functions applied to the data we recover from experiments to be globally concave \parencite[227]{Train2002}.
If we employed a linear-in-parameters utility function, as opposed to the non-linear functions we actually employ, we would have a globally concave log-likelihood function.

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	See \textcite[216]{Train2002}, for specifics about how NR attempts to mitigate this problem.
	Stata's \enquote{ml search} command additionally tries to mitigate this problem by initially searching for parameter sets that are near a global maximum, and using these found parameter sets as initial values for the NR algorithm.
}

% The Craft of Economics
% Edward E. Leamer
% p 25 -  Dissucesses the idea that two different statistical packages producing different results being shocking as "Economic Fiction"

Numerical optimization also takes place on a physical machine, and the limits of how computers manipulate and store numbers will also affect the result of an optimization exercise.
\textcite{Gould2006} discusses how real numbers are stored and processed in modern computers and how differences in the order of operations can lead to differences in how a computer stores a value.
Again, only a few points here are necessary to bear in mind.
Firstly, there is a limit at which a computer can effectively distinguish between two different real numbers.
Of particular interest to us is the limit at which a computer can distinguish between a small number and 0, as one of the conditions of finding an optimum was that the gradient must be equal to 0.{\footnotemark}
Indeed, even for peaked likelihood functions, there can be (and must be for continuous parameter sets), ranges of parameters at which the gradient is indistinguishable from 0.
Because of this, in the actual operation of an optimizer, a threshold is stipulated below which the gradient is considered equivalent to 0, and a (potentially different) threshold is stipulated below which the Hessian is considered negative definite.
These thresholds are very small numbers, but usually not the smallest numbers that a computer can distinguish from 0.
The issue with how computers store and manipulate numerical values is of course a very general issue and not unique to the NR algorithm, or the R or Stata statistical software.
Similar issues would arise for different optimization algorithms, such as BFGS or BHHH algorithms, though the differences between these algorithms and NR imply different issues as well.{\footnotemark}

\begin{lrbox}{\LstBoxR}
\begin{lstlisting}
.Machine$double.xmin == 0
FALSE
z <- .Machine$double.xmin + 0.1
z - 0.01 == 0
TRUE
\end{lstlisting}
\end{lrbox}

\begin{lrbox}{\LstBoxStata}
\begin{lstlisting}[language=bash]
di smallestdouble() == 0
0
scalar z = smallestdouble() + 0.1
di z - 0.1 == 0
1
\end{lstlisting}
\end{lrbox}

\addtocounter{footnote}{-2}
\stepcounter{footnote}\footnotetext{
For instance, in R, the smallest positive number recognized as different from 0 is given by the value of \texttt{.Machine\$double.xmin}, and in Stata is given by the value of \texttt{smallestdouble()}.
After having stored these values in either R or Stata, and then operating on them, these smallest values are then lost:

\noindent For R:

\usebox{\LstBoxR}

\noindent For Stata:

\usebox{\LstBoxStata}

The numerical precision is lost after the initial addition operation, and now the computer cannot distinguish between 0 and the operated on value, even though it is mathematically different from 0.
}
\stepcounter{footnote}\footnotetext{
	Again, \textcite[220-225]{Train2002} is a useful reference to understand how these algorithms operate.
}

What is important to note about these issues is that different optimization algorithms, initial values given to the optimizer, tolerances for convergence, or potentially even the order of operations in the \enquote{handwritten} programs used in optimizers can lead to different estimates of parameter values, or to different convergence codes.{\footnotemark}
Researchers generally recognise these issues and attempt estimation on a variety of optimizers within at least one statistical package, but seldom change the tolerances for convergence from those deemed \enquote{sane} defaults by the software's authors, or run estimations across different statistical software.{\footnotemark}

\addtocounter{footnote}{-2}
\stepcounter{footnote}\footnotetext{
	Generally optimizers give \enquote{codes} to signal the degree of confidence in the returned optimum.
	These may indicate that the gradient is below its tolerance level, that the gradient or likelihood hasn't decreased after many iterations, that the limit of iterations has been reached, or that the optimizer failed to converge on a single maximum.
	I follow \textcite{Harrison2016} in only considering estimates that have gradients below the given threshold value and a Hessian that is negative definite.
}
\stepcounter{footnote}\footnotetext{
	The NR, BFGS, and BHHH, optimizers are all available in Stata and R.
	Concerning tolerance levels, Stata's help file for its \texttt{ml\_maxopts} command states concerning the options for changing tolerance levels: \enquote{These options are seldom used.}
}

\onlyinsubfile{
\newpage
\printbibliography[segment=4, heading=subbibliography]
}

\end{document}
