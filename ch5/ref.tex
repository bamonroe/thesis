\documentclass[../main.tex]{subfiles}

\begin{document}

\doublespacing
\setcounter{chapter}{4}

\chapter{Conclusions}

%\lltoc % Table of contents only when locally compiled

\section{Review of Chapters}

%Shortly after the introduction of Expected Utility Theory, economists and psychologists began publishing results that showed choices made by subjects which apparently violate one or more of the EUT axioms.
%Research concerning how often choice patterns which violate EUT occur, whether they are more likely to occur for given choice scenarios than others, or whether agents \enquote{systematically} deviate from the axioms of EUT has been conducted in response to these results.

This thesis focuses broadly on the interpretation of choice behavior that seemingly violates Expected Utility Theory (EUT).
Chapter 1 discusses economists' responses to the experimental evidence presented by \textcite{Grether1979} which investigated apparent violations of transitivity.
These responses vary from developing new theoretical models, to critiques of experimental method and scope, to the promotion of stochastic models of choice.
The remainder of this thesis focused primarily on how stochastic elements of choice models influence normative statements of welfare.

Chapter 2 discusses the normative coherence of three classes of stochastic models: the \enquote{Tremble} (TR) model popularized by \textcite{Harless1994}, the \enquote{Random Error} (RE) model popularized by \textcite{Hey1994} and the \enquote{Random Preferences} (RP) model popularized by \textcite{Loomes1998}.
%TR models require that with some probability, a choice is made as if it was selected entirely at random from the set of alternatives.
%RP models require that subjects choose as if they had randomly picked a preference relation from some distribution of preference relations and made a choice deterministically with respect to that preference relation.
I propose an extension of the RP model, called the Random Preference Per Option (RPPO) model, which requires an agent to choose a preference parameter from a distribution of preferences for each option in the set of alternatives instead of a single preference relation for the entire set of alternatives.
%RE models generally require that as the difference in expected utility of the options grows, the choice probability of the option with the greatest expected utility will approach 1, while the choice probabilities of the other options will approach 0.{\footnotemark}
The RE model as proposed by \textcite{Hey1994} is similar to a homoscedastic latent index model, and can be modified in useful ways by making the latent index heteroscedastic, several examples of which are detailed in Chapter 2.
Chapter 2, specifically investigates the Contextual Utility (CU) model proposed by \textcite{Wilcox2008}.
The remainder of the thesis also utilizes this stochastic model.

%\addtocounter{footnote}{-1}
%\stepcounter{footnote}\footnotetext{
%	Some RE models assign a probability of 0 to options which are First Order Stochastically Dominated (FOSD) by another option, regardless of how great the difference in expected utility is between the two options.
%}

Chapter 2 proposes a thought experiment, called the Stochastic Money Pump (SMP), to explore the ability of stochastic models to make coherent normative statements according to two criteria.
The SMP allows for a choice pattern that would leave agents with a strictly smaller stock of assets, deemed an \enquote{extraction}.
The probability off an extraction and the welfare consequences of the extraction are calculated for each of the TR, CU, RP, and RPPO models, as well as a combination of RP and TR (RP+TR) models.
The various models can be parameterized in such a way to produce identical probabilities of extraction.

Of particular concern is a criterion stipulating that should an agent be left with strictly fewer assets after a resource allocation, that agent should be said to be worse off than had she had her previous, greater, stock of assets.
The TR and RE models usefully characterize a strict loss of assets as a loss of consumer surplus.
However, the RP model, and the related RPPO and RP+TR models, allow for an extraction event to result in \textit{greater} consumer surplus.
This is despite the fact that the RP models strictly prohibit the choice of a lower stock of assets over a greater stock of assets at the individual choice level.
I conclude that the RP model and its derivatives don't allow for perfectly coherent normative statements to be made and caution against its use in domains where individual level welfare is being assessed.

Chapter 3 adopts an unconditional probability and welfare framework to continue to discuss the relationship of choice probabilities and welfare.
The multiple price list of \textcite{Holt2002} (HL-MPL) is utilized to illustrate a disconnect between the probability of a pattern of choices and the expected welfare realization of those choices.
The HL-MPL is utilized because it contains only 10 pairs of lotteries, and thus there are only 1024 possible patterns of choices, and one of the lottery pairs is an obvious case of First Order Stochastic Dominance (FOSD).
For a hypothetical population, the correlation between likelihood and welfare realization is positive, but not particularly close to 1.
As the unconditional likelihood of a choice pattern increases, the welfare realization of the choice pattern generally also increases, but this is not the case across all choice patterns.
In particular, it is shown that for most choice patterns which exhibit FOSD, there exist choice patterns which are many times more likely to be observed, but which nonetheless provide less welfare.
This disconnect between likelihood and welfare realization is due to how the CU model is formulated to make individual choices which exhibit FOSD particularly unlikely, even if the cost of violating FOSD is relatively small in welfare terms.
%When the choices which exhibit FOSD are aggregated into larger patterns of choice, the likelihood of the choice pattern itself is greatly reduced.

Additionally, Chapter 3 discusses how the unconditional likelihood of \enquote{choice errors} and the expected unconditional welfare surplus of EUT populations relate to the distribution of preferences in the population and the instrument on which choices are made.
As the density of preferences in a population increases around a \enquote{point of indifference}, a value for which an agent would be indifferent between the options of some lottery pair, the likelihood of choice errors increases.
Generally as the density of preferences in a population increases around multiple points of indifference, the cost of the choice errors in a population also increases.
However, the welfare cost due to the stochastic parameters employed by the populations seems to be of greater magnitude than the preferences themselves.

Chapter 4 conducts a power analysis on individual level estimation utilizing the experimental design and protocol of \textcite{Harrison2016} (HN).
HN critique the \enquote{take-up} metric used in the insurance literature to judge the \enquote{success} of an insurance product.
They conduct an experiment to demonstrate how the structural estimation of a utility function at the individual level can be used to calculate the consumer surplus of decisions to purchase, or not to purchase, insurance products.
They presented the subjects with two instruments, a lottery task used to estimate the structural utility model, and an insurance task used to measure the consumer surplus of the subjects' choices.
This process requires that a model be selected in order to calculate the consumer surplus.
I call this process the \enquote{classification} process, and assess the power of this process, paired with the lottery task, to correctly identify agents employing either the EUT model or a Rank Dependent Utility (RDU) model with the flexible probability weighting function given by \textcite{Prelec1998} ($\mathit{RDU_{Prelec}}$).

I find that the accuracy of the classification process depends on both the model employed by the simulated subject and the values of the parameters of that model.
The probability of correctly classifying subjects that employed the $\mathit{RDU_{Prelec}}$ model was found to generally be lower than 50\% across the parameter space explored, and was noticeably lower than for EUT subjects, who were generally correctly classified between 80\% and 90\% of the time.
The cost of misclassification in terms of the difference between estimated and actual welfare surplus was much larger for subjects that employed the $\mathit{RDU_{Prelec}}$ model than for EUT subjects.

Given the asymmetry of the accuracy of estimates of welfare surplus between EUT and $\mathit{RDU_{Prelec}}$ subjects, I propose an approach which classifies every subject as employing an $\mathit{RDU_{Prelec}}$ model if it has converged for the subject, and EUT otherwise.
This \enquote{Default} approach results in greater accuracy of welfare surplus estimates for $\mathit{RDU_{Prelec}}$ subjects and slightly worse accuracy for EUT subjects.
For a given hypothetical population, the proportion of subjects employing the EUT model would have to be greater than 89.6\% for the improvement in average welfare accuracy for $\mathit{RDU_{Prelec}}$ subjects to be outweighed by the average loss of accuracy for EUT subjects.

\section{Limitations}
This thesis also suffers from a number of limitations.
In Chapter 2, the example used to make the argument that RP models do not make perfectly coherent statements about welfare relies on a parameterization of the RP model that makes the \enquote{extraction} event relatively rare and small in expected value terms compared to the expected value of the lotteries concerned.
If the difference between the RP and RE models in terms of expected welfare realization is small for choice domains that economists are concerned about, then descriptive concerns may outweigh the lack of perfect coherence of the RP model and its derivatives.
Additionally, Chapter 2 assesses the normative coherence of the stochastic models on the basis of two normative criteria.
Economists may find other criteria, not included in this analysis, to be of greater value in making normative prescriptions.
However, any gain in normative coherence for the RP model on the basis of additional criteria would still have to be weighed against the criteria proposed in Chapter 2.

In Chapter 3 the analysis was limited to the HL-MPL which has much fewer lottery pairs than modern experimental instruments and may not constitute a welfare relevant domain.
Additionally, the \enquote{D statistic} proposed would have to be extended to include probability weighting parameters in order to be applicable to RDU populations.

In Chapter 4 the power analysis is constrained to only two different types of utility models, the EUT and $\mathit{RDU_{Prelec}}$ model.
Additionally, both models utilized the same utility function, the CRRA function, and the same stochastic model, the CU model.
There are many possible utility functions and stochastic models that can be employed with either the EUT or $\mathit{RDU_{Prelec}}$ framework.
Real subjects may employ one of these different utility or stochastic models, while still conforming to EUT or $\mathit{RDU_{Prelec}}$.
Subjects may also employ a probability weighting function that does not closely resemble some parameterization of the $\mathit{RDU_{Prelec}}$ model, but nonetheless is permissible under the general RDU framework.
It may be the case that if subjects employ these different utility, probability weighting, and stochastic models, their welfare is more accurately characterized under the classification process proposed by HN than under the \enquote{Default} approach proposed in Chapter 4.
One should therefore be cautious when relating the power analysis conducted here to estimates on real subjects. % when the inferential goal is to classify subjects as conforming to either EUT or RDU more generally.
Power analyses utilizing a larger range of EUT and RDU models can help ease this concern.

Additionally, although the \enquote{Default} approach proposed in Chapter 4 achieves greater accuracy of welfare surplus estimates for populations made of both EUT and $\mathit{RDU_{Prelec}}$ subjects, it does so at the cost of the accuracy of classifying subjects as employing one model or the other.
There are many reasons why having increased likelihood of correct classification would be useful normatively.
Having models that accurately represent subjects' choice behavior allows for better experiment design.
For instance, the random lottery incentive mechanism (RLIM) discussed in Chapter 1 is considered to be incentive compatible under EUT, but not \textit{necessarily} so under RDU.
Having a high degree of confidence about whether subjects employ one model or another in this case speaks directly to the value of this experimental design.
The $\text{HN}_{1040}$ approach proposed in Chapter 4 suggests that one way to improve this accuracy is to dramatically increase the number of lottery pairs presented to subjects.
However, 1040 lottery pairs is well beyond what is considered an acceptable demand to place on subjects.
Additional power analyses should be conducted to help inform experimenters about the number of lottery pairs required to reach an acceptable level of power.

It should also be clear that the results of these power analyses are limited by the scope of the inferential objective under investigation.
While these results are useful for experiments where the inferential objective is to classify subjects as employing either the EUT or $\mathit{RDU_{Prelec}}$ models at the individual level, these results should not be construed to suggest that similar experiments with different inferential objectives have the same strengths or weaknesses.
For instance, these analyses cannot make any claims concerning inferences at the sample level from pooled data, even if the experimental protocol was identical.

This thesis offers cautions and insights for the experimental economics literature.
It cautions that some models of choice may be useful in terms of their descriptive ability, but not useful when making the kind of normative statements that economists care about.
It offers insights into the power of economic experiments to identify whether subjects employ probability weighting.

\onlyinsubfile{
\newpage
\printbibliography[segment=5, heading=subbibliography]
}

\end{document}
