\documentclass[../main.tex]{subfiles}

\begin{document}

\doublespacing
\setcounter{chapter}{4}

\chapter{Conclusions}

%\lltoc % Table of contents only when locally compiled

\section{Review of Chapters}

%Shortly after the introduction of Expected Utility Theory, economists and psychologists began publishing results that showed choices made by subjects which apparently violate one or more of the EUT axioms.
%Research concerning how often choice patterns which violate EUT occur, whether they are more likely to occur for given choice scenarios than others, or whether agents \enquote{systematically} deviate from the axioms of EUT has been conducted in response to these results.

I focus broadly on the interpretation of choice behavior that seemingly violates Expected Utility Theory (EUT).
Chapter 1 discusses economists' responses to the experimental evidence presented by \textcite{Grether1979}, which investigated apparent violations of transitivity.
These responses vary from developing new theoretical models, to critiques of experimental method and scope, to the promotion of stochastic models of choice.
The remainder of this thesis examines on how stochastic elements of choice models influence normative statements of welfare.

Chapter 2 discusses the normative coherence of three classes of stochastic models: the \enquote{Tremble} (TR) model developed by \textcite{Harless1994}, the \enquote{Random Error} (RE) model developed by \textcite{Hey1994}, and the \enquote{Random Preferences} (RP) model developed by \textcite{Loomes1998}.
TR models require that with some probability, a choice is made as if it was selected entirely at random from the set of alternatives.
RP models require that subjects choose as if they had randomly picked a preference relation from some distribution of preference relations and made a choice deterministically with respect to that preference relation.
RE models generally require that as the difference in expected utility of the options grows, the choice probability of the option with the greatest expected utility will approach 1, while the choice probabilities of the other options will approach 0.{\footnotemark}
I propose an extension of the RP model, called the Random Preference Per Option (RPPO) model, which requires an agent to choose a preference parameter from a distribution of preferences for \textit{each} option in the set of alternatives instead of a single preference relation for the entire set of alternatives.
This extension allows for options which are First Order Stochastically Dominated (FOSD) by another option to have a positive choice probability, which is prohibited by the stand-alone RP model.
The RE model proposed by \textcite{Hey1994} is similar to a homoscedastic latent index model, and can be modified in useful ways by making the latent index heteroscedastic, several examples of which are detailed in Chapter 2.
Chapter 2 specifically investigates the Contextual Utility (CU) model proposed by \textcite{Wilcox2008}, and the remainder of the thesis utilizes this stochastic model.

\addtocounter{footnote}{-1}
\stepcounter{footnote}\footnotetext{
	Some RE models assign a probability of 0 to options which are First Order Stochastically Dominated (FOSD) by another option, regardless of how great the difference in expected utility is between the two options.
}

Chapter 2 proposes a thought experiment, the Stochastic Money Pump (SMP), to explore the capacity of stochastic models to support coherent normative statements according to two criteria.
The first criterion stipulates that should an agent be left with strictly fewer assets after a resource allocation, that agent would be said to be worse off than had she had her previous, greater, stock of assets.
The second criterion stipulates that exposure to market forces should incentivize the agent to behave as if conforming to the theory in question.
The SMP allows for a choice pattern that would leave agents with a strictly smaller stock of assets, deemed an \enquote{extraction.}
The probability off an extraction and the welfare consequences of the extraction are calculated for each of the TR, CU, RP, and RPPO models, as well as a combination of RP and TR models (RP+TR).
The various models can be parameterized in such a way to produce identical probabilities of extraction.

Of particular concern is the first normative criterion relating strict stocks of assets to statements about welfare.
The TR and RE models usefully characterize a strict loss of assets as a loss of consumer surplus.
However, the RP model, and the related RPPO and RP+TR models, allow for an extraction event to result in \textit{greater} consumer surplus.
This is despite the fact that the RP models strictly prohibit the choice of a lower stock of assets over a greater stock of assets at the individual choice level.
I conclude that the RP model and its derivatives do not support coherent normative statements, and caution against its use in domains where individual level welfare is being assessed.

Chapter 3 adopts an unconditional probability and welfare framework to continue to discuss the relationship between choice probabilities and welfare.
The multiple price list popularized by \textcite{Holt2002} (HL-MPL) is utilized to illustrate a disconnect between the probability of a pattern of choices and the expected welfare realization of those choices.
The HL-MPL is utilized because it contains only 10 pairs of lotteries, and thus there are only 1024 possible patterns of choices, and one of the lottery pairs is a behaviorally obvious case of First Order Stochastic Dominance (FOSD).
For a hypothetical, simulated population, the correlation between likelihood and welfare realization is positive, but not particularly close to 1.
As the unconditional likelihood of a choice pattern increases, the welfare realization of the choice pattern generally also increases, but this is not the case across all choice patterns.
In particular, it is shown that most choice patterns which do not exhibit FOSD are many times more likely to be observed, but which nonetheless provide less welfare than many choice patterns which do exhibit FOSD.
This disconnect between likelihood and welfare realization is due to the manner in which the CU model is formulated to make individual choices which exhibit FOSD particularly unlikely, even if the cost of violating FOSD is relatively small in welfare terms.
%When the choices which exhibit FOSD are aggregated into larger patterns of choice, the likelihood of the choice pattern itself is greatly reduced.

%In particular, it is shown that for most choice patterns which exhibit FOSD, there exist choice patterns which are many times more likely to be observed, but which nonetheless provide less welfare than the patterns which exhibit FOSD.

Chapter 3 also discusses how the unconditional likelihood of \enquote{choice errors} and the expected unconditional welfare surplus of EUT populations relate to the distribution of preferences in the population and the instrument on which choices are made.
As the density of preferences in a population increases around a \enquote{point of indifference,} a parameter value for the CRRA function which would indicate indifference indifferent between the options of some lottery pair, the likelihood of choice errors increases.
Generally, as the density of preferences in a population increases around multiple points of indifference, the cost of choice errors in a population also increases.
However, the welfare cost due to the stochastic \enquote{noise} parameters employed by the populations seems to be of greater magnitude than the preferences representing the \enquote{deterministic core} themselves.

%%%%%
%% ABOVE NEEDS CLARITY
%%%%%


Chapter 4 conducts a power analysis on individual level estimation utilizing the experimental design and protocol of \textcite{Harrison2016} (HN).
HN critique the \enquote{take-up} metric used in the insurance literature to judge the \enquote{success} of an insurance product.
They conduct an experiment to demonstrate how the structural estimation of a utility function at the individual level can be used to calculate the consumer surplus of decisions to purchase, or not purchase, insurance products.
They presented subjects with two instruments, a lottery task used to estimate the structural model of risk preferences, and an insurance policy choice task used to measure the consumer surplus of the same subject's choices.
This process requires that a model be selected in order to calculate the consumer surplus.
I call this process the \enquote{classification} process, and assess the power of this process, paired with the lottery task, to correctly identify agents employing either the EUT model or a Rank Dependent Utility (RDU) model with the flexible probability weighting function given by \textcite{Prelec1998} ($\mathit{RDU_{Prelec}}$).

I find that the accuracy of the classification process depends on both the model employed by the simulated subject and the values of the parameters of that model.
The probability of correctly classifying subjects that employed the $\mathit{RDU_{Prelec}}$ model was found to generally be lower than 50\% across the (\textit{a priori} plausible) parameter space explored, and was noticeably lower than for EUT subjects, who were generally correctly classified between 80\% and 90\% of the time.
The cost of misclassification in terms of the difference between estimated and actual welfare surplus was much larger for subjects that employed the $\mathit{RDU_{Prelec}}$ model than for EUT subjects.

Given the asymmetry of the accuracy of estimates of welfare surplus between EUT and $\mathit{RDU_{Prelec}}$ subjects, I propose an approach which classifies every subject as employing an $\mathit{RDU_{Prelec}}$ model if feasible, and EUT otherwise.
This \enquote{Default} approach results in greater accuracy of welfare surplus estimates for $\mathit{RDU_{Prelec}}$ subjects and slightly worse accuracy for EUT subjects.
For a given hypothetical population, the proportion of subjects employing the EUT model would have to be greater than 90\% for the improvement in average welfare accuracy for $\mathit{RDU_{Prelec}}$ subjects to be outweighed by the average loss of accuracy for EUT subjects.

%%%%%
%% NEED TO ADD THING ABOUT THE MORE SUBJECTS
%%%%%


\section{Limitations}
This thesis also incorporates a number of limitations.
In Chapter 2, the example used to make the argument that RP models do not make perfectly coherent statements about welfare relies on a parameterization of the RP model that makes the \enquote{extraction} event relatively rare and small in expected value terms compared to the expected value of the lotteries concerned.
If the difference between the RP and RE models in terms of expected welfare realization is small for choice domains that economists are concerned about, then descriptive concerns may outweigh the lack of coherence of the RP model and its derivatives.
Additionally, Chapter 2 assesses the normative coherence of the stochastic models on the basis of the two normative criteria referenced above.
Economists may find other criteria to be of greater value in making normative prescriptions.
However, any gain in normative coherence for the RP model on the basis of additional or different criteria would still have to be weighed against the criteria considered in Chapter 2.

In Chapter 3 the analysis was limited to the HL-MPL, which has fewer lottery pairs than many modern experimental instruments, and may not constitute a choice domain economists are concerned with.
Additionally, the \enquote{D statistic}, proposed as a way to describe how the distribution of risk preferences interacts with the instrument, would have to be extended to include probability weighting parameters in order to be applicable to RDU populations.

In Chapter 4 the power analysis is constrained to only two different types of utility models, the EUT and $\mathit{RDU_{Prelec}}$ model.
Additionally, both models utilized the same risk response function, the CRRA function, and the same stochastic model, the CU model.
There are many possible response functions and stochastic models that can be employed with either the EUT or $\mathit{RDU_{Prelec}}$ framework.
Real subjects may employ one of these different response functions or stochastic models, while still conforming to EUT or $\mathit{RDU_{Prelec}}$ in general.
Subjects may also employ a probability weighting function that does not closely resemble any parameterization of the $\mathit{RDU_{Prelec}}$ model, but nonetheless is permissible under the general RDU framework.
It may be the case that if subjects employ these different response functions, probability weighting functions, and stochastic models, their welfare is more accurately characterized under the classification process proposed by HN than under the \enquote{Default} approach proposed in Chapter 4.
One should therefore be cautious when extending the conclusions drawn here to more general inferential objectives.
Power analyses utilizing a wider range of EUT and RDU models can help ease this concern.

Additionally, although the \enquote{Default} approach proposed in Chapter 4 achieves greater accuracy of welfare surplus estimates for populations made up of both EUT and $\mathit{RDU_{Prelec}}$ subjects, it does so at the cost of the accuracy of classifying subjects as employing one model or the other.
There are many reasons why increased likelihood of correct classification would be useful normatively.
Models that accurately represent the choice behavior of subjects can guide for better experiment design.
For instance, the random lottery incentive mechanism (RLIM) discussed in Chapter 1 is considered to be incentive compatible under EUT, but not \textit{necessarily} under RDU.
Having a high degree of confidence about whether subjects employ one model or another in this case speaks directly to the value of this experimental design.
The $\text{HN}_{1040}$ approach proposed in Chapter 4 suggests that one way to improve this accuracy is to dramatically increase the number of lottery pairs presented to subjects.
However, 1040 lottery pairs is well beyond what is considered an acceptable demand to place on subjects.
Additional power analyses should be conducted to help inform experimenters about the number of lottery pairs required to reach an acceptable level of power.

It should also be clear that the results of these power analyses are limited by the scope of the objective under investigation.
While these results are useful for experiments where the objective is to classify subjects as employing either the EUT or $\mathit{RDU_{Prelec}}$ models at the individual level, these results should not be construed to suggest that similar experiments with different inferential objectives have the same strengths or weaknesses.
For instance, these analyses cannot make any claims concerning inferences at the sample level from pooled data, even if the experimental protocol was identical.

This thesis offers cautions and insights for the experimental economics literature, as that literature starts to contribute rigorously to normative evaluations.
It cautions that some models of choice may be useful in facilitating description, but less useful for supporting the kind of normative assessments that economists care about.
It offers insights into the power of economic experiments to identify whether subjects employ probability weighting.

\onlyinsubfile{
\newpage
\printbibliography[segment=5, heading=subbibliography]
}

\end{document}
